[
  {
    "title": "Empirical and Experimental Perspectives on Big Data in Recommendation Systems: A Comprehensive Survey",
    "keywords": [
      "big data algorithms,",
      "recommendation systems,",
      "recommendation algorithms,",
      "deep learning in recommendations"
    ],
    "abstract": "This survey paper provides a comprehensive analysis of big data algorithms in recommendation systems, addressing the lack of depth and precision in existing literature. It proposes a two-pronged approach: a thorough analysis of current algorithms and a novel, hierarchical taxonomy for precise categorization. The taxonomy is based on a tri-level hierarchy, starting with the methodology category and narrowing down to specific techniques. Such a framework allows for a structured and comprehensive classification of algorithms, assisting researchers in understanding the interrelationships among diverse algorithms and techniques. Covering a wide range of algorithms, this taxonomy first categorizes algorithms into four main analysis types: user and item similarity based methods, hybrid and combined approaches, deep learning and algorithmic methods, and mathematical modeling methods, with further subdivisions into sub-categories and techniques. The paper incorporates both empirical and experimental evaluations to differentiate between the techniques. The empirical evaluation ranks the techniques based on four criteria. The experimental assessments rank the algorithms that belong to the same category, sub-category, technique, and sub-technique. Also, the paper illuminates the future prospects of big data techniques in recommendation systems, underscoring potential advancements and opportunities for further research in this fields."
  },
  {
    "title": "Towards Privacy in Decentralized IoT: A Blockchain-Based Dual Response DP Mechanism",
    "keywords": [
      "differential privacy,",
      "dual response strategies,",
      "collusion attack,",
      "blockchain"
    ],
    "abstract": "Differential Privacy (DP) stands as a secure and efficient mechanism for privacy preservation, offering enhanced data utility without compromising computational complexity. Its adaptability is evidenced by its integration into blockchain-based Internet of Things (IoT) contexts, including smart wearables, smart homes, etc. Nevertheless, a notable vulnerability surfaces in decentralized environments where existing DP mechanisms falter in withstanding collusion attacks. This vulnerability stems from the absence of an efficient strategy to synchronize the privacy budget consumption and historical query information among all network participants. Adversaries can exploit this weakness, collaborating to inject a substantial volume of queries simultaneously into disparate blockchain nodes to extract more precise results. To address this issue, we propose a novel dual response DP mechanism to preserve privacy in blockchain-based IoT scenarios. It encompasses both direct and indirect response strategies, enabling an adaptive response to external queries, aiming to provide better data utility while preserving privacy. Additionally, this mechanism can synchronize historical query information and privacy budget consumption within the blockchain network to prevent privacy leakage. We employ Relative Error (RE), Mean Square Error (MSE), and privacy budget consumption as evaluation metrics to measure the performance of the proposed mechanism. Experimental outcomes substantiate that the proposed mechanism can adapt to blockchain networks well, affirming its capacity for privacy and great utility."
  },
  {
    "title": "An Evaluation of Variational Autoencoder in Credit Card Anomaly Detection",
    "keywords": [
      "anomaly detection,",
      "optimization,",
      "imbalanced dataset,",
      "generative modeling,",
      "convolutional neural network (cnn),",
      "variational autoencoder (vae),",
      "latent space scaling,",
      "reconstruction error"
    ],
    "abstract": "Anomaly detection is one of the many challenging areas in cybersecurity. The anomaly can occur in many forms, such as fraudulent credit card transactions, network intrusions, and anomalous imageries or documents. One of the most common challenges in anomaly detection is the obscurity of the normal state and the lack of anomalous samples. Traditionally, this problem is tackled by using resampling techniques or choosing models that approximate the distribution of the normal states. Variational AutoEncoder (VAE) has been studied in anomaly detections despite being more suitable in generative tasks. This study aims to explore the usage of VAE in credit card anomaly detection and evaluate latent space sampling techniques. In this study, we evaluate the usage of the convolutional network-based VAE model on a credit card transaction dataset. We train two VAE models, one with a large number of normal data and one with a small number of anomalous data. We compare the performance of both VAE models and evaluate the latent space of both VAE models by rescaling them with reconstruction error vectors. We also compare the effectiveness of the VAE model with other anomaly detection models when they are trained on imbalanced dataset."
  },
  {
    "title": "SGCL-LncLoc: An Interpretable Deep Learning Model for Improving lncRNA Subcellular Localization Prediction with Supervised Graph Contrastive Learning",
    "keywords": [
      "supervised contrastive learning,",
      "long non-coding rna (lncrna),",
      "subcellular localization prediction,",
      "deep learning,",
      "graph convolutional network (gcn)"
    ],
    "abstract": "Understanding the subcellular localization of long non-coding RNAs (lncRNAs) is crucial for unraveling their functional mechanisms. While previous computational methods have made progress in predicting lncRNA subcellular localization, most of them ignore the sequence order information by relying on k-mer frequency features to encode lncRNA sequences. In the study, we develope SGCL-LncLoc, a novel interpretable deep learning model based on supervised graph contrastive learning. SGCL-LncLoc transforms lncRNA sequences into de Bruijn graphs and uses the Word2Vec technique to learn the node representation of the graph. Then, SGCL-LncLoc applies graph convolutional networks to learn the comprehensive graph representation. Additionally, we propose a computational method to map the attention weights of the graph nodes to the weights of nucleotides in the lncRNA sequence, allowing SGCL-LncLoc to serve as an interpretable deep learning model. Furthermore, SGCL-LncLoc employs a supervised contrastive learning strategy, which leverages the relationships between different samples and label information, guiding the model to enhance representation learning for lncRNAs. Extensive experimental results demonstrate that SGCL-LncLoc outperforms both deep learning baseline models and existing predictors, showing its capability for accurate lncRNA subcellular localization prediction. Furthermore, we conduct a motif analysis, revealing that SGCL-LncLoc successfully captures known motifs associated with lncRNA subcellular localization. The SGCL-LncLoc web server is available at http://csuligroup.com:8000/SGCL-LncLoc. The source code can be obtained from https://github.com/CSUBioGroup/SGCL-LncLoc."
  },
  {
    "title": "SNCA: Semi-Supervised Node Classification for Evolving Large Attributed Graphs",
    "keywords": [
      "attributed networks,",
      "node classification,",
      "recommender systems"
    ],
    "abstract": "Attributed graphs have an additional sign vector for each node. Typically, edge signs represent like or dislike relationship between the node pairs. This has applications in domains, such as recommender systems, personalised search, etc. However, limited availability of edge sign information in attributed networks requires inferring the underlying graph embeddings to fill-in the knowledge gap. Such inference is performed by way of node classification which aims to deduce the node characteristics based on the topological structure of the graph and signed interactions between the nodes. The study of attributed networks is challenging due to noise, sparsity, and class imbalance issues. In this work, we consider node centrality in conjunction with edge signs to contemplate the node classification problem in attributed networks. We propose Semi-supervised Node Classification in Attributed graphs (SNCA). SNCA is robust to underlying network noise, and has in-built class imbalance handling capabilities. We perform an extensive experimental study on real-world datasets to showcase the efficiency, scalability, robustness, and pertinence of the solution. The performance results demonstrate the suitability of the solution for large attributed graphs in real-world settings."
  },
  {
    "title": "G3DC: A Gene-Graph-Guided Selective Deep Clustering Method for Single Cell RNA-seq Data",
    "keywords": [
      "gene graphs,",
      "feature selection,",
      "deep learning"
    ],
    "abstract": "Single-cell RNA sequencing (scRNA-seq) technology measures the expression of thousands of genes at the cellular level. Analyzing single-cell transcriptome allows the identification of heterogeneous cell groups, cellular-level regulations, and the trajectory of cell development. An important aspect in the analyses of scRNA-seq data is the clustering of cells, which is hampered by issues, such as high dimensionality, cell type imbalance, redundancy, and dropout. Given cells of each type are functionally consistent, incorporating biological relations among genes may improve the clustering results. In light of this, we have developed a deep-embedded clustering method, G3DC. This method combines a graph regularization based on the pre-existing gene network and a feature selector based on the ℓ2,1-norm regularization, along with a reconstruction loss, to generate a discriminatory and informative embedding. Utilizing the gene interaction network bolsters the clustering performance and aids in selecting functionally coherent genes, consequently enriching the clustering results. Extensive experiments have shown that G3DC offers high clustering accuracy with regard to agreement with true cell types, outperforming other leading single-cell clustering methods. In addition, G3DC selects biologically relevant genes that contribute to the clustering, providing insight into biological functionality that differentiates cell groups."
  },
  {
    "title": "DMSS: An Attention-Based Deep Learning Model for High-Quality Mass Spectrometry Prediction",
    "keywords": [
      "mass spectrometry,",
      "proteomics,",
      "machine learning,",
      "deep learning"
    ],
    "abstract": "Accurate prediction of peptide spectra is crucial for improving the efficiency and reliability of proteomic analysis, as well as for gaining insight into various biological processes. In this study, we introduce Deep MS Simulator (DMSS), a novel attention-based model tailored for forecasting theoretical spectra in mass spectrometry. DMSS has undergone rigorous validation through a series of experiments, consistently demonstrating superior performance compared to current methods in forecasting theoretical spectra. The superior ability of DMSS to distinguish extremely similar peptides highlights the potential application of incorporating our predicted intensity information into mass spectrometry search engines to enhance the accuracy of protein identification. These findings contribute to the advancement of proteomics analysis and highlight the potential of the DMSS as a valuable tool in the field."
  },
  {
    "title": "A Disentangled Representation-Based Multimodal Fusion Framework Integrating Pathomics and Radiomics for KRAS Mutation Detection in Colorectal Cancer",
    "keywords": [
      "kras mutation detection,",
      "multimodal feature fusion,",
      "pathomics,",
      "radiomics"
    ],
    "abstract": "Kirsten rat sarcoma viral oncogene homolog (namely KRAS) is a key biomarker for prognostic analysis and targeted therapy of colorectal cancer. Recently, the advancement of machine learning, especially deep learning, has greatly promoted the development of KRAS mutation detection from tumor phenotype data, such as pathology slides or radiology images. However, there are still two major problems in existing studies: inadequate single-modal feature learning and lack of multimodal phenotypic feature fusion. In this paper, we propose a Disentangled Representation-based Multimodal Fusion framework integrating Pathomics and Radiomics (DRMF-PaRa) for KRAS mutation detection. Specifically, the DRMF-PaRa model consists of three parts: (1) the pathomics learning module, which introduces a tissue-guided Transformer model to extract more comprehensive and targeted pathological features; (2) the radiomics learning module, which captures the generic hand-crafted radiomics features and the task-specific deep radiomics features; (3) the disentangled representation-based multimodal fusion module, which learns factorized subspaces for each modality and provides a holistic view of the two heterogeneous phenotypic features. The proposed model is developed and evaluated on a multi modality dataset of 111 colorectal cancer patients with whole slide images and contrast-enhanced CT. The experimental results demonstrate the superiority of the proposed DRMF-PaRa model with an accuracy of 0.876 and an AUC of 0.865 for KRAS mutation detection."
  },
  {
    "title": "Influence of Attribute Granulation on Three-Way Concept Lattices",
    "keywords": [
      "granularity of attributes,",
      "three-way concept analysis (3wca),",
      "three-way concept lattice"
    ],
    "abstract": "In formal concept analysis based applications, controlling the structure of concept lattice is of vital importance, especially for big data, and is achieved via clarifying the granularity of attributes. Existing approaches for solving this issue are within the framework of classical formal concept analysis, which focuses on positive attributes. However, experiments have demonstrated that both positive and negative attributes exert comparable influence on knowledge discovery. Thus, it is essential to explore the granularity of attributes in positive and negative perspectives altogether. As a solution, we investigate this problem within the framework of three-way concept analysis. Specifically, we present zoom-in and zoom-out algorithms to obtain more particular and abstract three-way concepts, separately. Furthermore, we provide illustrative examples to show the practical significance of this study."
  },
  {
    "title": "EPIMR: Prediction of Enhancer-Promoter Interactions by Multi-Scale ResNet on Image Representation",
    "keywords": [
      "enhancer-promoter interactions,",
      "hilbert curve,",
      "multi-scale residual neural network (resnet)"
    ],
    "abstract": "Prediction of enhancer-promoter interactions (EPIs) is key to regulating gene expression and diagnosing genetic diseases. Due to limited resolution, biological experiments perform not as well as expected while precisely identifying specific interactions, giving rise to computational biology approaches. Many EPI predictors have been developed, but their prediction accuracy still needs to be enhanced. Here, we design a new model named EPIMR to identify enhancer-promoter interactions. First, Hilbert Curve is utilized to represent sequences to images to preserve the position and spatial information. Second, a multi-scale residual neural network (ResNet) is used to learn the distinguishing features of different abstraction levels. Finally, matching heuristics are adopted to concatenate the learned features of enhancers and promoters, which pays attention to their potential interaction information. Experimental results on six cell lines indicate that EPIMR performs better than existing methods, with higher area under the precision-recall curve (AUPR) and area under the receiver operating characteristic (AUROC) results on benchmark and under-sampling datasets. Furthermore, our model is pre-trained on all cell lines, which improves not only the transferability of cross-cell line prediction, but also cell line-specific prediction ability. In conclusion, our method serves as a valuable technical tool for predicting enhancer-promoter interactions, contributing to the understanding of gene transcription mechanisms. Our code and results are available at https://github.com/guofei-tju/EPIMR."
  },
  {
    "title": "House Price Prediction: A Multi-Source Data Fusion Perspective",
    "keywords": [
      "price prediction,",
      "real estate,",
      "data mining,",
      "data fusion,",
      "machine learning"
    ],
    "abstract": "House price prediction is of utmost importance in forecasting residential property prices, particularly as the demand for high-quality housing continues to rise. Accurate predictions have implications for real estate investors, financial institutions, urban planners, and policymakers. However, accurately predicting house prices is challenging due to the complex interplay of various influencing factors. Previous studies have primarily focused on basic property information, leaving room for further exploration of more intricate features, such as amenities, traffic, and social sentiments in the surrounding environment. In this paper, we propose a novel approach to house price prediction from a multi-source data fusion perspective. Our methodology involves analyzing house characteristics and incorporating factors from diverse aspects, including amenities, traffic, and emotions. We validate our approach using a dataset of 28550 real-world transactions in Beijing, China, providing a comprehensive analysis of the drivers influencing house prices. By adopting a multi-source data fusion perspective and considering a wide range of influential factors, our approach offers valuable insights into house price prediction. The findings from this study possess the capability to improve the accuracy and effectiveness of house price prediction models, benefiting stakeholders in the real estate market."
  },
  {
    "title": "A Large-Scale Spatio-Temporal Multimodal Fusion Framework for Traffic Prediction",
    "keywords": [
      "spatio-temporal,",
      "traffic prediction,",
      "multimodal fusion,",
      "learning representation"
    ],
    "abstract": "Traffic prediction is crucial for urban planning and transportation management, and deep learning techniques have emerged as effective tools for this task. While previous works have made advancements, they often overlook comprehensive analyses of spatio-temporal distributions and the integration of multimodal representations. Our research addresses these limitations by proposing a large-scale spatio-temporal multimodal fusion framework that enables accurate predictions based on location queries and seamlessly integrates various data sources. Specifically, we utilize Convolutional Neural Networks (CNNs) for spatial information processing and a combination of Recurrent Neural Networks (RNNs) for final spatio-temporal traffic prediction. This framework not only effectively reveals its ability to integrate various modal data in the spatio-temporal hyperspace, but has also been successfully implemented in a real-world large-scale map, showcasing its practical importance in tackling urban traffic challenges. The findings presented in this work contribute to the advancement of traffic prediction methods, offering valuable insights for further research and application in addressing real-world transportation challenges."
  },
  {
    "title": "Autism Spectrum Disorder Classification with Interpretability in Children Based on Structural MRI Features Extracted Using Contrastive Variational Autoencoder",
    "keywords": [
      "autism spectrum disorder (asd) classification,",
      "contrastive variational autoencoder (cvae),",
      "transfer learning,",
      "neuroanatomical interpretation"
    ],
    "abstract": "Autism Spectrum Disorder (ASD) is a highly disabling mental disease that brings significant impairments of social interaction ability to the patients, making early screening and intervention of ASD critical. With the development of the machine learning and neuroimaging technology, extensive research has been conducted on machine classification of ASD based on structural Magnetic Resonance Imaging (s-MRI). However, most studies involve with datasets where participants’ age are above 5 and lack interpretability. In this paper, we propose a machine learning method for ASD classification in children with age range from 0.92 to 4.83 years, based on s-MRI features extracted using Contrastive Variational AutoEncoder (CVAE). 78 s-MRIs, collected from Shenzhen Children’s Hospital, are used for training CVAE, which consists of both ASD-specific feature channel and common-shared feature channel. The ASD participants represented by ASD-specific features can be easily discriminated from Typical Control (TC) participants represented by the common-shared features. In case of degraded predictive accuracy when data size is extremely small, a transfer learning strategy is proposed here as a potential solution. Finally, we conduct neuroanatomical interpretation based on the correlation between s-MRI features extracted from CVAE and surface area of different cortical regions, which discloses potential biomarkers that could help target treatments of ASD in the future."
  },
  {
    "title": "Prompting Large Language Models with Knowledge-Injection for Knowledge-Based Visual Question Answering",
    "keywords": [
      "visual question answering,",
      "knowledge-based visual question answering,",
      "large language model,",
      "knowledge injection"
    ],
    "abstract": "Previous works employ the Large Language Model (LLM) like GPT-3 for knowledge-based Visual Question Answering (VQA). We argue that the inferential capacity of LLM can be enhanced through knowledge injection. Although methods that utilize knowledge graphs to enhance LLM have been explored in various tasks, they may have some limitations, such as the possibility of not being able to retrieve the required knowledge. In this paper, we introduce a novel framework for knowledge-based VQA titled “Prompting Large Language Models with Knowledge-Injection” (PLLMKI). We use vanilla VQA model to inspire the LLM and further enhance the LLM with knowledge injection. Unlike earlier approaches, we adopt the LLM for knowledge enhancement instead of relying on knowledge graphs. Furthermore, we leverage open LLMs, incurring no additional costs. In comparison to existing baselines, our approach exhibits the accuracy improvement of over 1.3 and 1.7 on two knowledge-based VQA datasets, namely OK-VQA and A-OKVQA, respectively."
  },
  {
    "title": "Impact of Domain Knowledge and Multi-Modality on Intelligent Molecular Property Prediction: A Systematic Survey",
    "keywords": [
      "molecular property prediction (mpp),",
      "deep learning (dl),",
      "domain knowledge,",
      "multi-modality,",
      "drug discovery"
    ],
    "abstract": "The precise prediction of molecular properties is essential for advancements in drug development, particularly in virtual screening and compound optimization. The recent introduction of numerous deep learningbased methods has shown remarkable potential in enhancing Molecular Property Prediction (MPP), especially improving accuracy and insights into molecular structures. Yet, two critical questions arise: does the integration of domain knowledge augment the accuracy of molecular property prediction and does employing multi-modal data fusion yield more precise results than unique data source methods? To explore these matters, we comprehensively review and quantitatively analyze recent deep learning methods based on various benchmarks. We discover that integrating molecular information significantly improves Molecular Property Prediction (MPP) for both regression and classification tasks. Specifically, regression improvements, measured by reductions in Root Mean Square Error (RMSE), are up to 4.0%, while classification enhancements, measured by the area under the receiver operating characteristic curve (ROC-AUC), are up to 1.7%. Additionally, we discover that, as measured by ROC-AUC, augmenting 2D graphs with 3D information improves performance for classification tasks by up to 13.2% and enriching 2D graphs with 1D SMILES boosts multi-modal learning performance for regression tasks by up to 9.1%. The two consolidated insights offer crucial guidance for future advancements in drug discovery."
  },
  {
    "title": "Multi-Relational Graph Representation Learning for Financial Statement Fraud Detection",
    "keywords": [
      "financial statement fraud,",
      "class imbalance,",
      "graph neural networks (gnn),",
      "multi-relational graphs"
    ],
    "abstract": "Financial statement fraud refers to malicious manipulations of financial data in listed companies’ annual statements. Traditional machine learning approaches focus on individual companies, overlooking the interactive relationships among companies that are crucial for identifying fraud patterns. Moreover, fraud detection is a typical imbalanced binary classification task with normal samples outnumbering fraud ones. In this paper, we propose a multi-relational graph convolutional network, named FraudGCN, for detecting financial statement fraud. A multi-relational graph is constructed to integrate industrial, supply chain, and accounting-sharing relationships, effectively encapsulating the multidimensional and complex interactions among companies. We then develop a multi-relational graph convolutional network to aggregate information within each relationship and employ an attention mechanism to fuse information across multiple relationships. The attention mechanism enables the model to distinguish the importance of different relationships, thereby aggregating more useful information from key relationships. To alleviate the class imbalance problem, we present a diffusion-based under-sampling strategy that strategically selects key nodes globally for model training. We also employ focal loss to assign greater weights to harder-to-classify minority samples. We build a real-world dataset from the annual financial statement of listed companies in China. The experimental results show that FraudGCN achieves an improvement of 3.15% in Macro-recall, 3.36% in Macro-F1, and 3.86% in GMean compared to the second-best method. The dataset and codes are publicly available at: https://github.com/XNetLab/MRG-for-Finance."
  },
  {
    "title": "Network Diffusion Framework to Simulate Spreading Processes in Complex Networks",
    "keywords": [
      "computational framework,",
      "seed selection,",
      "influence maximisation,",
      "spreading models,",
      "temporal networks,",
      "multilayer networks,",
      "network science,",
      "network control"
    ],
    "abstract": "With the advancement of computational network science, its research scope has significantly expanded beyond static graphs to encompass more complex structures. The introduction of streaming, temporal, multilayer, and hypernetwork approaches has brought new possibilities and imposed additional requirements. For instance, by utilising these advancements, one can model structures such as social networks in a much more refined manner, which is particularly relevant in simulations of the spreading processes. Unfortunately, the pace of advancement is often too rapid for existing computational packages to keep up with the functionality updates. This results in a significant proliferation of tools used by researchers and, consequently, a lack of a universally accepted technological stack that would standardise experimental methods (as seen, e.g., in machine learning). This article addresses that issue by presenting an extended version of the Network Diffusion library. First, a survey of the existing approaches and toolkits for simulating spreading phenomena is shown, and then, an overview of the framework functionalities. Finally, we report four case studies conducted with the package to demonstrate its usefulness: the impact of sanitary measures on the spread of COVID-19, the comparison of information diffusion on two temporal network models, and the effectiveness of seed selection methods in the task of influence maximisation in multilayer networks. We conclude the paper with a critical assessment of the library and the outline of still awaiting challenges to standardise research environments in computational network science."
  },
  {
    "title": "Collaborative Knowledge Infusion for Low-Resource Stance Detection",
    "keywords": [
      "parameter-efficient learning,",
      "low-resource stance detection,",
      "knowledge infusion"
    ],
    "abstract": "Stance detection is the view towards a specific target by a given context (e.g. tweets, commercial reviews). Target-related knowledge is often needed to assist stance detection models in understanding the target well and making detection correctly. However, prevailing works for knowledge-infused stance detection predominantly incorporate target knowledge from a singular source that lacks knowledge verification in limited domain knowledge. The low-resource training data further increase the challenge for the data-driven large models in this task. To address those challenges, we propose a collaborative knowledge infusion approach for low-resource stance detection tasks, employing a combination of aligned knowledge enhancement and efficient parameter learning techniques. Specifically, our stance detection approach leverages target background knowledge collaboratively from different knowledge sources with the help of knowledge alignment. Additionally, we also introduce the parameter-efficient collaborative adaptor with a staged optimization algorithm, which collaboratively addresses the challenges associated with low-resource stance detection tasks from both network structure and learning perspectives. To assess the effectiveness of our method, we conduct extensive experiments on three public stance detection datasets, including low-resource and cross-target settings. The results demonstrate significant performance improvements compared to the existing stance detection approaches."
  },
  {
    "title": "Graph Deep Active Learning Framework for Data Deduplication",
    "keywords": [
      "data deduplication,",
      "active learning,",
      "similarity calculation"
    ],
    "abstract": "With the advent of the era of big data, an increasing amount of duplicate data are expressed in different forms. In order to reduce redundant data storage and improve data quality, data deduplication technology has never become more significant than nowadays. It is usually necessary to connect multiple data tables and identify different records pointing to the same entity, especially in the case of multi-source data deduplication. Active learning trains the model by selecting the data items with the maximum information divergence and reduces the data to be annotated, which has unique advantages in dealing with big data annotations. However, most of the current active learning methods only employ classical entity matching and are rarely applied to data deduplication tasks. To fill this research gap, we propose a novel graph deep active learning framework for data deduplication, which is based on similarity algorithms combined with the bidirectional encoder representations from transformers (BERT) model to extract the deep similarity features of multi-source data records, and first introduce the graph active learning strategy to build a clean graph to filter the data that needs to be labeled, which is used to delete the duplicate data that retain the most information. Experimental results on real-world datasets demonstrate that the proposed method outperforms state-of-the-art active learning models on data deduplication tasks."
  },
  {
    "title": "Multi-Task Learning for Alzheimer’s Disease Diagnosis and Mini-Mental State Examination Score Prediction",
    "keywords": [
      "multi-task learning,",
      "alzheimer’s disease diagnosis,",
      "mini-mental state examination score prediction"
    ],
    "abstract": "Accurately diagnosing Alzheimer’s disease is essential for improving elderly health. Meanwhile, accurate prediction of the mini-mental state examination score also can measure cognition impairment and track the progression of Alzheimer’s disease. However, most of the existing methods perform Alzheimer’s disease diagnosis and mini-mental state examination score prediction separately and ignore the relation between these two tasks. To address this challenging problem, we propose a novel multi-task learning method, which uses feature interaction to explore the relationship between Alzheimer’s disease diagnosis and mini-mental state examination score prediction. In our proposed method, features from each task branch are firstly decoupled into candidate and non-candidate parts for interaction. Then, we propose feature sharing module to obtain shared features from candidate features and return shared features to task branches, which can promote the learning of each task. We validate the effectiveness of our proposed method on multiple datasets. In Alzheimer’s disease neuroimaging initiative 1 dataset, the accuracy in diagnosis task and the root mean squared error in prediction task of our proposed method is 87.86% and 2.5, respectively. Experimental results show that our proposed method outperforms most state-of-the-art methods. Our proposed method enables accurate Alzheimer’s disease diagnosis and mini-mental state examination score prediction. Therefore, it can be used as a reference for the clinical diagnosis of Alzheimer’s disease, and can also help doctors and patients track disease progression in a timely manner."
  },
  {
    "title": "Local Region Frequency Guided Dynamic Inconsistency Network for Deepfake Video Detection",
    "keywords": [
      "deepfake video detection,",
      "dynamic inconsistency,",
      "local region,",
      "local region frequency"
    ],
    "abstract": "In recent years, with the rapid development of deepfake technology, a large number of deepfake videos have emerged on the Internet, which poses a huge threat to national politics, social stability, and personal privacy. Although many existing deepfake detection methods exhibit excellent performance for known manipulations, their detection capabilities are not strong when faced with unknown manipulations. Therefore, in order to obtain better generalization ability, this paper analyzes global and local inter-frame dynamic inconsistencies from the perspective of spatial and frequency domains, and proposes a Local region Frequency Guided Dynamic Inconsistency Network (LFGDIN). The network includes two parts: Global SpatioTemporal Network (GSTN) and Local Region Frequency Guided Module (LRFGM). The GSTN is responsible for capturing the dynamic information of the entire face, while the LRFGM focuses on extracting the frequency dynamic information of the eyes and mouth. The LRFGM guides the GTSN to concentrate on dynamic inconsistency in some significant local regions through local region alignment, so as to improve the model’s detection performance. Experiments on the three public datasets (FF++, DFDC, and Celeb-DF) show that compared with many recent advanced methods, the proposed method achieves better detection results when detecting deepfake videos of unknown manipulation types."
  },
  {
    "title": "QTFN: A General End-to-End Time-Frequency Network to Reveal the Time-Varying Signatures of the Time Series",
    "keywords": [
      "time-frequency analysis (tfa),",
      "multi-scale residual encoder-decoder (mred),",
      "quadratic time-frequency distribution (tfd)"
    ],
    "abstract": "Nonstationary time series are ubiquitous in almost all natural and engineering systems. Capturing the time-varying signatures from nonstationary time series is still a challenging problem for data mining. Quadratic Time-Frequency Distribution (TFD) provides a powerful tool to analyze these data. However, they suffer from Cross-Term (CT) issues that impair the readability of TFDs. Therefore, to achieve high-resolution and CT-free TFDs, an end-to-end architecture termed Quadratic TF-Net (QTFN) is proposed in this paper. Guided by classic TFD theory, the design of this deep learning architecture is heuristic, which firstly generates various basis functions through data-driven. Thus, more comprehensive TF features can be extracted by these basis functions. Then, to balance the results of various basis functions adaptively, the Efficient Channel Attention (ECA) block is also embedded into QTFN. Moreover, a new structure called Muti-scale Residual Encoder-Decoder (MRED) is also proposed to improve the learning ability of the model by highly integrating the multi-scale learning and encoder-decoder architecture. Finally, although the model is only trained by synthetic signals, both synthetic and real-world signals are tested to validate the generalization capability and superiority of the proposed QTFN."
  },
  {
    "title": "Analysis and Classification of Fake News Using Sequential Pattern Mining",
    "keywords": [
      "disinformation,",
      "fake news,",
      "sequential pattern mining (spm),",
      "frequent patterns,",
      "classification"
    ],
    "abstract": "Disinformation, often known as fake news, is a major issue that has received a lot of attention lately. Many researchers have proposed effective means of detecting and addressing it. Current machine and deep learning based methodologies for classification/detection of fake news are content-based, network (propagation) based, or multimodal methods that combine both textual and visual information. We introduce here a framework, called FNACSPM, based on sequential pattern mining (SPM), for fake news analysis and classification. In this framework, six publicly available datasets, containing a diverse range of fake and real news, and their combination, are first transformed into a proper format. Then, algorithms for SPM are applied to the transformed datasets to extract frequent patterns (and rules) of words, phrases, or linguistic features. The obtained patterns capture distinctive characteristics associated with fake or real news content, providing valuable insights into the underlying structures and commonalities of misinformation. Subsequently, the discovered frequent patterns are used as features for fake news classification. This framework is evaluated with eight classifiers, and their performance is assessed with various metrics. Extensive experiments were performed and obtained results show that FNACSPM outperformed other state-of-the-art approaches for fake news classification, and that it expedites the classification task with high accuracy."
  },
  {
    "title": "Exploring Fragment Adding Strategies to Enhance Molecule Pretraining in AI-Driven Drug Discovery",
    "keywords": [
      "pretraining,",
      "information retrieval,",
      "drug discovery,",
      "virtual screening,",
      "molecule property prediction"
    ],
    "abstract": "The effectiveness of AI-driven drug discovery can be enhanced by pretraining on small molecules. However, the conventional masked language model pretraining techniques are not suitable for molecule pretraining due to the limited vocabulary size and the non-sequential structure of molecules. To overcome these challenges, we propose FragAdd, a strategy that involves adding a chemically implausible molecular fragment to the input molecule. This approach allows for the incorporation of rich local information and the generation of a high-quality graph representation, which is advantageous for tasks like virtual screening. Consequently, we have developed a virtual screening protocol that focuses on identifying estrogen receptor alpha binders on a nucleus receptor. Our results demonstrate a significant improvement in the binding capacity of the retrieved molecules. Additionally, we demonstrate that the FragAdd strategy can be combined with other self-supervised methods to further expedite the drug discovery process."
  },
  {
    "title": "Node and Edge Joint Embedding for Heterogeneous Information Network",
    "keywords": [
      "node embedding,",
      "edge embedding,",
      "joint embedding,",
      "heterogeneous information network (hin)"
    ],
    "abstract": "Due to the heterogeneity of nodes and edges, heterogeneous network embedding is a very challenging task to embed highly coupled networks into a set of low-dimensional vectors. Existing models either only learn embedding vectors for nodes or only for edges. These two methods of embedding learning are rarely performed in the same model, and they both overlook the internal correlation between nodes and edges. To solve these problems, a node and edge joint embedding model is proposed for Heterogeneous Information Networks (HINs), called NEJE. The NEJE model can better capture the latent structural and semantic information from an HIN through two joint learning strategies: type-level joint learning and element-level joint learning. Firstly, node-type-aware structure learning and edge-type-aware semantic learning are sequentially performed on the original network and its line graph to get the initial embedding of nodes and the embedding of edges. Then, to optimize performance, type-level joint learning is performed through the alternating training of node embedding on the original network and edge embedding on the line graph. Finally, a new homogeneous network is constructed from the original heterogeneous network, and the graph attention model is further used on the new network to perform element-level joint learning. Experiments on three tasks and five public datasets show that our NEJE model performance improves by about 2.83% over other models, and even improves by 6.42% on average for the node clustering task on Digital Bibliography & Library Project (DBLP) dataset."
  },
  {
    "title": "Call for Papers Special Issue on AI-Enhanced Big Data Governance",
    "keywords": [],
    "abstract": ""
  },
  {
    "title": "Data Temperature Informed Streaming for Optimising Large-Scale Multi-Tiered Storage",
    "keywords": [
      "data temperature,",
      "hot and cold data,",
      "multi-tiered storage,",
      "metadata variable,",
      "multi-temperature system"
    ],
    "abstract": "Data temperature is a response to the ever-growing amount of data. These data have to be stored, but they have been observed that only a small portion of the data are accessed more frequently at any one time. This leads to the concept of hot and cold data. Cold data can be migrated away from high-performance nodes to free up performance for higher priority data. Existing studies classify hot and cold data primarily on the basis of data age and usage frequency. We present this as a limitation in the current implementation of data temperature. This is due to the fact that age automatically assumes that all new data have priority and that usage is purely reactive. We propose new variables and conditions that influence smarter decision-making on what are hot or cold data and allow greater user control over data location and their movement. We identify new metadata variables and user-defined variables to extend the current data temperature value. We further establish rules and conditions for limiting unnecessary movement of the data, which helps to prevent wasted input output (I/O) costs. We also propose a hybrid algorithm that combines existing variables and new variables and conditions into a single data temperature. The proposed system provides higher accuracy, increases performance, and gives greater user control for optimal positioning of data within multi-tiered storage solutions."
  },
  {
    "title": "Improved Quantile Convolutional and Recurrent Neural Networks for Electric Vehicle Battery Temperature Prediction",
    "keywords": [
      "battery temperature,",
      "deep learning,",
      "convolutional and recurrent neural network,",
      "quantile forecasting"
    ],
    "abstract": "The battery thermal management of electric vehicles can be improved using neural networks predicting quantile sequences of the battery temperature. This work extends a method for the development of Quantile Convolutional and Quantile Recurrent Neural Networks (namely Q*NN). Fleet data of 225 629 drives are clustered and balanced, simulation data from 971 simulations are augmented before they are combined for training and testing. The Q*NN hyperparameters are optimized using an efficient Bayesian optimization, before the Q*NN models are compared with regression and quantile regression models for four horizons. The analysis of point-forecast and quantile-related metrics shows the superior performance of the novel Q*NN models. The median predictions of the best performing model achieve an average RMSE of 0.66°C and R2 of 0.84. The predicted 0.99 quantile covers 98.87% of the true values in the test data. In conclusion, this work proposes an extended development and comparison of Q*NN models for accurate battery temperature prediction."
  },
  {
    "title": "Extending OpenStack Monasca for Predictive Elasticity Control",
    "keywords": [
      "elasticity control,",
      "auto-scaling,",
      "predictive operations,",
      "monitoring,",
      "openstack,",
      "monasca"
    ],
    "abstract": "Traditional auto-scaling approaches are conceived as reactive automations, typically triggered when predefined thresholds are breached by resource consumption metrics. Managing such rules at scale is cumbersome, especially when resources require non-negligible time to be instantiated. This paper introduces an architecture for predictive cloud operations, which enables orchestrators to apply time-series forecasting techniques to estimate the evolution of relevant metrics and take decisions based on the predicted state of the system. In this way, they can anticipate load peaks and trigger appropriate scaling actions in advance, such that new resources are available when needed. The proposed architecture is implemented in OpenStack, extending the monitoring capabilities of Monasca by injecting short-term forecasts of standard metrics. We use our architecture to implement predictive scaling policies leveraging on linear regression, autoregressive integrated moving average, feed-forward, and recurrent neural networks (RNN). Then, we evaluate their performance on a synthetic workload, comparing them to those of a traditional policy. To assess the ability of the different models to generalize to unseen patterns, we also evaluate them on traces from a real content delivery network (CDN) workload. In particular, the RNN model exhibites the best overall performance in terms of prediction error, observed client-side response latency, and forecasting overhead. The implementation of our architecture is open-source."
  },
  {
    "title": "An Intelligent Big Data Security Framework Based on AEFS-KENN Algorithms for the Detection of Cyber-Attacks from Smart Grid Systems",
    "keywords": [
      "smart grid,",
      "big data analytics,",
      "machine learning (ml),",
      "adabelief exponential feature selection (aefs),",
      "polar bear optimization (pbo),",
      "kernel extreme neural network (kenn)"
    ],
    "abstract": "Big data has the ability to open up innovative and ground-breaking prospects for the electrical grid, which also supports to obtain a variety of technological, social, and financial benefits. There is an unprecedented amount of heterogeneous big data as a consequence of the growth of power grid technologies, along with data processing and advanced tools. The main obstacles in turning the heterogeneous large dataset into useful results are computational burden and information security. The original contribution of this paper is to develop a new big data framework for detecting various intrusions from the smart grid systems with the use of AI mechanisms. Here, an AdaBelief Exponential Feature Selection (AEFS) technique is used to efficiently handle the input huge datasets from the smart grid for boosting security. Then, a Kernel based Extreme Neural Network (KENN) technique is used to anticipate security vulnerabilities more effectively. The Polar Bear Optimization (PBO) algorithm is used to efficiently determine the parameters for the estimate of radial basis function. Moreover, several types of smart grid network datasets are employed during analysis in order to examine the outcomes and efficiency of the proposed AdaBelief Exponential Feature Selection- Kernel based Extreme Neural Network (AEFS-KENN) big data security framework. The results reveal that the accuracy of proposed AEFS-KENN is increased up to 99.5% with precision and AUC of 99% for all smart grid big datasets used in this study."
  },
  {
    "title": "Predicting Energy Consumption Using Stacked LSTM Snapshot Ensemble",
    "keywords": [
      "artificial intelligence (ai),",
      "deep learning (dl),",
      "energy consumption,",
      "snapshot ensemble,",
      "prediction"
    ],
    "abstract": "The ability to make accurate energy predictions while considering all related energy factors allows production plants, regulatory bodies, and governments to meet energy demand and assess the effects of energy-saving initiatives. When energy consumption falls within normal parameters, it will be possible to use the developed model to predict energy consumption and develop improvements and mitigating measures for energy consumption. The objective of this model is to accurately predict energy consumption without data limitations and provide results that are easily interpretable. The proposed model is an implementation of the stacked Long Short-Term Memory (LSTM) snapshot ensemble combined with the Fast Fourier Transform (FFT) and meta-learner. Hebrail and Berard’s Individual Household Electric-Power Consumption (IHEPC) dataset incorporated with weather data are used to analyse the model’s accuracy with predicting energy consumption. The model is trained, and the results measured using Root Mean Square Error (RMSE), Mean Absolute Error (MAE), Mean Absolute Percentage Error (MAPE), and coefficient of determination (R2) metrics are 0.020, 0.013, 0.017, and 0.999, respectively. The stacked LSTM snapshot ensemble performs better than the compared models based on prediction accuracy and minimized errors. The results of this study show that prediction accuracy is high, and the model’s stability is high as well. The model shows that high levels of accuracy prove accurate predictive ability, and together with high levels of stability, the model has good interpretability, which is not typically accounted for in models. However, this study shows that it can be inferred."
  },
  {
    "title": "A Novel Recommendation Algorithm Integrates Resource Allocation and Resource Transfer in Weighted Bipartite Network",
    "keywords": [
      "cloud computing,",
      "bipartite graph network,",
      "recommendation algorithm,",
      "link prediction,",
      "cold start problem"
    ],
    "abstract": "Grid-based recommendation algorithms view users and items as abstract nodes, and the information utilised by the algorithm is hidden in the selection relationships between users and items. Although these relationships can be easily handled, much useful information is overlooked, resulting in a less accurate recommendation algorithm. The aim of this paper is to propose improvements on the standard substance diffusion algorithm, taking into account the influence of the user’s rating on the recommended item, adding a moderating factor, and optimising the initial resource allocation vector and resource transfer matrix in the recommendation algorithm. An average ranking score evaluation index is introduced to quantify user satisfaction with the recommendation results. Experiments are conducted on the MovieLens training dataset, and the experimental results show that the proposed algorithm outperforms classical collaborative filtering systems and network structure based recommendation systems in terms of recommendation accuracy and hit rate."
  },
  {
    "title": "AI-Based Advanced Approaches and Dry Eye Disease Detection Based on Multi-Source Evidence: Cases, Applications, Issues, and Future Directions",
    "keywords": [
      "artificial intelligence (ai),",
      "dry eye disease (ded) detection,",
      "ophthalmology,",
      "multi-source evidence"
    ],
    "abstract": "This study explores the potential of Artificial Intelligence (AI) in early screening and prognosis of Dry Eye Disease (DED), aiming to enhance the accuracy of therapeutic approaches for eye-care practitioners. Despite the promising opportunities, challenges such as diverse diagnostic evidence, complex etiology, and interdisciplinary knowledge integration impede the interpretability, reliability, and applicability of AI-based DED detection methods. The research conducts a comprehensive review of datasets, diagnostic evidence, and standards, as well as advanced algorithms in AI-based DED detection over the past five years. The DED diagnostic methods are categorized into three groups based on their relationship with AI techniques: (1) those with ground truth and/or comparable standards, (2) potential AI-based methods with significant advantages, and (3) supplementary methods for AI-based DED detection. The study proposes suggested DED detection standards, the combination of multiple diagnostic evidence, and future research directions to guide further investigations. Ultimately, the research contributes to the advancement of ophthalmic disease detection by providing insights into knowledge foundations, advanced methods, challenges, and potential future perspectives, emphasizing the significant role of AI in both academic and practical aspects of ophthalmology."
  },
  {
    "title": "Interpretable Detection of Malicious Behavior in Windows Portable Executables Using Multi-Head 2D Transformers",
    "keywords": [
      "malware,",
      "windows protable executable (pe),",
      "machine learning,",
      "vision transformers"
    ],
    "abstract": "Windows malware is becoming an increasingly pressing problem as the amount of malware continues to grow and more sensitive information is stored on systems. One of the major challenges in tackling this problem is the complexity of malware analysis, which requires expertise from human analysts. Recent developments in machine learning have led to the creation of deep models for malware detection. However, these models often lack transparency, making it difficult to understand the reasoning behind the model’s decisions, otherwise known as the black-box problem. To address these limitations, this paper presents a novel model for malware detection, utilizing vision transformers to analyze the Operation Code (OpCode) sequences of more than 350000 Windows portable executable malware samples from real-world datasets. The model achieves a high accuracy of 0.9864, not only surpassing the previous results but also providing valuable insights into the reasoning behind the classification. Our model is able to pinpoint specific instructions that lead to malicious behavior in malware samples, aiding human experts in their analysis and driving further advancements in the field. We report our findings and show how causality can be established between malicious code and actual classification by a deep learning model, thus opening up this black-box problem for deeper analysis."
  },
  {
    "title": "Unstructured Big Data Threat Intelligence Parallel Mining Algorithm",
    "keywords": [
      "unstructured big data mining,",
      "parallel deep forest,",
      "multi-label classification algorithm,",
      "threat intelligence"
    ],
    "abstract": "To efficiently mine threat intelligence from the vast array of open-source cybersecurity analysis reports on the web, we have developed the Parallel Deep Forest-based Multi-Label Classification (PDFMLC) algorithm. Initially, open-source cybersecurity analysis reports are collected and converted into a standardized text format. Subsequently, five tactics category labels are annotated, creating a multi-label dataset for tactics classification. Addressing the limitations of low execution efficiency and scalability in the sequential deep forest algorithm, our PDFMLC algorithm employs broadcast variables and the Lempel-Ziv-Welch (LZW) algorithm, significantly enhancing its acceleration ratio. Furthermore, our proposed PDFMLC algorithm incorporates label mutual information from the established dataset as input features. This captures latent label associations, significantly improving classification accuracy. Finally, we present the PDFMLC-based Threat Intelligence Mining (PDFMLC-TIM) method. Experimental results demonstrate that the PDFMLC algorithm exhibits exceptional node scalability and execution efficiency. Simultaneously, the PDFMLC-TIM method proficiently conducts text classification on cybersecurity analysis reports, extracting tactics entities to construct comprehensive threat intelligence. As a result, successfully formatted STIX2.1 threat intelligence is established."
  },
  {
    "title": "Call for Papers Special Issue on Challenges and Opportunities in Retrieval-Augmented Generation for LLMs: Techniques, Trends, and Applications",
    "keywords": [],
    "abstract": ""
  },
  {
    "title": "Editorial",
    "keywords": [],
    "abstract": ""
  },
  {
    "title": "AI/ML Enabled Automation System for Software Defined Disaggregated Open Radio Access Networks: Transforming Telecommunication Business",
    "keywords": [
      "open radio access networks (o-ran),",
      "flexible radio access network intelligent controller (fric),",
      "reinforcement learning (rl),",
      "external applications (xapps),",
      "artificial intelligence (ai),",
      "machine learning (ml), sixth generation (6g)"
    ],
    "abstract": "Open Air Interface (OAI) alliance recently introduced a new disaggregated Open Radio Access Networks (O-RAN) framework for next generation telecommunications and networks. This disaggregated architecture is open, automated, software defined, virtual, and supports the latest advanced technologies like Artificial Intelligence (AI) Machine Learning (AI/ML). This novel intelligent architecture enables programmers to design and customize automated applications according to the business needs and to improve quality of service in fifth generation (5G) and Beyond 5G (B5G). Its disaggregated and multivendor nature gives the opportunity to new startups and small vendors to participate and provide cheap hardware software solutions to keep the market competitive. This paper presents the disaggregated and programmable O-RAN architecture focused on automation, AI/ML services, and applications with Flexible Radio access network Intelligent Controller (FRIC). We schematically demonstrate the reinforcement learning, external applications (xApps), and automation steps to implement this disaggregated O-RAN architecture. The idea of this research paper is to implement an AI/ML enabled automation system for software defined disaggregated O-RAN, which monitors, manages, and performs AI/ML-related services, including the model deployment, optimization, inference, and training."
  },
  {
    "title": "Enhancing Telemarketing Success Using Ensemble-Based Online Machine Learning",
    "keywords": [
      "telemarketing,",
      "machine learning,",
      "imbalanced dataset,",
      "oversampling,",
      "ensemble model,",
      "online learning"
    ],
    "abstract": "Telemarketing is a well-established marketing approach to offering products and services to prospective customers. The effectiveness of such an approach, however, is highly dependent on the selection of the appropriate consumer base, as reaching uninterested customers will induce annoyance and consume costly enterprise resources in vain while missing interested ones. The introduction of business intelligence and machine learning models can positively influence the decision-making process by predicting the potential customer base, and the existing literature in this direction shows promising results. However, the selection of influential features and the construction of effective learning models for improved performance remain a challenge. Furthermore, from the modelling perspective, the class imbalance nature of the training data, where samples with unsuccessful outcomes highly outnumber successful ones, further compounds the problem by creating biased and inaccurate models. Additionally, customer preferences are likely to change over time due to various reasons, and/or a fresh group of customers may be targeted for a new product or service, necessitating model retraining which is not addressed at all in existing works. A major challenge in model retraining is maintaining a balance between stability (retaining older knowledge) and plasticity (being receptive to new information). To address the above issues, this paper proposes an ensemble machine learning model with feature selection and oversampling techniques to identify potential customers more accurately. A novel online learning method is proposed for model retraining when new samples are available over time. This newly introduced method equips the proposed approach to deal with dynamic data, leading to improved readiness of the proposed model for practical adoption, and is a highly useful addition to the literature. Extensive experiments with real-world data show that the proposed approach achieves excellent results in all cases (e.g., 98.6% accuracy in classifying customers) and outperforms recent competing models in the literature by a considerable margin of 3% on a widely used dataset."
  },
  {
    "title": "ROBO-SPOT: Detecting Robocalls by Understanding User Engagement and Connectivity Graph",
    "keywords": [
      "social network analysis,",
      "reputation,",
      "spam over internet technology (spit),",
      "unwanted calls,",
      "robo-callers,",
      "telephone network"
    ],
    "abstract": "Robo or unsolicited calls have become a persistent issue in telecommunication networks, posing significant challenges to individuals, businesses, and regulatory authorities. These calls not only trick users into disclosing their private and financial information, but also affect their productivity through unwanted phone ringing. A proactive approach to identify and block such unsolicited calls is essential to protect users and service providers from potential harm. Therein, this paper proposes a solution to identify robo-callers in the telephony network utilising a set of novel features to evaluate the trustworthiness of callers in a network. The trust score of the callers is then used along with machine learning models to classify them as legitimate or robo-caller. We use a large anonymized dataset (call detailed records) from a large telecommunication provider containing more than 1 billion records collected over 10 days. We have conducted extensive evaluation demonstrating that the proposed approach achieves high accuracy and detection rate whilst minimizing the error rate. Specifically, the proposed features when used collectively achieve a true-positive rate of around 97% with a false-positive rate of less than 0.01%."
  },
  {
    "title": "E-Commerce Fraud Detection Based on Machine Learning Techniques: Systematic Literature Review",
    "keywords": [
      "e-commerce,",
      "fraud detection,",
      "machine learning (ml),",
      "systematic review,",
      "organized retail fraud"
    ],
    "abstract": "The e-commerce industry’s rapid growth, accelerated by the COVID-19 pandemic, has led to an alarming increase in digital fraud and associated losses. To establish a healthy e-commerce ecosystem, robust cyber security and anti-fraud measures are crucial. However, research on fraud detection systems has struggled to keep pace due to limited real-world datasets. Advances in artificial intelligence, Machine Learning (ML), and cloud computing have revitalized research and applications in this domain. While ML and data mining techniques are popular in fraud detection, specific reviews focusing on their application in e-commerce platforms like eBay and Facebook are lacking depth. Existing reviews provide broad overviews but fail to grasp the intricacies of ML algorithms in the e-commerce context. To bridge this gap, our study conducts a systematic literature review using the Preferred Reporting Items for Systematic reviews and Meta-Analysis (PRISMA) methodology. We aim to explore the effectiveness of these techniques in fraud detection within digital marketplaces and the broader e-commerce landscape. Understanding the current state of the literature and emerging trends is crucial given the rising fraud incidents and associated costs. Through our investigation, we identify research opportunities and provide insights to industry stakeholders on key ML and data mining techniques for combating e-commerce fraud. Our paper examines the research on these techniques as published in the past decade. Employing the PRISMA approach, we conducted a content analysis of 101 publications, identifying research gaps, recent techniques, and highlighting the increasing utilization of artificial neural networks in fraud detection within the industry."
  },
  {
    "title": "An Adaptive Scalable Data Pipeline for Multiclass Attack Classification in Large-Scale IoT Networks",
    "keywords": [
      "internet of things (iot),",
      "apache spark,",
      "apache kafka,",
      "mongodb,",
      "streaming,",
      "concept drift"
    ],
    "abstract": "The current large-scale Internet of Things (IoT) networks typically generate high-velocity network traffic streams. Attackers use IoT devices to create botnets and launch attacks, such as DDoS, Spamming, Cryptocurrency mining, Phishing, etc. The service providers of large-scale IoT networks need to set up a data pipeline to collect the vast network traffic data from the IoT devices, store it, analyze it, and report the malicious IoT devices and types of attacks. Further, the attacks originating from IoT devices are dynamic, as attackers launch one kind of attack at one time and another kind of attack at another time. The number of attacks and benign instances also vary from time to time. This phenomenon of change in attack patterns is called concept drift. Hence, the attack detection system must learn continuously from the ever-changing real-time attack patterns in large-scale IoT network traffic. To meet this requirement, in this work, we propose a data pipeline with Apache Kafka, Apache Spark structured streaming, and MongoDB that can adapt to the ever-changing attack patterns in real time and classify attacks in large-scale IoT networks. When concept drift is detected, the proposed system retrains the classifier with the instances that cause the drift and a representative subsample instances from the previous training of the model. The proposed approach is evaluated with the latest dataset, IoT23, which consists of benign and several attack instances from various IoT devices. Attack classification accuracy is improved from 97.8% to 99.46% by the proposed system. The training time of distributed random forest algorithm is also studied by varying the number of cores in Apache Spark environment."
  },
  {
    "title": "KeyEE: Enhancing Low-Resource Generative Event Extraction with Auxiliary Keyword Sub-Prompt",
    "keywords": [
      "natural language processing,",
      "event extraction (ee),",
      "multi-prompt learning (mpl),",
      "low-resource"
    ],
    "abstract": "Event Extraction (EE) is a key task in information extraction, which requires high-quality annotated data that are often costly to obtain. Traditional classification-based methods suffer from low-resource scenarios due to the lack of label semantics and fine-grained annotations. While recent approaches have endeavored to address EE through a more data-efficient generative process, they often overlook event keywords, which are vital for EE. To tackle these challenges, we introduce KeyEE, a multi-prompt learning strategy that improves low-resource event extraction by Event Keywords Extraction(EKE). We suggest employing an auxiliary EKE sub-prompt and concurrently training both EE and EKE with a shared pre-trained language model. With the auxiliary sub-prompt, KeyEE learns event keywords knowledge implicitly, thereby reducing the dependence on annotated data. Furthermore, we investigate and analyze various EKE sub-prompt strategies to encourage further research in this area. Our experiments on benchmark datasets ACE2005 and ERE show that KeyEE achieves significant improvement in low-resource settings and sets new state-of-the-art results."
  },
  {
    "title": "Call for Papers Special Issue on Data-Driven Spatial and Temporal Anomaly Detection",
    "keywords": [],
    "abstract": ""
  },
  {
    "title": "Limits of Depth: Over-Smoothing and Over-Squashing in GNNs",
    "keywords": [
      "graph neural networks (gnns),",
      "learning on graphs,",
      "over-smoothing,",
      "over-squashing,",
      "isotropic-gnns,",
      "anisotropic-gnns"
    ],
    "abstract": "Graph Neural Networks (GNNs) have become a widely used tool for learning and analyzing data on graph structures, largely due to their ability to preserve graph structure and properties via graph representation learning. However, the effect of depth on the performance of GNNs, particularly isotropic and anisotropic models, remains an active area of research. This study presents a comprehensive exploration of the impact of depth on GNNs, with a focus on the phenomena of over-smoothing and the bottleneck effect in deep graph neural networks. Our research investigates the tradeoff between depth and performance, revealing that increasing depth can lead to over-smoothing and a decrease in performance due to the bottleneck effect. We also examine the impact of node degrees on classification accuracy, finding that nodes with low degrees can pose challenges for accurate classification. Our experiments use several benchmark datasets and a range of evaluation metrics to compare isotropic and anisotropic GNNs of varying depths, also explore the scalability of these models. Our findings provide valuable insights into the design of deep GNNs and offer potential avenues for future research to improve their performance."
  },
  {
    "title": "Molecular Generation and Optimization of Molecular Properties Using a Transformer Model",
    "keywords": [
      "molecular optimization,",
      "transformer,",
      "matched molecular pairs (mmps),",
      "logd,",
      "solubility"
    ],
    "abstract": "Generating novel molecules to satisfy specific properties is a challenging task in modern drug discovery, which requires the optimization of a specific objective based on satisfying chemical rules. Herein, we aim to optimize the properties of a specific molecule to satisfy the specific properties of the generated molecule. The Matched Molecular Pairs (MMPs), which contain the source and target molecules, are used herein, and logD and solubility are selected as the optimization properties. The main innovative work lies in the calculation related to a specific transformer from the perspective of a matrix dimension. Threshold intervals and state changes are then used to encode logD and solubility for subsequent tests. During the experiments, we screen the data based on the proportion of heavy atoms to all atoms in the groups and select 12365, 1503, and 1570 MMPs as the training, validation, and test sets, respectively. Transformer models are compared with the baseline models with respect to their abilities to generate molecules with specific properties. Results show that the transformer model can accurately optimize the source molecules to satisfy specific properties."
  },
  {
    "title": "Attention-Based CNN Fusion Model for Emotion Recognition During Walking Using Discrete Wavelet Transform on EEG and Inertial Signals",
    "keywords": [
      "walking,",
      "multi-modal fusion,",
      "virtual reality,",
      "emotion recognition,",
      "discrete wavelet transform,",
      "attention mechanism"
    ],
    "abstract": "Walking as a unique biometric tool conveys important information for emotion recognition. Individuals in different emotional states exhibit distinct walking patterns. For this purpose, this paper proposes a novel approach to recognizing emotion during walking using electroencephalogram (EEG) and inertial signals. Accurate recognition of emotion is achieved by training in an end-to-end deep learning fashion and taking into account multi-modal fusion. Subjects wear virtual reality head-mounted display (VR-HMD) equipment to immerse in strong emotions during walking. VR environment shows excellent imitation and experience ability, which plays an important role in awakening and changing emotions. In addition, the multi-modal signals acquired from EEG and inertial sensors are separately represented as virtual emotion images by discrete wavelet transform (DWT). These serve as input to the attention-based convolutional neural network (CNN) fusion model. The designed network structure is simple and lightweight while integrating the channel attention mechanism to extract and enhance features. To effectively improve the performance of the recognition system, the proposed decision fusion algorithm combines Critic method and majority voting strategy to determine the weight values that affect the final decision results. An investigation is made on the effect of diverse mother wavelet types and wavelet decomposition levels on model performance which indicates that the 2.2-order reverse biorthogonal (rbio2.2) wavelet with two-level decomposition has the best recognition performance. Comparative experiment results show that the proposed method outperforms other existing state-of-the-art works with an accuracy of 98.73%."
  },
  {
    "title": "A Survey on Event Tracking in Social Media Data Streams",
    "keywords": [
      "event detection (ed),",
      "event propagation,",
      "event evolution,",
      "social networks"
    ],
    "abstract": "Social networks are inevitable parts of our daily life, where an unprecedented amount of complex data corresponding to a diverse range of applications are generated. As such, it is imperative to conduct research on social events and patterns from the perspectives of conventional sociology to optimize services that originate from social networks. Event tracking in social networks finds various applications, such as network security and societal governance, which involves analyzing data generated by user groups on social networks in real time. Moreover, as deep learning techniques continue to advance and make important breakthroughs in various fields, researchers are using this technology to progressively optimize the effectiveness of Event Detection (ED) and tracking algorithms. In this regard, this paper presents an in-depth comprehensive review of the concept and methods involved in ED and tracking in social networks. We introduce mainstream event tracking methods, which involve three primary technical steps: ED, event propagation, and event evolution. Finally, we introduce benchmark datasets and evaluation metrics for ED and tracking, which allow comparative analysis on the performance of mainstream methods. Finally, we present a comprehensive analysis of the main research findings and existing limitations in this field, as well as future research prospects and challenges."
  },
  {
    "title": "PURP: A Scalable System for Predicting Short-Term Urban TrafficFlow Based on License Plate Recognition Data",
    "keywords": [
      "traffic flow prediction,",
      "k-nearest neighbor (knn),",
      "license plate recognition (lpr) data,",
      "spatio-temporal context"
    ],
    "abstract": "Accurate and efficient urban traffic flow prediction can help drivers identify road traffic conditions in real-time, consequently helping them avoid congestion and accidents to a certain extent. However, the existing methods for real-time urban traffic flow prediction focus on improving the model prediction accuracy or efficiency while ignoring the training efficiency, which results in a prediction system that lacks the scalability to integrate real-time traffic flow into the training procedure. To conduct accurate and real-time urban traffic flow prediction while considering the latest historical data and avoiding time-consuming online retraining, herein, we propose a scalable system for Predicting short-term URban traffic flow in real-time based on license Plate recognition data (PURP). First, to ensure prediction accuracy, PURP constructs the spatio-temporal contexts of traffic flow prediction from License Plate Recognition (LPR) data as effective characteristics. Subsequently, to utilize the recent data without retraining the model online, PURP uses the nonparametric method k-Nearest Neighbor (namely KNN) as the prediction framework because the KNN can efficiently identify the top-k most similar spatio-temporal contexts and make predictions based on these contexts without time-consuming model retraining online. The experimental results show that PURP retains strong prediction efficiency as the prediction period increases."
  },
  {
    "title": "Call for Papers Special Issue on Big Data Computing for Cyber Physical Social Intelligence",
    "keywords": [],
    "abstract": ""
  },
  {
    "title": "Building a High-Performance Graph Storage on Top of Tree-Structured Key-Value Stores",
    "keywords": [
      "graph database,",
      "high-performance,",
      "graph storage"
    ],
    "abstract": "Graph databases have gained widespread adoption in various industries and have been utilized in a range of applications, including financial risk assessment, commodity recommendation, and data lineage tracking. While the principles and design of these databases have been the subject of some investigation, there remains a lack of comprehensive examination of aspects such as storage layout, query language, and deployment. The present study focuses on the design and implementation of graph storage layout, with a particular emphasis on tree-structured key-value stores. We also examine different design choices in the graph storage layer and present our findings through the development of TuGraph, a highly efficient single-machine graph database that significantly outperforms well-known Graph DataBase Management System (GDBMS). Additionally, TuGraph demonstrates superior performance in the Linked Data Benchmark Council (LDBC) Social Network Benchmark (SNB) interactive benchmark."
  },
  {
    "title": "Call for Papers Special Issue on Challenges and Opportunities in Biomedical Big Data Analysis: From Large Language Models to Clinical Applications",
    "keywords": [],
    "abstract": ""
  },
  {
    "title": "QAR Data Imputation Using Generative Adversarial Network with Self-Attention Mechanism",
    "keywords": [
      "multivariate time series,",
      "data imputation,",
      "self-attention,",
      "generative adversarial network (gan)"
    ],
    "abstract": "Quick Access Recorder (QAR), an important device for storing data from various flight parameters, contains a large amount of valuable data and comprehensively records the real state of the airline flight. However, the recorded data have certain missing values due to factors, such as weather and equipment anomalies. These missing values seriously affect the analysis of QAR data by aeronautical engineers, such as airline flight scenario reproduction and airline flight safety status assessment. Therefore, imputing missing values in the QAR data, which can further guarantee the flight safety of airlines, is crucial. QAR data also have multivariate, multiprocess, and temporal features. Therefore, we innovatively propose the imputation models A-AEGAN (“A” denotes attention mechanism, “AE” denotes autoencoder, and “GAN” denotes generative adversarial network) and SA-AEGAN (“SA” denotes self-attentive mechanism) for missing values of QAR data, which can be effectively applied to QAR data. Specifically, we apply an innovative generative adversarial network to impute missing values from QAR data. The improved gated recurrent unit is then introduced as the neural unit of GAN, which can successfully capture the temporal relationships in QAR data. In addition, we modify the basic structure of GAN by using an autoencoder as the generator and a recurrent neural network as the discriminator. The missing values in the QAR data are imputed by using the adversarial relationship between generator and discriminator. We introduce an attention mechanism in the autoencoder to further improve the capability of the proposed model to capture the features of QAR data. Attention mechanisms can maintain the correlation among QAR data and improve the capability of the model to impute missing data. Furthermore, we improve the proposed model by integrating a self-attention mechanism to further capture the relationship between different parameters within the QAR data. Experimental results on real datasets demonstrate that the model can reasonably impute the missing values in QAR data with excellent results."
  },
  {
    "title": "Multi-Smart Meter Data Encryption Scheme Basedon Distributed Differential Privacy",
    "keywords": [
      "smart grid,",
      "homomorphic encryption,",
      "data aggregation,",
      "differential privacy,",
      "cloud computing"
    ],
    "abstract": "Under the general trend of the rapid development of smart grids, data security and privacy are facing serious challenges; protecting the privacy data of single users under the premise of obtaining user-aggregated data has attracted widespread attention. In this study, we propose an encryption scheme on the basis of differential privacy for the problem of user privacy leakage when aggregating data from multiple smart meters. First, we use an improved homomorphic encryption method to realize the encryption aggregation of users’ data. Second, we propose a double-blind noise addition protocol to generate distributed noise through interaction between users and a cloud platform to prevent semi-honest participants from stealing data by colluding with one another. Finally, the simulation results show that the proposed scheme can encrypt the transmission of multi-intelligent meter data under the premise of satisfying the differential privacy mechanism. Even if an attacker has enough background knowledge, the security of the electricity information of one another can be ensured."
  },
  {
    "title": "Cell Consistency Evaluation Method Based on Multiple Unsupervised Learning Algorithms",
    "keywords": [
      "battery consistency,",
      "charging segment data,",
      "unsupervised learning"
    ],
    "abstract": "Unsupervised learning algorithms can effectively solve sample imbalance. To address battery consistency anomalies in new energy vehicles, we adopt a variety of unsupervised learning algorithms to evaluate and predict the battery consistency of three vehicles using charging fragment data from actual operating conditions. We extract battery-related features, such as the mean of maximum difference, standard deviation, and entropy of batteries and then apply principal component analysis to reduce the dimensionality and record the amount of preserved information. We then build models through a collection of unsupervised learning algorithms for the anomaly detection of cell consistency faults. We also determine whether unsupervised and supervised learning algorithms can address the battery consistency problem and document the parameter tuning process. In addition, we compare the prediction effectiveness of charging and discharging features modeled individually and in combination, determine the choice of charging and discharging features to be modeled in combination, and visualize the multidimensional data for fault detection. Experimental results show that the unsupervised learning algorithm is effective in visualizing and predicting vehicle core conformance faults, and can accurately predict faults in real time. The “distance+boxplot” algorithm shows the best performance with a prediction accuracy of 80%, a recall rate of 100%, and an F1 of 0.89. The proposed approach can be applied to monitor battery consistency faults in real time and reduce the possibility of disasters arising from consistency faults."
  },
  {
    "title": "Gender-Based Analysis of User Reactions to Facebook Posts",
    "keywords": [
      "profiling,",
      "knowledge extraction,",
      "data mining,",
      "emotion mining,",
      "social media,",
      "data crawling,",
      "facebook reactions,",
      "gender"
    ],
    "abstract": "Online Social Networks (OSNs) are based on the sharing of different types of information and on various interactions (comments, reactions, and sharing). One of these important actions is the emotional reaction to the content. The diversity of reaction types available on Facebook (namely FB) enables users to express their feelings, and its traceability creates and enriches the users’ emotional identity in the virtual world. This paper is based on the analysis of 119875012 FB reactions (Like, Love, Haha, Wow, Sad, Angry, Thankful, and Pride) made at multiple levels (publications, comments, and sub-comments) to study and classify the users’ emotional behavior, visualize the distribution of different types of reactions, and analyze the gender impact on emotion generation. All of these can be achieved by addressing these research questions: who reacts the most? Which emotion is the most expressed?"
  },
  {
    "title": "Incremental Data Stream Classification with Adaptive Multi-Task Multi-View Learning",
    "keywords": [
      "data stream classification,",
      "mobile sensors,",
      "multi-task multi-view learning,",
      "incremental learning"
    ],
    "abstract": "With the enhancement of data collection capabilities, massive streaming data have been accumulated in numerous application scenarios. Specifically, the issue of classifying data streams based on mobile sensors can be formalized as a multi-task multi-view learning problem with a specific task comprising multiple views with shared features collected from multiple sensors. Existing incremental learning methods are often single-task single-view, which cannot learn shared representations between relevant tasks and views. An adaptive multi-task multi-view incremental learning framework for data stream classification called MTMVIS is proposed to address the above challenges, utilizing the idea of multi-task multi-view learning. Specifically, the attention mechanism is first used to align different sensor data of different views. In addition, MTMVIS uses adaptive Fisher regularization from the perspective of multi-task multi-view learning to overcome catastrophic forgetting in incremental learning. Results reveal that the proposed framework outperforms state-of-the-art methods based on the experiments on two different datasets with other baselines."
  },
  {
    "title": "Identification of Proteins and Genes Associated with Hedgehog Signaling Pathway Involved in Neoplasm Formation Using Text-Mining Approach",
    "keywords": [
      "text-mining,",
      "data mining,",
      "hedgehog pathway,",
      "neoplastic processes,",
      "enrichment analysis,",
      "pathology molecular mechanisms"
    ],
    "abstract": "Analysis of molecular mechanisms that lead to the development of various types of tumors is essential for biology and medicine, because it may help to find new therapeutic opportunities for cancer treatment and cure including personalized treatment approaches. One of the pathways known to be important for the development of neoplastic diseases and pathological processes is the Hedgehog signaling pathway that normally controls human embryonic development. Systematic accumulation of various types of biological data, including interactions between proteins, regulation of genes transcription, proteomics, and metabolomics experiments results, allows the application of computational analysis of these big data for identification of key molecular mechanisms of certain diseases and pathologies and promising therapeutic targets. The aim of this study is to develop a computational approach for revealing associations between human proteins and genes interacting with the Hedgehog pathway components, as well as for identifying their roles in the development of various types of tumors. We automatically collect sets of abstract texts from the NCBI PubMed bibliographic database. For recognition of the Hedgehog pathway proteins and genes and neoplastic diseases we use a dictionary-based named entity recognition approach, while for all other proteins and genes machine learning method is used. For association extraction, we develop a set of semantic rules. We complete the results of the text analysis with the gene set enrichment analysis. The identified key pathways that may influence the Hedgehog pathway and their roles in tumor development are then verified using the information in the literature."
  },
  {
    "title": "Multi-Scale Feature Fusion Model for Bridge Appearance Defect Detection",
    "keywords": [
      "defect detection,",
      "multi-scale feature fusion (mff),",
      "region of interest (roi) alignment,",
      "lightweight network"
    ],
    "abstract": "Although the Faster Region-based Convolutional Neural Network (Faster R-CNN) model has obvious advantages in defect recognition, it still cannot overcome challenging problems, such as time-consuming, small targets, irregular shapes, and strong noise interference in bridge defect detection. To deal with these issues, this paper proposes a novel Multi-scale Feature Fusion (MFF) model for bridge appearance disease detection. First, the Faster R-CNN model adopts Region Of Interest (ROI) pooling, which omits the edge information of the target area, resulting in some missed detections and inaccuracies in both detecting and localizing bridge defects. Therefore, this paper proposes an MFF based on regional feature Aggregation (MFF-A), which reduces the missed detection rate of bridge defect detection and improves the positioning accuracy of the target area. Second, the Faster R-CNN model is insensitive to small targets, irregular shapes, and strong noises in bridge defect detection, which results in a long training time and low recognition accuracy. Accordingly, a novel Lightweight MFF (namely MFF-L）model for bridge appearance defect detection using a lightweight network EfficientNetV2 and a feature pyramid network is proposed, which fuses multi-scale features to shorten the training speed and improve recognition accuracy. Finally, the effectiveness of the proposed method is evaluated on the bridge disease dataset and public computational fluid dynamic dataset."
  },
  {
    "title": "IoTDQ: An Industrial IoT Data Analysis Library for Apache IoTDB",
    "keywords": [
      "industrial big data,",
      "data quality,",
      "data mining and analytics"
    ],
    "abstract": "There is a growing demand for time series data analysis in industry areas. Apache IoTDB is a time series database designed for the Internet of Things (IoT) with enhanced storage and I/O performance. With User-Defined Functions (UDF) provided, computation for time series can be executed on Apache IoTDB directly. To satisfy most of the common requirements in industrial time series analysis, we create a UDF library, IoTDQ, on Apache IoTDB. This library integrates stream computation functions on data quality analysis, data profiling, anomaly detection, data repairing, etc. IoTDQ enables users to conduct a wide range of analyses, such as monitoring, error diagnosis, equipment reliability analysis. It provides a framework for users to examine IoT time series with data quality problems. Experiments show that IoTDQ keeps the same level of performance compared to mainstream alternatives, and shortens I/O consumption for Apache IoTDB users."
  },
  {
    "title": "Discriminatively Constrained Semi-Supervised Multi-View Nonnegative Matrix Factorization with Graph Regularization",
    "keywords": [
      "multi-view,",
      "semi-supervised clustering,",
      "discriminative information,",
      "geometric information,",
      "feature normalizing strategy"
    ],
    "abstract": "Nonnegative Matrix Factorization (NMF) is one of the most popular feature learning technologies in the field of machine learning and pattern recognition. It has been widely used and studied in the multi-view clustering tasks because of its effectiveness. This study proposes a general semi-supervised multi-view nonnegative matrix factorization algorithm. This algorithm incorporates discriminative and geometric information on data to learn a better-fused representation, and adopts a feature normalizing strategy to align the different views. Two specific implementations of this algorithm are developed to validate the effectiveness of the proposed framework: Graph regularization based Discriminatively Constrained Multi-View Nonnegative Matrix Factorization (GDCMVNMF) and Extended Multi-View Constrained Nonnegative Matrix Factorization (ExMVCNMF). The intrinsic connection between these two specific implementations is discussed, and the optimization based on multiply update rules is presented. Experiments on six datasets show that the effectiveness of GDCMVNMF and ExMVCNMF outperforms several representative unsupervised and semi-supervised multi-view NMF approaches."
  },
  {
    "title": "Call for Papers—Special Issue on Edge AI Empowered Giant Model Training",
    "keywords": [],
    "abstract": ""
  },
  {
    "title": "Towards Privacy-Aware and Trustworthy Data Sharing Using Blockchain for Edge Intelligence",
    "keywords": [
      "edge intelligence,",
      "blockchain,",
      "personalized privacy preservation,",
      "differential privacy,",
      "smart healthcare networks (shns)"
    ],
    "abstract": "The popularization of intelligent healthcare devices and big data analytics significantly boosts the development of Smart Healthcare Networks (SHNs). To enhance the precision of diagnosis, different participants in SHNs share health data that contain sensitive information. Therefore, the data exchange process raises privacy concerns, especially when the integration of health data from multiple sources (linkage attack) results in further leakage. Linkage attack is a type of dominant attack in the privacy domain, which can leverage various data sources for private data mining. Furthermore, adversaries launch poisoning attacks to falsify the health data, which leads to misdiagnosing or even physical damage. To protect private health data, we propose a personalized differential privacy model based on the trust levels among users. The trust is evaluated by a defined community density, while the corresponding privacy protection level is mapped to controllable randomized noise constrained by differential privacy. To avoid linkage attacks in personalized differential privacy, we design a noise correlation decoupling mechanism using a Markov stochastic process. In addition, we build the community model on a blockchain, which can mitigate the risk of poisoning attacks during differentially private data transmission over SHNs. Extensive experiments and analysis on real-world datasets have testified the proposed model, and achieved better performance compared with existing research from perspectives of privacy protection and effectiveness."
  },
  {
    "title": "K-Means Clustering with Local Distance Privacy",
    "keywords": [
      "k-means clustering,",
      "local differential privacy,",
      "data analysis"
    ],
    "abstract": "With the development of information technology, a mass of data are generated every day. Collecting and analysing these data help service providers improve their services and gain an advantage in the fierce market competition. K-means clustering has been widely used for cluster analysis in real life. However, these analyses are based on users’ data, which disclose users’ privacy. Local differential privacy has attracted lots of attention recently due to its strong privacy guarantee and has been applied for clustering analysis. However, existing K-means clustering methods with local differential privacy protection cannot get an ideal clustering result due to the large amount of noise introduced to the whole dataset to ensure the privacy guarantee. To solve this problem, we propose a novel method that provides local distance privacy for users who participate in the clustering analysis. Instead of making the users’ records in-distinguish from each other in high-dimensional space, we map the user’s record into a one-dimensional distance space and make the records in such a distance space not be distinguished from each other. To be specific, we generate a noisy distance first and then synthesize the high-dimensional data record. We propose a Bounded Laplace Method (BLM) and a Cluster Indistinguishable Method (CIM) to sample such a noisy distance, which satisfies the local differential privacy guarantee and local dE-privacy guarantee, respectively. Furthermore, we introduce a way to generate synthetic data records in high-dimensional space. Our experimental evaluation results show that our methods outperform the traditional methods significantly."
  },
  {
    "title": "A Clinical Data Analysis Based Diagnostic Systems for Heart Disease Prediction Using Ensemble Method",
    "keywords": [
      "artificial intelligence,",
      "support vector machine,",
      "logistic regression,",
      "cleveland dataset,",
      "supervised algorithm,",
      "human sensing"
    ],
    "abstract": "The correct diagnosis of heart disease can save lives, while the incorrect diagnosis can be lethal. The UCI machine learning heart disease dataset compares the results and analyses of various machine learning approaches, including deep learning. We used a dataset with 13 primary characteristics to carry out the research. Support vector machine and logistic regression algorithms are used to process the datasets, and the latter displays the highest accuracy in predicting coronary disease. Python programming is used to process the datasets. Multiple research initiatives have used machine learning to speed up the healthcare sector. We also used conventional machine learning approaches in our investigation to uncover the links between the numerous features available in the dataset and then used them effectively in anticipation of heart infection risks. Using the accuracy and confusion matrix has resulted in some favorable outcomes. To get the best results, the dataset contains certain unnecessary features that are dealt with using isolation logistic regression and Support Vector Machine (SVM) classification."
  },
  {
    "title": "Editorial",
    "keywords": [],
    "abstract": ""
  },
  {
    "title": "AI-Based Hybrid Models for Predicting Loan Risk in the Banking Sector",
    "keywords": [
      "artificial intelligence (ai),",
      "machine learning (ml),",
      "loan prediction,",
      "support vector machine (svm),",
      "random forest (rf),",
      "accuracy"
    ],
    "abstract": "Every real-world scenario is now digitally replicated in order to reduce paperwork and human labor costs. Machine Learning (ML) models are also being used to make predictions in these applications. Accurate forecasting requires knowledge of these machine learning models and their distinguishing features. The datasets we use as input for each of these different types of ML models, yielding different results. The choice of an ML model for a dataset is critical. A loan risk model is used to show how ML models for a dataset can be linked together. The purpose of this study is to look into how we could use machine learning to quantify or forecast mortgage credit risk. This phrase refers to the process of evaluating massive amounts of data in order to derive useful information for making decisions in a variety of fields. If credit risk is considered, a method based on an examination of what caused and how mortgage credit risk affected credit defaults during the still-current economic crisis of 2021 will be tried. Various approaches to credit risk calculation will be examined, ranging from the most basic to the most complex. In addition, we will conduct a case study on a sample of mortgage loans and compare the results of three different analytical approaches, logistic regression, decision tree, and gradient boost to see which one produced the most commercially useful insights."
  },
  {
    "title": "A PLS-SEM Based Approach: Analyzing Generation Z Purchase Intention Through Facebook’s Big Data",
    "keywords": [
      "facebook,",
      "enjoyment,",
      "credibility,",
      "peer communication,",
      "attitude,",
      "intentions to purchase"
    ],
    "abstract": "The objective of this paper is to provide a better rendition of Generation Z purchase intentions of retail products through Facebook. The study gyrated around the favorable attitude formation of Generation Z translating into intentions to purchase retail products through Facebook. The role of antecedents of attitude, namely enjoyment, credibility, and peer communication was also explored. The main purpose was to analyze the F-commerce pervasiveness (retail purchases through Facebook) among Generation Z in India and how could it be materialized effectively. A conceptual façade was proposed after trotting out germane and urbane literature. The study focused exclusively on Generation Z population. The data were statistically analyzed using partial least squares structural equation modelling. The study found the proposed conceptual model had a high prediction power of Generation Z intentions to purchase retail products through Facebook verifying the materialization of F-commerce. Enjoyment, credibility, and peer communication were proved to be good predictors of attitude (R2=0.589) and furthermore attitude was found to be a stellar antecedent to purchase intentions (R2=0.540)."
  },
  {
    "title": "VDCM: A Data Collection Mechanism for Crowd Sensing in Vehicular Ad Hoc Networks",
    "keywords": [
      "vehicular ad hoc networks (vanets),",
      "crowd sensing,",
      "data collection,",
      "data aggregation security"
    ],
    "abstract": "With the rapid development of mobile devices, aggregation security and efficiency topics are more important than past in crowd sensing. When collecting large-scale vehicle-provided data, the data transmitted via autonomous networks are publicly accessible to all attackers, which increases the risk of vehicle exposure. So we need to ensure data aggregation security. In addition, low aggregation efficiency will lead to insufficient sensing data, making the data unable to provide data mining services. Aiming at the problem of aggregation security and efficiency in large-scale data collection, this article proposes a data collection mechanism (VDCM) for crowd sensing in vehicular ad hoc networks (VANETs). The mechanism includes two mechanism assumptions and selects appropriate methods to reduce consumption. It selects sub mechanism 1 when there exist very few vehicles or the coalition cannot be formed, otherwise selects sub mechanism 2. Single aggregation is used to collect data in sub mechanism 1. In sub mechanism 2, cooperative vehicles are selected by using coalition formation strategy and auction cooperation agreement, and multi aggregation is used to collect data. Two sub mechanisms use Paillier homomorphic encryption technology to ensure the security of data aggregation. In addition, mechanism supplements the data update and scoring steps to increase the amount of available data. The performance analysis shows that the mechanism proposed in this paper can safely aggregate data and reduce consumption. The simulation results indicate that the proposed mechanism reduces time consumption and increases the amount of available data compared with existing mechanisms."
  },
  {
    "title": "Elastic Optimization for Stragglers in Edge Federated Learning",
    "keywords": [
      "edge computing,",
      "federated learning,",
      "distributed machine learning,",
      "regularization,",
      "stragglers"
    ],
    "abstract": "To fully exploit enormous data generated by intelligent devices in edge computing, edge federated learning (EFL) is envisioned as a promising solution. The distributed collaborative training in EFL deals with delay and privacy issues compared to traditional centralized model training. However, the existence of straggling devices, responding slow to servers, degrades model performance. We consider data heterogeneity from two aspects: high dimensional data generated at edge devices where the number of features is greater than that of observations and the heterogeneity caused by partial device participation. With large number of features, computation overhead on the devices increases, causing edge devices to become stragglers. And incorporation of partial training results causes gradients to be diverged which further exaggerates when more training is performed to reach local optima. In this paper, we introduce elastic optimization methods for stragglers due to data heterogeneity in edge federated learning. Specifically, we define the problem of stragglers in EFL. Then, we formulate an optimization problem to be solved at edge devices. We customize a benchmark algorithm, FedAvg, to obtain a new elastic optimization algorithm (FedEN) which is applied in local training of edge devices. FedEN mitigates stragglers by having a balance between lasso and ridge penalization thereby generating sparse model updates and enforcing parameters as close as to local optima. We have evaluated the proposed model on MNIST and CIFAR-10 datasets. Simulated experiments demonstrate that our approach improves run time training performance by achieving average accuracy with less communication rounds. The results confirm the improved performance of our approach over benchmark algorithms."
  },
  {
    "title": "Personalized Federated Learning for Heterogeneous Residential Load Forecasting",
    "keywords": [
      "load forecasting,",
      "personalized federated learning,",
      "differential privacy"
    ],
    "abstract": "Accurate load forecasting is critical for electricity production, transmission, and maintenance. Deep learning (DL) model has replaced other classical models as the most popular prediction models. However, the deep prediction model requires users to provide a large amount of private electricity consumption data, which has potential privacy risks. Edge nodes can federally train a global model through aggregation using federated learning (FL). As a novel distributed machine learning (ML) technique, it only exchanges model parameters without sharing raw data. However, existing forecasting methods based on FL still face challenges from data heterogeneity and privacy disclosure. Accordingly, we propose a user-level load forecasting system based on personalized federated learning (PFL) to address these issues. The obtained personalized model outperforms the global model on local data. Further, we introduce a novel differential privacy (DP) algorithm in the proposed system to provide an additional privacy guarantee. Based on the principle of generative adversarial network (GAN), the algorithm achieves the balance between privacy and prediction accuracy throughout the game. We perform simulation experiments on the real-world dataset and the experimental results show that the proposed system can comply with the requirement for accuracy and privacy in real load forecasting scenarios."
  },
  {
    "title": "Replication-Based Query Management for Resource Allocation Using Hadoop and MapReduce over Big Data",
    "keywords": [
      "big data,",
      "hadoop,",
      "mapreduce,",
      "resource allocation,",
      "query management"
    ],
    "abstract": "We live in an age where everything around us is being created. Data generation rates are so scary, creating pressure to implement costly and straightforward data storage and recovery processes. MapReduce model functionality is used for creating a cluster parallel, distributed algorithm, and large datasets. The MapReduce strategy from Hadoop helps develop a community of non-commercial use to offer a new algorithm for resolving such problems for commercial applications as expected from this working algorithm with insights as a result of disproportionate or discriminatory Hadoop cluster results. Expected results are obtained in the work and the exam conducted under this job; many of them are scheduled to set schedules, match matrices’ data positions, clustering before determining to click, and accurate mapping and internal reliability to be closed together to avoid running and execution times. Mapper output and proponents have been implemented, and the map has been used to reduce the function. The execution input key/value pair and output key/value pair have been set. This paper focuses on evaluating this technique for the efficient retrieval of large volumes of data. The technique allows for capabilities to inform a massive database of information, from storage and indexing techniques to the distribution of queries, scalability, and performance in heterogeneous environments. The results show that the proposed work reduces the data processing time by 30%."
  },
  {
    "title": "Diagnosis and Detection of Alzheimer’s Disease Using Learning Algorithm",
    "keywords": [
      "alzheimer’s disease,",
      "deep learning,",
      "random forest,",
      "xgboost"
    ],
    "abstract": "In Computer-Aided Detection (CAD) brain disease classification is a vital issue. Alzheimer’s Disease (AD) and brain tumors are the primary reasons of death. The studies of these diseases are carried out by Magnetic Resonance Imaging (MRI), Positron Emission Tomography (PET), and Computed Tomography (CT) scans which require expertise to understand the modality. The disease is the most prevalent in the elderly and can be fatal in its later stages. The result can be determined by calculating the mini-mental state exam score, following which the MRI scan of the brain is successful. Apart from that, various classification algorithms, such as machine learning and deep learning, are useful for diagnosing MRI scans. However, they do have some limitations in terms of accuracy. This paper proposes some insightful pre-processing methods that significantly improve the classification performance of these MRI images. Additionally, it reduced the time it took to train the model of various pre-existing learning algorithms. A dataset was obtained from Alzheimer’s Disease Neurological Initiative (ADNI) and converted from a 4D format to a 2D format. Selective clipping, grayscale image conversion, and histogram equalization techniques were used to pre-process the images. After pre-processing, we proposed three learning algorithms for AD classification, that is random forest, XGBoost, and Convolution Neural Networks (CNN). Results are computed on dataset and show that it outperformed with exiting work in terms of accuracy is 97.57% and sensitivity is 97.60%."
  },
  {
    "title": "τSQWRL: A TSQL2-Like Query Language for Temporal Ontologies Generated from JSON Big Data",
    "keywords": [
      "temporal big data,",
      "temporal ontology,",
      "temporal query language,",
      "temporal owl 2 from temporal json (τjowl ),",
      "semantic query-enhanced web rule language (sqwrl),",
      "temporal sql2 (tsql2),",
      "internet of healthcare things (ioht)"
    ],
    "abstract": "Temporal ontologies allow to represent not only concepts, their properties, and their relationships, but also time-varying information through explicit versioning of definitions or through the four-dimensional perdurantist view. They are widely used to formally represent temporal data semantics in several applications belonging to different fields (e.g., Semantic Web, expert systems, knowledge bases, big data, and artificial intelligence). They facilitate temporal knowledge representation and discovery, with the support of temporal data querying and reasoning. However, there is no standard or consensual temporal ontology query language. In a previous work, we have proposed an approach named τJOWL (temporal OWL 2 from temporal JSON, where OWL 2 stands for \"OWL 2 Web Ontology Language\" and JSON stands for \"JavaScript Object Notation\" ). τJOWL allows (1) to automatically build a temporal OWL 2 ontology of data, following the Closed World Assumption (CWA), from temporal JSON-based big data, and (2) to manage its incremental maintenance accommodating their evolution, in a temporal and multi-schema-version environment. In this paper, we propose a temporal ontology query language for τJOWL, named τSQWRL (temporal SQWRL), designed as a temporal extension of the ontology query language—Semantic Query-enhanced Web Rule Language (SQWRL). The new language has been inspired by the features of the consensual temporal query language TSQL2 (Temporal SQL2), well known in the temporal (relational) database community. The aim of the proposal is to enable and simplify the task of retrieving any desired ontology version or of specifying any (complex) temporal query on time-varying ontologies generated from time-varying big data. Some examples, in the Internet of Healthcare Things (IoHT) domain, are provided to motivate and illustrate our proposal."
  },
  {
    "title": "Artificial Intelligence Methods Applied to Catalytic Cracking Processes",
    "keywords": [
      "intelligent optimization algorithm,",
      "neural networks,",
      "catalytic cracking,",
      "lumped kinetics"
    ],
    "abstract": "Fluidic Catalytic Cracking (FCC) is a complex petrochemical process affected by many highly non-linear and interrelated factors. Product yield analysis, flue gas desulfurization prediction, and abnormal condition warning are several key research directions in FCC. This paper will sort out the relevant research results of the existing Artificial Intelligence (AI) algorithms applied to the analysis and optimization of catalytic cracking processes, with a view to providing help for the follow-up research. Compared with the traditional mathematical mechanism method, the AI method can effectively solve the difficulties in FCC process modeling, such as high-dimensional, nonlinear, strong correlation, and large delay. AI methods applied in product yield analysis build models based on massive data. By fitting the functional relationship between operating variables and products, the excessive simplification of mechanism model can be avoided, resulting in high model accuracy. AI methods applied in flue gas desulfurization can be usually divided into two stages: modeling and optimization. In the modeling stage, data-driven methods are often used to build the system model or rule base; In the optimization stage, heuristic search or reinforcement learning methods can be applied to find the optimal operating parameters based on the constructed model or rule base. AI methods, including data-driven and knowledge-driven algorithms, are widely used in the abnormal condition warning. Knowledge-driven methods have advantages in interpretability and generalization, but disadvantages in construction difficulty and prediction recall. While the data-driven methods are just the opposite. Thus, some studies combine these two methods to obtain better results."
  },
  {
    "title": "An Ensemble Learning Based Intrusion Detection Model for Industrial IoT Security",
    "keywords": [
      "industrial internet of things (iiot),",
      "isolation forest,",
      "intrusion detection dystem (ids),",
      "intrusion,",
      "pearson’s correlation coefficient (pcc),",
      "random forest"
    ],
    "abstract": "Industrial Internet of Things (IIoT) represents the expansion of the Internet of Things (IoT) in industrial sectors. It is designed to implicate embedded technologies in manufacturing fields to enhance their operations. However, IIoT involves some security vulnerabilities that are more damaging than those of IoT. Accordingly, Intrusion Detection Systems (IDSs) have been developed to forestall inevitable harmful intrusions. IDSs survey the environment to identify intrusions in real time. This study designs an intrusion detection model exploiting feature engineering and machine learning for IIoT security. We combine Isolation Forest (IF) with Pearson’s Correlation Coefficient (PCC) to reduce computational cost and prediction time. IF is exploited to detect and remove outliers from datasets. We apply PCC to choose the most appropriate features. PCC and IF are applied exchangeably (PCCIF and IFPCC). The Random Forest (RF) classifier is implemented to enhance IDS performances. For evaluation, we use the Bot-IoT and NF-UNSW-NB15-v2 datasets. RF-PCCIF and RF-IFPCC show noteworthy results with 99.98% and 99.99% Accuracy (ACC) and 6.18 s and 6.25 s prediction time on Bot-IoT, respectively. The two models also score 99.30% and 99.18% ACC and 6.71 s and 6.87 s prediction time on NF-UNSW-NB15-v2, respectively. Results prove that our designed model has several advantages and higher performance than related models."
  },
  {
    "title": "Copy-Move Forgery Verification in Images Using Local Feature Extractors and Optimized Classifiers",
    "keywords": [
      "copy move forgery detection,",
      "image authentication,",
      "passive image forgery detection,",
      "blind forgery detection"
    ],
    "abstract": "Passive image forgery detection methods that identify forgeries without prior knowledge have become a key research focus. In copy-move forgery, the assailant intends to hide a portion of an image by pasting other portions of the same image. The detection of such manipulations in images has great demand in legal evidence, forensic investigation, and many other fields. The paper aims to present copy-move forgery detection algorithms with the help of advanced feature descriptors, such as local ternary pattern, local phase quantization, local Gabor binary pattern histogram sequence, Weber local descriptor, and local monotonic pattern, and classifiers such as optimized support vector machine and optimized NBC. The proposed algorithms can classify an image efficiently as either copy-move forged or authenticated, even if the test image is subjected to attacks such as JPEG compression, scaling, rotation, and brightness variation. CoMoFoD, CASIA, and MICC datasets and a combination of CoMoFoD and CASIA datasets images are used to quantify the performance of the proposed algorithms. The proposed algorithms are more efficient than state-of-the-art algorithms even though the suspected image is post-processed."
  },
  {
    "title": "An Intelligent Heuristic Manta-Ray Foraging Optimization and Adaptive Extreme Learning Machine for Hand Gesture Image Recognition",
    "keywords": [
      "hand gesture recognition,",
      "skin color detection,",
      "morphological operations,",
      "multifaceted feature extraction (mfe) model,",
      "heuristic manta-ray foraging optimization (hmfo),",
      "adaptive extreme learning machine (aelm)"
    ],
    "abstract": "The development of hand gesture recognition systems has gained more attention in recent days, due to its support of modern human-computer interfaces. Moreover, sign language recognition is mainly developed for enabling communication between deaf and dumb people. In conventional works, various image processing techniques like segmentation, optimization, and classification are deployed for hand gesture recognition. Still, it limits the major problems of inefficient handling of large dimensional datasets and requires more time consumption, increased false positives, error rate, and misclassification outputs. Hence, this research work intends to develop an efficient hand gesture image recognition system by using advanced image processing techniques. During image segmentation, skin color detection and morphological operations are performed for accurately segmenting the hand gesture portion. Then, the Heuristic Manta-ray Foraging Optimization (HMFO) technique is employed for optimally selecting the features by computing the best fitness value. Moreover, the reduced dimensionality of features helps to increase the accuracy of classification with a reduced error rate. Finally, an Adaptive Extreme Learning Machine (AELM) based classification technique is employed for predicting the recognition output. During results validation, various evaluation measures have been used to compare the proposed model’s performance with other classification approaches."
  },
  {
    "title": "Impact of Mobile Technology and Use of Big Data in Physics Education During Coronavirus Lockdown",
    "keywords": [
      "coronavirus,",
      "mobile technology,",
      "smartphone,",
      "physics education,",
      "remote learning"
    ],
    "abstract": "The speed of spread of Coronavirus Disease 2019 led to global lockdowns and disruptions in the academic sector. The study examined the impact of mobile technology on physics education during lockdowns. Data were collected through an online survey and later evaluated using regression tools, frequency, and an analysis of variance (ANOVA). The findings revealed that the usage of mobile technology had statistically significant effects on physics instructors’ and students’ academics during the coronavirus lockdown. Most of the participants admitted that the use of mobile technologies such as smartphones, laptops, PDAs, Zoom, mobile apps, etc. were very useful and helpful for continued education amid the pandemic restrictions. Online teaching is very effective during lock-down with smartphones and laptops on different platforms. The paper brings the limelight to the growing power of mobile technology solutions in physics education."
  },
  {
    "title": "Call for Papers——Special Issue on Intelligent Network Video Advances Based on Transformers",
    "keywords": [],
    "abstract": ""
  },
  {
    "title": "Extraction of Fetal Electrocardiogram by Combining Deep Learning and SVD-ICA-NMF Methods",
    "keywords": [
      "fetal electrocardiogram,",
      "convolutional neural network (cnn),",
      "deep learning (dl),",
      "feature extraction"
    ],
    "abstract": "This paper deals with detecting fetal electrocardiogram FECG signals from single-channel abdominal lead. It is based on the Convolutional Neural Network (CNN) combined with advanced mathematical methods, such as Independent Component Analysis (ICA), Singular Value Decomposition (SVD), and a dimension-reduction technique like Nonnegative Matrix Factorization (NMF). Due to the highly disproportionate frequency of the fetus’s heart rate compared to the mother’s, the time-scale representation clearly distinguishes the fetal electrical activity in terms of energy. Furthermore, we can disentangle the various components of fetal ECG, which serve as inputs to the CNN model to optimize the actual FECG signal, denoted by FECGr, which is recovered using the SVD-ICA process. The findings demonstrate the efficiency of this innovative approach, which may be deployed in real-time."
  },
  {
    "title": "Cloud-Based Intrusion Detection Approach Using Machine Learning Techniques",
    "keywords": [
      "cloud security,",
      "anomaly detection,",
      "features engineering,",
      "random forest"
    ],
    "abstract": "Cloud computing (CC) is a novel technology that has made it easier to access network and computer resources on demand such as storage and data management services. In addition, it aims to strengthen systems and make them useful. Regardless of these advantages, cloud providers suffer from many security limits. Particularly, the security of resources and services represents a real challenge for cloud technologies. For this reason, a set of solutions have been implemented to improve cloud security by monitoring resources, services, and networks, then detect attacks. Actually, intrusion detection system (IDS) is an enhanced mechanism used to control traffic within networks and detect abnormal activities. This paper presents a cloud-based intrusion detection model based on random forest (RF) and feature engineering. Specifically, the RF classifier is obtained and integrated to enhance accuracy (ACC) of the proposed detection model. The proposed model approach has been evaluated and validated on two datasets and gives 98.3% ACC and 99.99% ACC using Bot-IoT and NSL-KDD datasets, respectively. Consequently, the obtained results present good performances in terms of ACC, precision, and recall when compared to the recent related works."
  },
  {
    "title": "Human Action Recognition Using Difference of Gaussian and Difference of Wavelet",
    "keywords": [
      "human action recognition,",
      "difference of gaussian,",
      "difference of wavelet,",
      "linear discriminant analysis,",
      "weizmann,",
      "ucf 11,",
      "accuracy"
    ],
    "abstract": "Human Action Recognition (HAR) attempts to recognize the human action from images and videos. The major challenge in HAR is the design of an action descriptor that makes the HAR system robust for different environments. A novel action descriptor is proposed in this study, based on two independent spatial and spectral filters. The proposed descriptor uses a Difference of Gaussian (DoG) filter to extract scale-invariant features and a Difference of Wavelet (DoW) filter to extract spectral information. To create a composite feature vector for a particular test action picture, the Discriminant of Guassian (DoG) and Difference of Wavelet (DoW) features are combined. Linear Discriminant Analysis (LDA), a widely used dimensionality reduction technique, is also used to eliminate duplicate data. Finally, a closest neighbor method is used to classify the dataset. Weizmann and UCF 11 datasets were used to run extensive simulations of the suggested strategy, and the accuracy assessed after the simulations were run on Weizmann datasets for five-fold cross validation is shown to perform well. The average accuracy of DoG + DoW is observed as 83.6635% while the average accuracy of Discrinanat of Guassian (DoG) and Difference of Wavelet (DoW) is observed as 80.2312% and 77.4215%, respectively. The average accuracy measured after the simulation of proposed methods over UCF 11 action dataset for five-fold cross validation DoG + DoW is observed as 62.5231% while the average accuracy of Difference of Guassian (DoG) and Difference of Wavelet (DoW) is observed as 60.3214% and 58.1247%, respectively. From the above accuracy observations, the accuracy of Weizmann is high compared to the accuracy of UCF 11, hence verifying the effectiveness in the improvisation of recognition accuracy."
  },
  {
    "title": "Editorial",
    "keywords": [],
    "abstract": ""
  },
  {
    "title": "A Machine Learning Based Framework for a Stage-Wise Classification of Date Palm White Scale Disease",
    "keywords": [
      "precision agriculture,",
      "machine learning,",
      "ensemble learning,",
      "feature extraction,",
      "date palm,",
      "diseases"
    ],
    "abstract": "Date palm production is critical to oasis agriculture, owing to its economic importance and nutritional advantages. Numerous diseases endanger this precious tree, putting a strain on the economy and environment. White scale Parlatoria blanchardi is a damaging bug that degrades the quality of dates. When an infestation reaches a specific degree, it might result in the tree’s death. To counter this threat, precise detection of infected leaves and its infestation degree is important to decide if chemical treatment is necessary. This decision is crucial for farmers who wish to minimize yield losses while preserving production quality. For this purpose, we propose a feature extraction and machine learning (ML) technique based framework for classifying the stages of infestation by white scale disease (WSD) in date palm trees by investigating their leaflets images. 80 gray level co-occurrence matrix (GLCM) texture features and 9 hue, saturation, and value (HSV) color moments features are extracted from both grayscale and color images of the used dataset. To classify the WSD into its four classes (healthy, low infestation degree, medium infestation degree, and high infestation degree), two types of ML algorithms were tested; classical machine learning methods, namely, support vector machine (SVM) and k-nearest neighbors (KNN), and ensemble learning methods such as random forest (RF) and light gradient boosting machine (LightGBM). The ML models were trained and evaluated using two datasets: the first is composed of the extracted GLCM features only, and the second combines GLCM and HSV descriptors. The results indicate that SVM classifier outperformed on combined GLCM and HSV features with an accuracy of 98.29%. The proposed framework could be beneficial to the oasis agricultural community in terms of early detection of date palm white scale disease (DPWSD) and assisting in the adoption of preventive measures to protect both date palm trees and crop yield."
  },
  {
    "title": "Denoising Graph Inference Network for Document-Level Relation Extraction",
    "keywords": [
      "relation eextraction (re),",
      "document-level,",
      "denoising,",
      "linguistic knowledge,",
      "attention mechanism"
    ],
    "abstract": "Relation Extraction (RE) is to obtain a predefined relation type of two entities mentioned in a piece of text, e.g., a sentence-level or a document-level text. Most existing studies suffer from the noise in the text, and necessary pruning is of great importance. The conventional sentence-level RE task addresses this issue by a denoising method using the shortest dependency path to build a long-range semantic dependency between entity pairs. However, this kind of denoising method is scarce in document-level RE. In this work, we explicitly model a denoised document-level graph based on linguistic knowledge to capture various long-range semantic dependencies among entities. We first formalize a Syntactic Dependency Tree forest (SDT-forest) by introducing the syntax and discourse dependency relation. Then, the Steiner tree algorithm extracts a mention-level denoised graph, Steiner Graph (SG), removing linguistically irrelevant words from the SDT-forest. We then devise a slide residual attention to highlight word-level evidence on text and SG. Finally, the classification is established on the SG to infer the relations of entity pairs. We conduct extensive experiments on three public datasets. The results evidence that our method is beneficial to establish long-range semantic dependency and can improve the classification performance with longer texts."
  },
  {
    "title": "Efficacy of Bluetooth-Based Data Collection for Road Traffic Analysis and Visualization Using Big Data Analytics",
    "keywords": [
      "bluetooth scanners,",
      "big data,",
      "visualization,",
      "speed,",
      "sensors"
    ],
    "abstract": "Effective management of daily road traffic is a huge challenge for traffic personnel. Urban traffic management has come a long way from manual control to artificial intelligence techniques. Still real-time adaptive traffic control is an unfulfilled dream due to lack of low cost and easy to install traffic sensor with real-time communication capability. With increasing number of on-board Bluetooth devices in new generation automobiles, these devices can act as sensors to convey the traffic information indirectly. This paper presents the efficacy of road-side Bluetooth scanners for traffic data collection and big-data analytics to process the collected data to extract traffic parameters. Extracted information and analysis are presented through visualizations and tables. All data analytics and visualizations are carried out off-line in R Studio environment. Reliability aspects of the collected and processed data are also investigated. Higher speed of traffic in one direction owing to the geometry of the road is also established through data analysis. Increased penetration of smart phones and fitness bands in day to day use is also established through the device type of the data collected. The results of this work can be used for regular data collection compared to the traditional road surveys carried out annually or bi-annually. It is also found that compared to previous studies published in the literature, the device penetration rate and sample size found in this study are quite high and very encouraging. This is a novel work in literature, which would be quite useful for effective road traffic management in future."
  },
  {
    "title": "DeepRetention: A Deep Learning Approach for Intron Retention Detection",
    "keywords": [
      "alternative splicing (as),",
      "intron retention (ir),",
      "intronic reads distribution pattern,",
      "rna-seq"
    ],
    "abstract": "As the least understood mode of alternative splicing, Intron Retention (IR) is emerging as an interesting area and has attracted more and more attention in the field of gene regulation and disease studies. Existing methods detect IR exclusively based on one or a few predefined metrics describing local or summarized characteristics of retained introns. These metrics are not able to describe the pattern of sequencing depth of intronic reads, which is an intuitive and informative characteristic of retained introns. We hypothesize that incorporating the distribution pattern of intronic reads will improve the accuracy of IR detection. Here we present DeepRetention, a novel approach for IR detection by modeling the pattern of sequencing depth of introns. Due to the lack of a gold standard dataset of IR, we first compare DeepRetention with two state-of-the-art methods, i.e. iREAD and IRFinder, on simulated RNA-seq datasets with retained introns. The results show that DeepRetention outperforms these two methods. Next, DeepRetention performs well when it is applied to third-generation long-read RNA-seq data, while IRFinder and iREAD are not applicable to detecting IR from the third-generation sequencing data. Further, we show that IRs predicted by DeepRetention are biologically meaningful on an RNA-seq dataset from Alzheimer’s Disease (AD) samples. The differential IRs are found to be significantly associated with AD based on statistical evaluation of an AD-specific functional gene network. The parent genes of differential IRs are enriched in AD-related functions. In summary, DeepRetention detects IR from a new angle of view, providing a valuable tool for IR analysis."
  },
  {
    "title": "Cloud-Based Software Development Lifecycle: A Simplified Algorithm for Cloud Service Provider Evaluation with Metric Analysis",
    "keywords": [
      "cloud-based software development life cycle (sdlc),",
      "cloud evaluation,",
      "parameter-ranking priority level weightage (prplw) algorithm,",
      "cloud service providers,",
      "software engineering"
    ],
    "abstract": "At present, hundreds of cloud vendors in the global market provide various services based on a customer’s requirements. All cloud vendors are not the same in terms of the number of services, infrastructure availability, security strategies, cost per customer, and reputation in the market. Thus, software developers and organizations face a dilemma when choosing a suitable cloud vendor for their developmental activities. Thus, there is a need to evaluate various cloud service providers (CSPs) and platforms before choosing a suitable vendor. Already existing solutions are either based on simulation tools as per the requirements or evaluated concerning the quality of service attributes. However, they require more time to collect data, simulate and evaluate the vendor. The proposed work compares various CSPs in terms of major metrics, such as establishment, services, infrastructure, tools, pricing models, market share, etc., based on the comparison, parameter ranking, and weightage allocated. Furthermore, the parameters are categorized depending on the priority level. The weighted average is calculated for each CSP, after which the values are sorted in descending order. The experimental results show the unbiased selection of CSPs based on the chosen parameters. The proposed parameter-ranking priority level weightage (PRPLW) algorithm simplifies the selection of the best-suited cloud vendor in accordance with the requirements of software development."
  },
  {
    "title": "Medical Knowledge Graph: Data Sources, Construction, Reasoning, and Applications",
    "keywords": [
      "medical knowledge graph,",
      "knowledge graph construction,",
      "knowledge reasoning,",
      "intelligent medical applications,",
      "intelligent healthcare"
    ],
    "abstract": "Medical knowledge graphs (MKGs) are the basis for intelligent health care, and they have been in use in a variety of intelligent medical applications. Thus, understanding the research and application development of MKGs will be crucial for future relevant research in the biomedical field. To this end, we offer an in-depth review of MKG in this work. Our research begins with the examination of four types of medical information sources, knowledge graph creation methodologies, and six major themes for MKG development. Furthermore, three popular models of reasoning from the viewpoint of knowledge reasoning are discussed. A reasoning implementation path (RIP) is proposed as a means of expressing the reasoning procedures for MKG. In addition, we explore intelligent medical applications based on RIP and MKG and classify them into nine major types. Finally, we summarize the current state of MKG research based on more than 130 publications and future challenges and opportunities."
  },
  {
    "title": "EScope: Effective Event Validation for IoT Systems Based on State Correlation",
    "keywords": [
      "internet of things (iot),",
      "event spoofing,",
      "event fingerprint,",
      "correlation analysis"
    ],
    "abstract": "Typical Internet of Things (IoT) systems are event-driven platforms, in which smart sensing devices sense or subscribe to events (device state changes), and react according to the preconfigured trigger-action logic, as known as, automation rules. \"Events\" are essential elements to perform automatic control in an IoT system. However, events are not always trustworthy. Sensing fake event notifications injected by attackers (called event spoofing attack) can trigger sensitive actions through automation rules without involving authorized users. Existing solutions verify events via \"event fingerprints\" extracted by surrounding sensors. However, if a system has homogeneous sensors that have strong correlations among them, traditional threshold-based methods may cause information redundancy and noise amplification, consequently, decreasing the checking accuracy. Aiming at this, in this paper, we propose \"EScope\" , an effective event validation approach to check the authenticity of system events based on device state correlation. EScope selects informative and representative sensors using an Neural-Network-based (NN-based) sensor selection component and extracts a verification sensor set for event validation. We evaluate our approach using an existing dataset provided by Peeves. The experiment results demonstrate that EScope achieves an average 67% sensor amount reduction on 22 events compared with the existing work, and increases the event spoofing detection accuracy."
  },
  {
    "title": "Security and Privacy in Metaverse: A Comprehensive Survey",
    "keywords": [
      "metaverse,",
      "cybersecurity,",
      "privacy protection,",
      "cyber infrastructure,",
      "extended reality"
    ],
    "abstract": "Metaverse describes a new shape of cyberspace and has become a hot-trending word since 2021. There are many explanations about what Meterverse is and attempts to provide a formal standard or definition of Metaverse. However, these definitions could hardly reach universal acceptance. Rather than providing a formal definition of the Metaverse, we list four must-have characteristics of the Metaverse: socialization, immersive interaction, real world-building, and expandability. These characteristics not only carve the Metaverse into a novel and fantastic digital world, but also make it suffer from all security/privacy risks, such as personal information leakage, eavesdropping, unauthorized access, phishing, data injection, broken authentication, insecure design, and more. This paper first introduces the four characteristics, then the current progress and typical applications of the Metaverse are surveyed and categorized into four economic sectors. Based on the four characteristics and the findings of the current progress, the security and privacy issues in the Metaverse are investigated. We then identify and discuss more potential critical security and privacy issues that can be caused by combining the four characteristics. Lastly, the paper also raises some other concerns regarding society and humanity."
  },
  {
    "title": "Survey of Distributed Computing Frameworks for Supporting Big Data Analysis",
    "keywords": [
      "distributed computing frameworks,",
      "big data analysis,",
      "approximate computing,",
      "mapreduce computing model"
    ],
    "abstract": "Distributed computing frameworks are the fundamental component of distributed computing systems. They provide an essential way to support the efficient processing of big data on clusters or cloud. The size of big data increases at a pace that is faster than the increase in the big data processing capacity of clusters. Thus, distributed computing frameworks based on the MapReduce computing model are not adequate to support big data analysis tasks which often require running complex analytical algorithms on extremely big data sets in terabytes. In performing such tasks, these frameworks face three challenges: computational inefficiency due to high I/O and communication costs, non-scalability to big data due to memory limit, and limited analytical algorithms because many serial algorithms cannot be implemented in the MapReduce programming model. New distributed computing frameworks need to be developed to conquer these challenges. In this paper, we review MapReduce-type distributed computing frameworks that are currently used in handling big data and discuss their problems when conducting big data analysis. In addition, we present a non-MapReduce distributed computing framework that has the potential to overcome big data analysis challenges."
  },
  {
    "title": "Semi-Supervised Machine Learning for Fault Detection and Diagnosis of a Rooftop Unit",
    "keywords": [
      "semi-supervised machine learning,",
      "fault classification,",
      "fault detection and diagnostics,",
      "heating, ventilation, and air-conditioning,",
      "data-driven modeling,",
      "energy efficiency"
    ],
    "abstract": "Most heating, ventilation, and air-conditioning (HVAC) systems operate with one or more faults that result in increased energy consumption and that could lead to system failure over time. Today, most building owners are performing reactive maintenance only and may be less concerned or less able to assess the health of the system until catastrophic failure occurs. This is mainly because the building owners do not previously have good tools to detect and diagnose these faults, determine their impact, and act on findings. Commercially available fault detection and diagnostics (FDD) tools have been developed to address this issue and have the potential to reduce equipment downtime, energy costs, maintenance costs, and improve occupant comfort and system reliability. However, many of these tools require an in-depth knowledge of system behavior and thermodynamic principles to interpret the results. In this paper, supervised and semi-supervised machine learning (ML) approaches are applied to datasets collected from an operating system in the field to develop new FDD methods and to help building owners see the value proposition of performing proactive maintenance. The study data was collected from one packaged rooftop unit (RTU) HVAC system running under normal operating conditions at an industrial facility in Connecticut. This paper compares three different approaches for fault classification for a real-time operating RTU using semi-supervised learning, achieving accuracies as high as 95.7% using few-shot learning."
  },
  {
    "title": "Continuous and Discrete Similarity Coefficient for Identifying Essential Proteins Using Gene Expression Data",
    "keywords": [
      "protein-protein interaction (ppi) network,",
      "continuous and discrete similarity coefficient,",
      "essential proteins"
    ],
    "abstract": "Essential proteins play a vital role in biological processes, and the combination of gene expression profiles with Protein-Protein Interaction (PPI) networks can improve the identification of essential proteins. However, gene expression data are prone to significant fluctuations due to noise interference in topological networks. In this work, we discretized gene expression data and used the discrete similarities of the gene expression spectrum to eliminate noise fluctuation. We then proposed the Pearson Jaccard coefficient (PJC) that consisted of continuous and discrete similarities in the gene expression data. Using the graph theory as the basis, we fused the newly proposed similarity coefficient with the existing network topology prediction algorithm at each protein node to recognize essential proteins. This strategy exhibited a high recognition rate and good specificity. We validated the new similarity coefficient PJC on PPI datasets of Krogan, Gavin, and DIP of yeast species and evaluated the results by receiver operating characteristic analysis, jackknife analysis, top analysis, and accuracy analysis. Compared with that of node-based network topology centrality and fusion biological information centrality methods, the new similarity coefficient PJC showed a significantly improved prediction performance for essential proteins in DC, IC, Eigenvector centrality, subgraph centrality, betweenness centrality, closeness centrality, NC, PeC, and WDC. We also compared the PJC coefficient with other methods using the NF-PIN algorithm, which predicts proteins by constructing active PPI networks through dynamic gene expression. The experimental results proved that our newly proposed similarity coefficient PJC has superior advantages in predicting essential proteins."
  },
  {
    "title": "Ultra-Short Wave Communication Squelch Algorithm Based on Deep Neural Network",
    "keywords": [
      "squelch,",
      "gated recurrent unit (gru),",
      "ultra-short wave communication"
    ],
    "abstract": "The squelch problem of ultra-short wave communication under non-stationary noise and low Signal-to-Noise Ratio (SNR) in a complex electromagnetic environment is still challenging. To alleviate the problem, we proposed a squelch algorithm for ultra-short wave communication based on a deep neural network and the traditional energy decision method. The proposed algorithm first predicts the speech existence probability using a three-layer Gated Recurrent Unit (GRU) with the speech banding spectrum as the feature. Then it gets the final squelch result by combining the strength of the signal energy and the speech existence probability. Multiple simulations and experiments are done to verify the robustness and effectiveness of the proposed algorithm. We simulate the algorithm in three situations: the typical Amplitude Modulation (AM) and Frequency Modulation (FM) in the ultra-short wave communication under different SNR environments, the non-stationary burst-like noise environments, and the real received signal of the ultra-short wave radio. The experimental results show that the proposed algorithm performs better than the traditional squelch methods in all the simulations and experiments. In particular, the false alarm rate of the proposed squelch algorithm for non-stationary burst-like noise is significantly lower than that of traditional squelch methods."
  },
  {
    "title": "FingerDTA: A Fingerprint-Embedding Framework for Drug-Target Binding Affinity Prediction",
    "keywords": [
      "drug-target binding affinity,",
      "fingerprint,",
      "new drug discovery"
    ],
    "abstract": "Many efforts have been exerted toward screening potential drugs for targets, and conducting wet experiments remains a laborious and time-consuming approach. Artificial intelligence methods, such as Convolutional Neural Network (CNN), are widely used to facilitate new drug discovery. Owing to the structural limitations of CNN, features extracted from this method are local patterns that lack global information. However, global information extracted from the whole sequence and local patterns extracted from the special domain can influence the drug-target affinity. A fusion of global information and local patterns can construct neural network calculations closer to actual biological processes. This paper proposes a Fingerprint-embedding framework for Drug-Target binding Affinity prediction (FingerDTA), which uses CNN to extract local patterns and utilize fingerprints to characterize global information. These fingerprints are generated on the basis of the whole sequence of drugs or targets. Furthermore, FingerDTA achieves comparable performance on Davis and KIBA data sets. In the case study of screening potential drugs for the spike protein of the coronavirus disease 2019 (COVID-19), 7 of the top 10 drugs have been confirmed potential by literature. Ultimately, the docking experiment demonstrates that FingerDTA can find novel drug candidates for targets. All codes are available at http://lanproxy.biodwhu.cn:9099/mszjaas/FingerDTA.git."
  },
  {
    "title": "Satellite Image Classification Using a Hybrid Manta Ray Foraging Optimization Neural Network",
    "keywords": [
      "radial basis function neural network (rbfnn),",
      "manta ray foraging optimization algorithm (mrfo),",
      "landsat 8,",
      "classification,",
      "change detection,",
      "disaster mitigation,",
      "planning"
    ],
    "abstract": "A semi supervised image classification method for satellite images is proposed in this paper. The satellite images contain enormous data that can be used in various applications. The analysis of the data is a tedious task due to the amount of data and the heterogeneity of the data. Thus, in this paper, a Radial Basis Function Neural Network (RBFNN) trained using Manta Ray Foraging Optimization algorithm (MRFO) is proposed. RBFNN is a three-layer network comprising of input, output, and hidden layers that can process large amounts. The trained network can discover hidden data patterns in unseen data. The learning algorithm and seed selection play a vital role in the performance of the network. The seed selection is done using the spectral indices to further improve the performance of the network. The manta ray foraging optimization algorithm is inspired by the intelligent behaviour of manta rays. It emulates three unique foraging behaviours namelys chain, cyclone, and somersault foraging. The satellite images contain enormous amount of data and thus require exploration in large search space. The spiral movement of the MRFO algorithm enables it to explore large search spaces effectively. The proposed method is applied on pre and post flooding Landsat 8 Operational Land Imager (OLI) images of New Brunswick area. The method was applied to identify and classify the land cover changes in the area induced by flooding. The images are classified using the proposed method and a change map is developed using post classification comparison. The change map shows that a large amount of agricultural area was washed away due to flooding. The measurement of the affected area in square kilometres is also performed for mitigation activities. The results show that post flooding the area covered by water is increased whereas the vegetated area is decreased. The performance of the proposed method is done with existing state-of-the-art methods."
  },
  {
    "title": "A Method for Bio-Sequence Analysis Algorithm Development Based on the PAR Platform",
    "keywords": [
      "partition-and-recur (par),",
      "domain engineering,",
      "biological sequences,",
      "feature model,",
      "component assembly"
    ],
    "abstract": "The problems of biological sequence analysis have great theoretical and practical value in modern bioinformatics. Numerous solving algorithms are used for these problems, and complex similarities and differences exist among these algorithms for the same problem, causing difficulty for researchers to select the appropriate one. To address this situation, combined with the formal partition-and-recur method, component technology, domain engineering, and generic programming, the paper presents a method for the development of a family of biological sequence analysis algorithms. It designs highly trustworthy reusable domain algorithm components and further assembles them to generate specifific biological sequence analysis algorithms. The experiment of the development of a dynamic programming based LCS algorithm family shows the proposed method enables the improvement of the reliability, understandability, and development efficiency of particular algorithms."
  },
  {
    "title": "Deep Convolutional Network Based Machine Intelligence Model for Satellite Cloud Image Classification",
    "keywords": [
      "satellite images,",
      "satellite image classification,",
      "cyclone prediction,",
      "deep convolutional neural network (dcnn),",
      "features,",
      "layers,",
      "down-sampling process"
    ],
    "abstract": "As a huge number of satellites revolve around the earth, a great probability exists to observe and determine the change phenomena on the earth through the analysis of satellite images on a real-time basis. Therefore, classifying satellite images plays strong assistance in remote sensing communities for predicting tropical cyclones. In this article, a classification approach is proposed using Deep Convolutional Neural Network (DCNN), comprising numerous layers, which extract the features through a downsampling process for classifying satellite cloud images. DCNN is trained marvelously on cloud images with an impressive amount of prediction accuracy. Delivery time decreases for testing images, whereas prediction accuracy increases using an appropriate deep convolutional network with a huge number of training dataset instances. The satellite images are taken from the Meteorological & Oceanographic Satellite Data Archival Centre, the organization is responsible for availing satellite cloud images of India and its subcontinent. The proposed cloud image classification shows 94% prediction accuracy with the DCNN framework."
  },
  {
    "title": "Intelligent Segment Routing: Toward Load Balancing with Limited Control Overheads",
    "keywords": [
      "traffic engineering,",
      "segment routing,",
      "bandwidth load balancing,",
      "ant colony optimization"
    ],
    "abstract": "Segment routing has been a novel architecture for traffic engineering in recent years. However, segment routing brings control overheads, i.e., additional packets headers should be inserted. The overheads can greatly reduce the forwarding efficiency for a large network, when segment headers become too long. To achieve the best of two targets, we propose the intelligent routing scheme for traffic engineering (IRTE), which can achieve load balancing with limited control overheads. To achieve optimal performance, we first formulate the problem as a mapping problem that maps different flows to key diversion points. Second, we prove the problem is nondeterministic polynomial (NP)-hard by reducing it to a k-dense subgraph problem. To solve this problem, we develop an ant colony optimization algorithm as improved ant colony optimization (IACO), which is widely used in network optimization problems. We also design the load balancing algorithm with diversion routing (LBA-DR), and analyze its theoretical performance. Finally, we evaluate the IRTE in different real-world topologies, and the results show that the IRTE outperforms traditional algorithms, e.g., the maximum bandwidth is 24.6% lower than that of traditional algorithms when evaluating on BellCanada topology."
  },
  {
    "title": "RF-PSSM: A Combination of Rotation Forest Algorithm and Position-Specific Scoring Matrix for Improved Prediction of Protein-Protein Interactions Between Hepatitis C Virus and Human",
    "keywords": [
      "protein-protein interactions,",
      "hepatitis c virus,",
      "position specific scoring matrix,",
      "two-dimensional principal component analysis,",
      "rotation forest"
    ],
    "abstract": "The identification of hepatitis C virus (HCV) virus-human protein interactions will not only help us understand the molecular mechanisms of related diseases but also be conductive to discovering new drug targets. An increasing number of clinically and experimentally validated interactions between HCV and human proteins have been documented in public databases, facilitating studies based on computational methods. In this study, we proposed a new computational approach, rotation forest position-specific scoring matrix (RF-PSSM), to predict the interactions among HCV and human proteins. In particular, PSSM was used to characterize each protein, two-dimensional principal component analysis (2DPCA) was then adopted for feature extraction of PSSM. Finally, rotation forest (RF) was used to implement classification. The results of various ablation experiments show that on independent datasets, the accuracy and area under curve (AUC) value of RF-PSSM can reach 93.74% and 94.29%, respectively, outperforming almost all cutting-edge research. In addition, we used RF-PSSM to predict 9 human proteins that may interact with HCV protein E1, which can provide theoretical guidance for future experimental studies."
  },
  {
    "title": "Closed-Form Models of Accuracy Loss due to Subsampling in SVD Collaborative Filtering",
    "keywords": [
      "collaborative filtering,",
      "subsampling,",
      "accuracy loss models,",
      "performance loss,",
      "recommendation system,",
      "simulation,",
      "rating matrix,",
      "root mean square error"
    ],
    "abstract": "We postulate and analyze a nonlinear subsampling accuracy loss (SSAL) model based on the root mean square error (RMSE) and two SSAL models based on the mean square error (MSE), suggested by extensive preliminary simulations. The SSAL models predict accuracy loss in terms of subsampling parameters like the fraction of users dropped (FUD) and the fraction of items dropped (FID). We seek to investigate whether the models depend on the characteristics of the dataset in a constant way across datasets when using the SVD collaborative filtering (CF) algorithm. The dataset characteristics considered include various densities of the rating matrix and the numbers of users and items. Extensive simulations and rigorous regression analysis led to empirical symmetrical SSAL models in terms of FID and FUD whose coefficients depend only on the data characteristics. The SSAL models came out to be multi-linear in terms of odds ratios of dropping a user (or an item) vs. not dropping it. Moreover, one MSE deterioration model turned out to be linear in the FID and FUD odds where their interaction term has a zero coefficient. Most importantly, the models are constant in the sense that they are written in closed-form using the considered data characteristics (densities and numbers of users and items). The models are validated through extensive simulations based on 850 synthetically generated primary (pre-subsampling) matrices derived from the 25M MovieLens dataset. Nearly 460 000 subsampled rating matrices were then simulated and subjected to the singular value decomposition (SVD) CF algorithm. Further validation was conducted using the 1M MovieLens and the Yahoo! Music Rating datasets. The models were constant and significant across all 3 datasets."
  },
  {
    "title": "WTASR: Wavelet Transformer for Automatic Speech Recognition of Indian Languages",
    "keywords": [
      "transformer,",
      "wavelet,",
      "automatic speech recognition (asr),",
      "indian language"
    ],
    "abstract": "Automatic speech recognition systems are developed for translating the speech signals into the corresponding text representation. This translation is used in a variety of applications like voice enabled commands, assistive devices and bots, etc. There is a significant lack of efficient technology for Indian languages. In this paper, an wavelet transformer for automatic speech recognition (WTASR) of Indian language is proposed. The speech signals suffer from the problem of high and low frequency over different times due to variation in speech of the speaker. Thus, wavelets enable the network to analyze the signal in multiscale. The wavelet decomposition of the signal is fed in the network for generating the text. The transformer network comprises an encoder decoder system for speech translation. The model is trained on Indian language dataset for translation of speech into corresponding text. The proposed method is compared with other state of the art methods. The results show that the proposed WTASR has a low word error rate and can be used for effective speech recognition for Indian language."
  },
  {
    "title": "Predicted Mean Vote of Subway Car Environment Based on Machine Learning",
    "keywords": [
      "predicted mean vote,",
      "random forest,",
      "variable selection,",
      "thermal comfort"
    ],
    "abstract": "The thermal comfort of passengers in the carriage cannot be ignored. Thus, this research aims to establish a prediction model for the thermal comfort of the internal environment of a subway car and find the optimal input combination in establishing the prediction model of the predicted mean vote (PMV) index. Data-driven modeling utilizes data from experiments and questionnaires conducted in Nanjing Metro. Support vector machine (SVM), decision tree (DT), random forest (RF), and logistic regression (LR) were used to build four models. This research aims to select the most appropriate input variables for the predictive model. All possible combinations of 11 input variables were used to determine the most accurate model, with variable selection for each model comprising 102 350 iterations. In the PMV prediction, the RF model was the best when using the correlation coefficients square (R2) as the evaluation indicator (R2: 0.7680, mean squared error (MSE): 0.2868). The variables include clothing temperature (CT), convective heat transfer coefficient between the surface of the human body and the environment (CHTC), black bulb temperature (BBT), and thermal resistance of clothes (TROC). The RF model with MSE as the evaluation index also had the highest accuracy (R2: 0.7676, MSE: 0.2836). The variables include clothing surface area coefficient (CSAC), CT, BBT, and air velocity (AV). The results show that the RF model can efficiently predict the PMV of the subway car environment."
  },
  {
    "title": "Call for Papers——Special Issue on Role & Impact of Advance Technologies AI, ML, and Big Data in Business and Society",
    "keywords": [],
    "abstract": ""
  },
  {
    "title": "Recommendation System with Biclustering",
    "keywords": [
      "recommendation system (rs),",
      "collaborative filtering (cf),",
      "local pattern,",
      "biclustering,",
      "similarity measure"
    ],
    "abstract": "The massive growth of online commercial data has raised the request for an automatic recommender system to benefit both users and merchants. One of the most frequently used recommendation methods is collaborative filtering, but its accuracy is limited by the sparsity of the rating dataset. Most existing collaborative filtering methods consider all features when calculating user/item similarity and ignore much local information. In collaborative filtering, selecting neighbors and determining users’ similarities are the most important parts. For the selection of better neighbors, this study proposes a novel biclustering method based on modified fuzzy adaptive resonance theory. To reflect the similarity between users, a new measure that considers the effect of the number of users’ common items is proposed. Specifically, the proposed novel biclustering method is first adopted to obtain local similarity and local prediction. Second, item-based collaborative filtering is used to generate global predictions. Finally, the two resultant predictions are fused to obtain a final one. Experiment results demonstrate that the proposed method outperforms state-of-the-art models in terms of several aspects on three benchmark datasets."
  },
  {
    "title": "Predicting Students’ Final Performance Using Artificial Neural Networks",
    "keywords": [
      "data science,",
      "artificial intelligence (ai),",
      "machine learning (ml),",
      "neural networks,",
      "prediction,",
      "recommendation,",
      "high school,",
      "data analysis"
    ],
    "abstract": "Artificial Intelligence (AI) is based on algorithms that allow machines to make decisions for humans. This technology enhances the users’ experience in various ways. Several studies have been conducted in the field of education to solve the problem of student orientation and performance using various Machine Learning (ML) algorithms. The main goal of this article is to predict Moroccan students’ performance in the region of Guelmim Oued Noun using an intelligent system based on neural networks, one of the best data mining techniques that provided us with the best results."
  },
  {
    "title": "Application of Internet of Things in the Health Sector: Toward Minimizing Energy Consumption",
    "keywords": [
      "internet of things (iot),",
      "energy consumption,",
      "cloud computing,",
      "data storage"
    ],
    "abstract": "The Internet of Things (IoT) is currently reflected in the increase in the number of connected objects, that is, devices with their own identity and computing and communication capacities. IoT is recognized as one of the most critical areas for future technologies, gaining worldwide attention. It applies to many areas, where it has achieved success, such as healthcare, where a patient is monitored using nodes and lightweight sensors. However, the powerful functions of IoT in the medical field are based on communication, analysis, processing, and management of data autonomously without any manual intervention, which presents many difficulties, such as energy consumption. However, these issues significantly slow down the development and rapid deployment of this technology. The main causes of wasted energy from connected objects include collisions that occur when two or more nodes send data simultaneously and the leading cause of data retransmission that occurs when a collision occurs or when data are not received correctly due to channel fading. The distance between nodes is one of the factors influencing energy consumption. In this article, we have proposed direct communication between nodes to avoid collision domains, which will help reduce data retransmission. The results show that the distribution can ensure the performance of the system under general conditions compared to the centralization and to the existing works."
  },
  {
    "title": "Influencing Factors and Clustering Characteristics of COVID-19: A Global Analysis",
    "keywords": [
      "data analysis,",
      "extreme random forest regression,",
      "spectral clustering,",
      "hdi,",
      "covid-19"
    ],
    "abstract": "The unprecedented coronavirus disease 2019 (COVID-19) pandemic is still raging (in year 2021) in many countries worldwide. Various response strategies to study the characteristics and distributions of the virus in various regions of the world have been developed to assist in the prevention and control of this epidemic. Descriptive statistics and regression analysis on COVID-19 data from different countries were conducted in this study to compare and evaluate various regression models. Results showed that the extreme random forest regression (ERFR) model had the best performance, and factors such as population density, ozone, median age, life expectancy, and Human Development Index (HDI) were relatively influential on the spread and diffusion of COVID-19 in the ERFR model. In addition, the epidemic clustering characteristics were analyzed through the spectral clustering algorithm. The visualization results of spectral clustering showed that the geographical distribution of global COVID-19 pandemic spread formation was highly clustered, and its clustering characteristics and influencing factors also exhibited some consistency in distribution. This study aims to deepen the understanding of the international community regarding the global COVID-19 pandemic to develop measures for countries worldwide to mitigate potential large-scale outbreaks and improve the ability to respond to such public health emergencies."
  },
  {
    "title": "Editorial",
    "keywords": [],
    "abstract": ""
  },
  {
    "title": "τJOWL: A Systematic Approach to Build and Evolve a Temporal OWL 2 Ontology Based on Temporal JSON Big Data",
    "keywords": [
      "big data,",
      "javascript object notation (json),",
      "json schema,",
      "temporal json,",
      "ontology,",
      "temporal ontology,",
      "τjschema,",
      "τowl"
    ],
    "abstract": "Nowadays, ontologies, which are defined under the OWL 2 Web Ontology Language (OWL 2), are being used in several fields like artificial intelligence, knowledge engineering, and Semantic Web environments to access data, answer queries, or infer new knowledge. In particular, ontologies can be used to model the semantics of big data as an enabling factor for the deployment of intelligent analytics. Big data are being widely stored and exchanged in JavaScript Object Notation (JSON) format, in particular by Web applications. However, JSON data collections lack explicit semantics as they are in general schema-less, which does not allow to efficiently leverage the benefits of big data. Furthermore, several applications require bookkeeping of the entire history of big data changes, for which no support is provided by mainstream Big Data management systems, including Not only SQL (NoSQL) database systems. In this paper, we propose an approach, named τJOWL (temporal OWL 2 from temporal JSON), which allows users (i) to automatically build a temporal OWL 2 ontology of data, following the Closed World Assumption (CWA), from temporal JSON-based big data, and (ii) to manage its incremental maintenance accommodating the evolution of these data, in a temporal and multi-schema environment."
  },
  {
    "title": "Effect of Feature Selection on the Prediction of Direct Normal Irradiance",
    "keywords": [
      "machine learning,",
      "deep learning,",
      "feature importance,",
      "renewable energies,",
      "solar radiation"
    ],
    "abstract": "Solar radiation is capable of producing heat, causing chemical reactions, or generating electricity. Thus, the amount of solar radiation at different times of the day must be determined to design and equip all solar systems. Moreover, it is necessary to have a thorough understanding of different solar radiation components, such as Direct Normal Irradiance (DNI), Diffuse Horizontal Irradiance (DHI), and Global Horizontal Irradiance (GHI). Unfortunately, measurements of solar radiation are not easily accessible for the majority of regions on the globe. This paper aims to develop a set of deep learning models through feature importance algorithms to predict the DNI data. The proposed models are based on historical data of meteorological parameters and solar radiation properties in a specific location of the region of Errachidia, Morocco, from January 1, 2017, to December 31, 2019, with an interval of 60 minutes. The findings demonstrated that feature selection approaches play a crucial role in forecasting of solar radiation accurately when compared with the available data."
  },
  {
    "title": "Call for Papers—Special Issue on Big Data Computing for Internet of Things and Utility and Cloud Computing",
    "keywords": [],
    "abstract": ""
  },
  {
    "title": "Deep Feature Learning for Intrinsic Signature Based Camera Discrimination",
    "keywords": [
      "deep learning,",
      "visual signatures,",
      "camera identification,",
      "convolutional neural networks,",
      "deep feature learning"
    ],
    "abstract": "In this paper we consider the problem of \"end-to-end\" digital camera identification by considering sequence of images obtained from the cameras. The problem of digital camera identification is harder than the problem of identifying its analog counterpart since the process of analog to digital conversion smooths out the intrinsic noise in the analog signal. However it is known that identifying a digital camera is possible by analyzing the camera's intrinsic sensor artifacts that are introduced into the images/videos during the process of photo/video capture. It is known that such methods are computationally intensive requiring expensive pre-processing steps. In this paper we propose an end-to-end deep feature learning framework for identifying cameras using images obtained from them. We conduct experiments using three custom datasets: the first containing two cameras in an indoor environment where each camera may observe different scenes having no overlapping features, the second containing images from four cameras in an outdoor setting but where each camera observes scenes having overlapping features and the third containing images from two cameras observing the same checkerboard pattern in an indoor setting. Our results show that it is possible to capture the intrinsic hardware signature of the cameras using deep feature representations in an end-to-end framework. These deep feature maps can in turn be used to disambiguate the cameras from each another. Our system is end-to-end, requires no complicated pre-processing steps and the trained model is computationally efficient during testing, paving a way to have near instantaneous decisions for the problem of digital camera identification in production environments. Finally we present comparisons against the current state-of-the-art in digital camera identification which clearly establishes the superiority of the end-to-end solution."
  },
  {
    "title": "A Systematic Review Towards Big Data Analytics in Social Media",
    "keywords": [
      "big data,",
      "social media,",
      "big data analytics,",
      "social media analytics,",
      "text analytics,",
      "image analytics,",
      "audio analytics,",
      "video analytics,",
      "predictive analytics,",
      "descriptive analytics,",
      "prescriptive analytics,",
      "diagnostic analytics"
    ],
    "abstract": "The recent advancement in internet 2.0 creates a scope to connect people worldwide using society 2.0 and web 2.0 technologies. This new era allows the consumer to directly connect with other individuals, business corporations, and the government. People are open to sharing opinions, views, and ideas on any topic in different formats out loud. This creates the opportunity to make the \"Big Social Data\" handy by implementing machine learning approaches and social data analytics. This study offers an overview of recent works in social media, data science, and machine learning to gain a wide perspective on social media big data analytics. We explain why social media data are significant elements of the improved data-driven decision-making process. We propose and build the \"Sunflower Model of Big Data\" to define big data and bring it up to date with technology by combining 5 V’s and 10 Bigs. We discover the top ten social data analytics to work in the domain of social media platforms. A comprehensive list of relevant statistical/machine learning methods to implement each of these big data analytics is discussed in this work. \"Text Analytics\" is the most used analytics in social data analysis to date. We create a taxonomy on social media analytics to meet the need and provide a clear understanding. Tools, techniques, and supporting data type are also discussed in this research work. As a result, researchers will have an easier time deciding which social data analytics would best suit their needs."
  },
  {
    "title": "An Optimized Sanitization Approach for Minable Data Publication",
    "keywords": [
      "data publication,",
      "data sanitization,",
      "association rules hiding,",
      "evolutionary algorithm"
    ],
    "abstract": "Minable data publication is ubiquitous since it is beneficial to sharing/trading data among commercial companies and further facilitates the development of data-driven tasks. Unfortunately, the minable data publication is often implemented by publishers with limited privacy concerns such that the published dataset is minable by malicious entities. It prohibits minable data publication since the published data may contain sensitive information. Thus, it is urgently demanded to present some approaches and technologies for reducing the privacy leakage risks. To this end, in this paper, we propose an optimized sanitization approach for minable data publication (named as SA-MDP). SA-MDP supports association rules mining function while providing privacy protection for specific rules. In SA-MDP, we consider the trade-off between the data utility and the data privacy in the minable data publication problem. To address this problem, SA-MDP designs a customized particle swarm optimization (PSO) algorithm, where the optimization objective is determined by both the data utility and the data privacy. Specifically, we take advantage of PSO to produce new particles, which is achieved by random mutation or learning from the best particle. Hence, SA-MDP can avoid the solutions being trapped into local optima. Besides, we design a proper fitness function to guide the particles to run towards the optimal solution. Additionally, we present a preprocessing method before the evolution process of the customized PSO algorithm to improve the convergence rate. Finally, the proposed SA-MDP approach is performed and verified over several datasets. The experimental results have demonstrated the effectiveness and efficiency of SA-MDP."
  },
  {
    "title": "Estimating Intelligence Quotient Using Stylometry and Machine Learning Techniques: A Review",
    "keywords": [
      "stylometry,",
      "iq estimation,",
      "authorship attribution,",
      "intelligence,",
      "iq,",
      "author profiling,",
      "machine learning"
    ],
    "abstract": "The task of trying to quantify a person’s intelligence has been a goal of psychologists for over a century. The area of estimating IQ using stylometry has been a developing area of research and the effectiveness of using machine learning in stylometry analysis for the estimation of IQ has been demonstrated in literature whose conclusions suggest that using a large dataset could improve the quality of estimation. The unavailability of large datasets in this area of research has led to very few publications in IQ estimation from written text. In this paper, we review studies that have been done in IQ estimation and also that have been done in author profiling using stylometry and we conclude that based on the success of IQ estimation and author profiling with stylometry, a study on IQ estimation from written text using stylometry will yield good results if the right dataset is used."
  },
  {
    "title": "Optimal Dependence of Performance and Efficiency of Collaborative Filtering on Random Stratified Subsampling",
    "keywords": [
      "collaborative filtering (cf),",
      "subsampling,",
      "training time improvement (tti),",
      "performance loss,",
      "recommendation system (rs),",
      "collaborative filtering optimal solutions,",
      "rating matrix"
    ],
    "abstract": "Dropping fractions of users or items judiciously can reduce the computational cost of Collaborative Filtering (CF) algorithms. The effect of this subsampling on the computing time and accuracy of CF is not fully understood, and clear guidelines for selecting optimal or even appropriate subsampling levels are not available. In this paper, we present a Density-based Random Stratified Subsampling using Clustering (DRSC) algorithm in which the desired Fraction of Users Dropped (FUD) and Fraction of Items Dropped (FID) are specified, and the overall density during subsampling is maintained. Subsequently, we develop simple models of the Training Time Improvement (TTI) and the Accuracy Loss (AL) as functions of FUD and FID, based on extensive simulations of seven standard CF algorithms as applied to various primary matrices from MovieLens, Yahoo Music Rating, and Amazon Automotive data. Simulations show that both TTI and a scaled AL are bi-linear in FID and FUD for all seven methods. The TTI linear regression of a CF method appears to be same for all datasets. Extensive simulations illustrate that TTI can be estimated reliably with FUD and FID only, but AL requires considering additional dataset characteristics. The derived models are then used to optimize the levels of subsampling addressing the tradeoff between TTI and AL. A simple sub-optimal approximation was found, in which the optimal AL is proportional to the optimal Training Time Reduction Factor (TTRF) for higher values of TTRF, and the optimal subsampling levels, like optimal FID/(1-FID), are proportional to the square root of TTRF."
  },
  {
    "title": "p-Norm Broad Learning for Negative Emotion Classification in Social Networks",
    "keywords": [
      "social networks,",
      "negative emotion,",
      "roberta,",
      "broad learning,",
      "p-norm"
    ],
    "abstract": "Negative emotion classification refers to the automatic classification of negative emotion of texts in social networks. Most existing methods are based on deep learning models, facing challenges such as complex structures and too many hyperparameters. To meet these challenges, in this paper, we propose a method for negative emotion classification utilizing a Robustly Optimized BERT Pretraining Approach (RoBERTa) and p-norm Broad Learning (p-BL). Specifically, there are mainly three contributions in this paper. Firstly, we fine-tune the RoBERTa to adapt it to the task of negative emotion classification. Then, we employ the fine-tuned RoBERTa to extract features of original texts and generate sentence vectors. Secondly, we adopt p-BL to construct a classifier and then predict negative emotions of texts using the classifier. Compared with deep learning models, p-BL has advantages such as a simple structure that is only 3-layer and fewer parameters to be trained. Moreover, it can suppress the adverse effects of more outliers and noise in data by flexibly changing the value of p. Thirdly, we conduct extensive experiments on the public datasets, and the experimental results show that our proposed method outperforms the baseline methods on the tested datasets."
  },
  {
    "title": "Deep Learning in Nuclear Industry: A Survey",
    "keywords": [
      "nuclear industry,",
      "artificial intelligence (ai),",
      "deep learning (dl),",
      "research status,",
      "development trend"
    ],
    "abstract": "As a high-tech strategic emerging comprehensive industry, the nuclear industry is committed to the research, production, and processing of nuclear fuel, as well as the development and utilization of nuclear energy. Nowadays, the nuclear industry has made remarkable progress in the application fields of nuclear weapons, nuclear power, nuclear medical treatment, radiation processing, and so on. With the development of artificial intelligence and the proposal of \"Industry 4.0\", more and more artificial intelligence technologies are introduced into the nuclear industry chain to improve production efficiency, reduce operation cost, improve operation safety, and realize risk avoidance. Meanwhile, deep learning, as an important technology of artificial intelligence, has made amazing progress in theoretical and applied research in the nuclear industry, which vigorously promotes the development of informatization, digitization, and intelligence of the nuclear industry. In this paper, we first simply comb and analyze the intelligent demand scenarios in the whole industrial chain of the nuclear industry. Then, we discuss the data types involved in the nuclear industry chain. After that, we investigate the research status of deep learning in the application fields corresponding to different data types in the nuclear industry. Finally, we discuss the limitation and unique challenges of deep learning in the nuclear industry and the future direction of the intelligent nuclear industry."
  },
  {
    "title": "News Topic Detection Based on Capsule Semantic Graph",
    "keywords": [
      "news topic detection,",
      "capsule semantic graph,",
      "graph kernel"
    ],
    "abstract": "Most news topic detection methods use word-based methods, which easily ignore the relationship among words and have semantic sparsity, resulting in low topic detection accuracy. In addition, the current mainstream probability methods and graph analysis methods for topic detection have high time complexity. For these reasons, we present a news topic detection model on the basis of capsule semantic graph (CSG). The keywords that appear in each text at the same time are modeled as a keyword graph, which is divided into multiple subgraphs through community detection. Each subgraph contains a group of closely related keywords. The graph is used as the vertex of CSG. The semantic relationship among the vertices is obtained by calculating the similarity of the average word vector of each vertex. At the same time, the news text is clustered using the incremental clustering method, where each text uses CSG; that is, the similarity among texts is calculated by the graph kernel. The relationship between vertices and edges is also considered when calculating the similarity. Experimental results on three standard datasets show that CSG can obtain higher precision, recall, and F1 values than several latest methods. Experimental results on large-scale news datasets reveal that the time complexity of CSG is lower than that of probabilistic methods and other graph analysis methods."
  },
  {
    "title": "MAGAN: Unsupervised Low-Light Image Enhancement Guided by Mixed-Attention",
    "keywords": [
      "low-light image enhancement,",
      "unsupervised learning,",
      "generative adversarial network (gan),",
      "mixed-attention"
    ],
    "abstract": "Most learning-based low-light image enhancement methods typically suffer from two problems. First, they require a large amount of paired data for training, which are difficult to acquire in most cases. Second, in the process of enhancement, image noise is difficult to be removed and may even be amplified. In other words, performing denoising and illumination enhancement at the same time is difficult. As an alternative to supervised learning strategies that use a large amount of paired data, as presented in previous work, this paper presents an mixed-attention guided generative adversarial network called MAGAN for low-light image enhancement in a fully unsupervised fashion. We introduce a mixed-attention module layer, which can model the relationship between each pixel and feature of the image. In this way, our network can enhance a low-light image and remove its noise simultaneously. In addition, we conduct extensive experiments on paired and no-reference datasets to show the superiority of our method in enhancing low-light images."
  },
  {
    "title": "Understanding Social Relationships with Person-Pair Relations",
    "keywords": [
      "social relationship understanding,",
      "person-pair relations,",
      "person-pair relation network (pprn)"
    ],
    "abstract": "Social relationship understanding infers existing social relationships among individuals in a given scenario, which has been demonstrated to have a wide range of practical value in reality. However, existing methods infer the social relationship of each person pair in isolation, without considering the context-aware information for person pairs in the same scenario. The context-aware information for person pairs exists extensively in reality, that is, the social relationships of different person pairs in a simple scenario are always related to each other. For instance, if most of the person pairs in a simple scenario have the same social relationship, \"friends\", then the other pairs have a high probability of being \"friends\" or other similar coarse-level relationships, such as \"intimate\" . This context-aware information should thus be considered in social relationship understanding. Therefore, this paper proposes a novel end-to-end trainable Person-Pair Relation Network (PPRN), which is a GRU-based graph inference network, to first extract the visual and position information as the person-pair feature information, then enable it to transfer on a fully-connected social graph, and finally utilizes different aggregators to collect different kinds of person-pair information. Unlike existing methods, the method—with its message passing mechanism in the graph model—can infer the social relationship of each person-pair in a joint way (i.e., not in isolation). Extensive experiments on People In Social Context (PISC)- and People In Photo Album (PIPA)-relation datasets show the superiority of our method compared to other methods."
  },
  {
    "title": "A Novel Influence Maximization Algorithm for a Competitive Environment Based on Social Media Data Analytics",
    "keywords": [
      "influence maximization,",
      "competitive environment,",
      "dynamic network"
    ],
    "abstract": "Online social networks are increasingly connecting people around the world. Influence maximization is a key area of research in online social networks, which identifies influential users during information dissemination. Most of the existing influence maximization methods only consider the transmission of a single channel, but real-world networks mostly include multiple channels of information transmission with competitive relationships. The problem of influence maximization in an environment involves selecting the seed node set for certain competitive information, so that it can avoid the influence of other information, and ultimately affect the largest set of nodes in the network. In this paper, the influence calculation of nodes is achieved according to the local community discovery algorithm, which is based on community dispersion and the characteristics of dynamic community structure. Furthermore, considering two various competitive information dissemination cases as an example, a solution is designed for self-interested information based on the assumption that the seed node set of competitive information is known, and a novel influence maximization algorithm of node avoidance based on user interest is proposed. Experiments conducted based on real-world Twitter dataset demonstrates the efficiency of our proposed algorithm in terms of accuracy and time against notable influence maximization algorithms."
  },
  {
    "title": "A Mini-Review of Machine Learning in Big Data Analytics: Applications, Challenges, and Prospects",
    "keywords": [
      "big data analytics (bda),",
      "machine learning (ml),",
      "big data (bd),",
      "hadoop,",
      "mapreduce"
    ],
    "abstract": "The availability of digital technology in the hands of every citizenry worldwide makes an available unprecedented massive amount of data. The capability to process these gigantic amounts of data in real-time with Big Data Analytics (BDA) tools and Machine Learning (ML) algorithms carries many paybacks. However, the high number of free BDA tools, platforms, and data mining tools makes it challenging to select the appropriate one for the right task. This paper presents a comprehensive mini-literature review of ML in BDA, using a keyword search; a total of 1512 published articles was identified. The articles were screened to 140 based on the study proposed novel taxonomy. The study outcome shows that deep neural networks (15%), support vector machines (15%), artificial neural networks (14%), decision trees (12%), and ensemble learning techniques (11%) are widely applied in BDA. The related applications fields, challenges, and most importantly the openings for future research, are detailed."
  },
  {
    "title": "Toward Intelligent Financial Advisors for Identifying Potential Clients: A Multitask Perspective",
    "keywords": [
      "intelligent financial advisor (ifa),",
      "potential client identification,",
      "multitask learning (mtl),",
      "feature selection"
    ],
    "abstract": "Intelligent Financial Advisors (IFAs) in online financial applications (apps) have brought new life to personal investment by providing appropriate and high-quality portfolios for users. In real-world scenarios, identifying potential clients is a crucial issue for IFAs, i.e., identifying users who are willing to purchase the portfolios. Thus, extracting useful information from various characteristics of users and further predicting their purchase inclination are urgent. However, two critical problems encountered in real practice make this prediction task challenging, i.e., sample selection bias and data sparsity. In this study, we formalize a potential conversion relationship, i.e., user → activated user → client and decompose this relationship into three related tasks. Then, we propose a Multitask Feature Extraction Model (MFEM), which can leverage useful information contained in these related tasks and learn them jointly, thereby solving the two problems simultaneously. In addition, we design a two-stage feature selection algorithm to select highly relevant user features efficiently and accurately from an incredibly huge number of user feature fields. Finally, we conduct extensive experiments on a real-world dataset provided by a famous fintech bank. Experimental results clearly demonstrate the effectiveness of MFEM."
  },
  {
    "title": "BCSE: Blockchain-Based Trusted Service Evaluation Model over Big Data",
    "keywords": [
      "social network,",
      "trusted service evaluation model,",
      "blockchain,",
      "identity authentication"
    ],
    "abstract": "The blockchain, with its key characteristics of decentralization, persistence, anonymity, and auditability, has become a solution to overcome the overdependence and lack of trust for a traditional public key infrastructure on third-party institutions. Because of these characteristics, the blockchain is suitable for solving certain open problems in the service-oriented social network, where the unreliability of submitted reviews of service vendors can cause serious security problems. To solve the unreliability problems of submitted reviews, this paper first proposes a blockchain-based identity authentication scheme and a new trusted service evaluation model by introducing the scheme into a service evaluation model. The new trusted service evaluation model consists of the blockchain-based identity authentication scheme, evaluation submission module, and evaluation publicity module. In the proposed evaluation model, only users who have successfully been authenticated can submit reviews to service vendors. The registration and authentication records of users’ identity and the reviews for service vendors are all stored in the blockchain network. The security analysis shows that this model can ensure the credibility of users’ reviews for service vendors, and other users can obtain credible reviews of service vendors via the review publicity module. The experimental results also show that the proposed model has a lower review submission delay than other models."
  },
  {
    "title": "A Comparison of Computational Approaches for Intron Retention Detection",
    "keywords": [
      "alternative splicing,",
      "intron retention,",
      "gene expression,",
      "rna-seq"
    ],
    "abstract": "Intron Retention (IR) is an alternative splicing mode through which introns are retained in mature RNAs rather than being spliced in most cases. IR has been gaining increasing attention in recent years because of its recognized association with gene expression regulation and complex diseases. Continuous efforts have been dedicated to the development of IR detection methods. These methods differ in their metrics to quantify retention propensity, performance to detect IR events, functional enrichment of detected IRs, and computational speed. A systematic experimental comparison would be valuable to the selection and use of existing methods. In this work, we conduct an experimental comparison of existing IR detection methods. Considering the unavailability of a gold standard dataset of intron retention, we compare the IR detection performance on simulation datasets. Then, we compare the IR detection results with real RNA-Seq data. We also describe the use of differential analysis methods to identify disease-associated IRs and compare differential IRs along with their Gene Ontology enrichment, which is illustrated on an Alzheimer’s disease RNA-Seq dataset. We discuss key principles and features of existing approaches and outline their differences. This systematic analysis provides helpful guidance for interrogating transcriptomic data from the point of view of IR."
  },
  {
    "title": "Exploiting More Associations Between Slots for Multi-Domain Dialog State Tracking",
    "keywords": [
      "slot-relevant attention,",
      "multi-domain dialog state tracking,",
      "task-oriented dialog system"
    ],
    "abstract": "Dialog State Tracking (DST) aims to extract the current state from the conversation and plays an important role in dialog systems. Existing methods usually predict the value of each slot independently and do not consider the correlations among slots, which will exacerbate the data sparsity problem because of the increased number of candidate values. In this paper, we propose a multi-domain DST model that integrates slot-relevant information. In particular, certain connections may exist among slots in different domains, and their corresponding values can be obtained through explicit or implicit reasoning. Therefore, we use the graph adjacency matrix to determine the correlation between slots, so that the slots can incorporate more slot-value transformer information. Experimental results show that our approach has performed well on the Multi-domain Wizard-Of-Oz (MultiWOZ) 2.0 and MultiWOZ2.1 datasets, demonstrating the effectiveness and necessity of incorporating slot-relevant information."
  },
  {
    "title": "Big Data with Cloud Computing: Discussions and Challenges",
    "keywords": [
      "big data,",
      "data analysis,",
      "cloud computing,",
      "hadoop"
    ],
    "abstract": "With the recent advancements in computer technologies, the amount of data available is increasing day by day. However, excessive amounts of data create great challenges for users. Meanwhile, cloud computing services provide a powerful environment to store large volumes of data. They eliminate various requirements, such as dedicated space and maintenance of expensive computer hardware and software. Handling big data is a time-consuming task that requires large computational clusters to ensure successful data storage and processing. In this work, the definition, classification, and characteristics of big data are discussed, along with various cloud services, such as Microsoft Azure, Google Cloud, Amazon Web Services, International Business Machine cloud, Hortonworks, and MapR. A comparative analysis of various cloud-based big data frameworks is also performed. Various research challenges are defined in terms of distributed database storage, data security, heterogeneity, and data visualization."
  },
  {
    "title": "Sampling with Prior Knowledge for High-dimensional Gravitational Wave Data Analysis",
    "keywords": [
      "high-dimensional data,",
      "prior sampling,",
      "normalizing flow,",
      "gravitational wave"
    ],
    "abstract": "Extracting knowledge from high-dimensional data has been notoriously difficult, primarily due to the so-called \"curse of dimensionality\" and the complex joint distributions of these dimensions. This is a particularly profound issue for high-dimensional gravitational wave data analysis where one requires to conduct Bayesian inference and estimate joint posterior distributions. In this study, we incorporate prior physical knowledge by sampling from desired interim distributions to develop the training dataset. Accordingly, the more relevant regions of the high-dimensional feature space are covered by additional data points, such that the model can learn the subtle but important details. We adapt the normalizing flow method to be more expressive and trainable, such that the information can be effectively extracted and represented by the transformation between the prior and target distributions. Once trained, our model only takes approximately 1 s on one V100 GPU to generate thousands of samples for probabilistic inference purposes. The evaluation of our approach confirms the efficacy and efficiency of gravitational wave data inferences and points to a promising direction for similar research. The source code, specifications, and detailed procedures are publicly accessible on GitHub."
  },
  {
    "title": "Intelligent and Adaptive Web Data Extraction System Using Convolutional and Long Short-Term Memory Deep Learning Networks",
    "keywords": [
      "adaptive web scraping,",
      "deep learning,",
      "long short-term memory (lstm),",
      "web data extraction,",
      "you only look once (yolo)"
    ],
    "abstract": "Data are crucial to the growth of e-commerce in today’s world of highly demanding hyper-personalized consumer experiences, which are collected using advanced web scraping technologies. However, core data extraction engines fail because they cannot adapt to the dynamic changes in website content. This study investigates an intelligent and adaptive web data extraction system with convolutional and Long Short-Term Memory (LSTM) networks to enable automated web page detection using the You only look once (Yolo) algorithm and Tesseract LSTM to extract product details, which are detected as images from web pages. This state-of-the-art system does not need a core data extraction engine, and thus can adapt to dynamic changes in website layout. Experiments conducted on real-world retail cases demonstrate an image detection (precision) and character extraction accuracy (precision) of 97% and 99%, respectively. In addition, a mean average precision of 74%, with an input dataset of 45 objects or images, is obtained."
  },
  {
    "title": "Multimodal Adaptive Identity-Recognition Algorithm Fused with Gait Perception",
    "keywords": [
      "gait recognition,",
      "person identification,",
      "deep learning,",
      "multimodal feature fusion"
    ],
    "abstract": "Identity-recognition technologies require assistive equipment, whereas they are poor in recognition accuracy and expensive. To overcome this deficiency, this paper proposes several gait feature identification algorithms. First, in combination with the collected gait information of individuals from triaxial accelerometers on smartphones, the collected information is preprocessed, and multimodal fusion is used with the existing standard datasets to yield a multimodal synthetic dataset; then, with the multimodal characteristics of the collected biological gait information, a Convolutional Neural Network based Gait Recognition (CNN-GR) model and the related scheme for the multimodal features are developed; at last, regarding the proposed CNN-GR model and scheme, a unimodal gait feature identity single-gait feature identification algorithm and a multimodal gait feature fusion identity multimodal gait information algorithm are proposed. Experimental results show that the proposed algorithms perform well in recognition accuracy, the confusion matrix, and the kappa statistic, and they have better recognition scores and robustness than the compared algorithms; thus, the proposed algorithm has prominent promise in practice."
  },
  {
    "title": "LotusSQL: SQL Engine for High-Performance Big Data Systems",
    "keywords": [
      "big data,",
      "c++,",
      "structured query language (sql),",
      "query optimization"
    ],
    "abstract": "In recent years, Apache Spark has become the de facto standard for big data processing. SparkSQL is a module offering support for relational analysis on Spark with Structured Query Language (SQL). SparkSQL provides convenient data processing interfaces. Despite its efficient optimizer, SparkSQL still suffers from the inefficiency of Spark resulting from Java virtual machine and the unnecessary data serialization and deserialization. Adopting native languages such as C++ could help to avoid such bottlenecks. Benefiting from a bare-metal runtime environment and template usage, systems with C++ interfaces usually achieve superior performance. However, the complexity of native languages also increases the required programming and debugging efforts. In this work, we present LotusSQL, an engine to provide SQL support for dataset abstraction on a native backend Lotus. We employ a convenient SQL processing framework to deal with frontend jobs. Advanced query optimization technologies are added to improve the quality of execution plans. Above the storage design and user interface of the compute engine, LotusSQL implements a set of structured dataset operations with high efficiency and integrates them with the frontend. Evaluation results show that LotusSQL achieves a speedup of up to 9× in certain queries and outperforms Spark SQL in a standard query benchmark by more than 2× on average."
  },
  {
    "title": "Attention-Aware Heterogeneous Graph Neural Network",
    "keywords": [
      "graph neural network (gnn),",
      "heterogeneous information network (hin),",
      "embedding"
    ],
    "abstract": "As a powerful tool for elucidating the embedding representation of graph-structured data, Graph Neural Networks (GNNs), which are a series of powerful tools built on homogeneous networks, have been widely used in various data mining tasks. It is a huge challenge to apply a GNN to an embedding Heterogeneous Information Network (HIN). The main reason for this challenge is that HINs contain many different types of nodes and different types of relationships between nodes. HIN contains rich semantic and structural information, which requires a specially designed graph neural network. However, the existing HIN-based graph neural network models rarely consider the interactive information hidden between the meta-paths of HIN in the poor embedding of nodes in the HIN. In this paper, we propose an Attention-aware Heterogeneous graph Neural Network (AHNN) model to effectively extract useful information from HIN and use it to learn the embedding representation of nodes. Specifically, we first use node-level attention to aggregate and update the embedding representation of nodes, and then concatenate the embedding representation of the nodes on different meta-paths. Finally, the semantic-level neural network is proposed to extract the feature interaction relationships on different meta-paths and learn the final embedding of nodes. Experimental results on three widely used datasets showed that the AHNN model could significantly outperform the state-of-the-art models."
  },
  {
    "title": "Coronavirus Pandemic Analysis Through Tripartite Graph Clustering in Online Social Networks",
    "keywords": [
      "covid-19,",
      "clustering,",
      "online social network,",
      "twitter"
    ],
    "abstract": "The COVID-19 pandemic has hit the world hard. The reaction to the pandemic related issues has been pouring into social platforms, such as Twitter. Many public officials and governments use Twitter to make policy announcements. People keep close track of the related information and express their concerns about the policies on Twitter. It is beneficial yet challenging to derive important information or knowledge out of such Twitter data. In this paper, we propose a Tripartite Graph Clustering for Pandemic Data Analysis (TGC-PDA) framework that builds on the proposed models and analysis: (1) tripartite graph representation, (2) non-negative matrix factorization with regularization, and (3) sentiment analysis. We collect the tweets containing a set of keywords related to coronavirus pandemic as the ground truth data. Our framework can detect the communities of Twitter users and analyze the topics that are discussed in the communities. The extensive experiments show that our TGC-PDA framework can effectively and efficiently identify the topics and correlations within the Twitter data for monitoring and understanding public opinions, which would provide policy makers useful information and statistics for decision making."
  },
  {
    "title": "A Deep-Learning Prediction Model for Imbalanced Time Series Data Forecasting",
    "keywords": [
      "time series forecasting,",
      "imbalanced data,",
      "deep learning,",
      "prediction model"
    ],
    "abstract": "Time series forecasting has attracted wide attention in recent decades. However, some time series are imbalanced and show different patterns between special and normal periods, leading to the prediction accuracy degradation of special periods. In this paper, we aim to develop a unified model to alleviate the imbalance and thus improving the prediction accuracy for special periods. This task is challenging because of two reasons: (1) the temporal dependency of series, and (2) the tradeoff between mining similar patterns and distinguishing different distributions between different periods. To tackle these issues, we propose a self-attention-based time-varying prediction model with a two-stage training strategy. First, we use an encoder-decoder module with the multi-head self-attention mechanism to extract common patterns of time series. Then, we propose a time-varying optimization module to optimize the results of special periods and eliminate the imbalance. Moreover, we propose reverse distance attention in place of traditional dot attention to highlight the importance of similar historical values to forecast results. Finally, extensive experiments show that our model performs better than other baselines in terms of mean absolute error and mean absolute percentage error."
  },
  {
    "title": "AIPerf: Automated Machine Learning as an AI-HPC Benchmark",
    "keywords": [
      "high-performance computing (hpc),",
      "artificial intelligence (ai),",
      "automated machine learning"
    ],
    "abstract": "The plethora of complex Artificial Intelligence (AI) algorithms and available High-Performance Computing (HPC) power stimulates the expeditious development of AI components with heterogeneous designs. Consequently, the need for cross-stack performance benchmarking of AI-HPC systems has rapidly emerged. In particular, the de facto HPC benchmark, LINPACK, cannot reflect the AI computing power and input/output performance without a representative workload. Current popular AI benchmarks, such as MLPerf, have a fixed problem size and therefore limited scalability. To address these issues, we propose an end-to-end benchmark suite utilizing automated machine learning, which not only represents real AI scenarios, but also is auto-adaptively scalable to various scales of machines. We implement the algorithms in a highly parallel and flexible way to ensure the efficiency and optimization potential on diverse systems with customizable configurations. We utilize Operations Per Second (OPS), which is measured in an analytical and systematic approach, as a major metric to quantify the AI performance. We perform evaluations on various systems to ensure the benchmark’s stability and scalability, from 4 nodes with 32 NVIDIA Tesla T4 (56.1 Tera-OPS measured) up to 512 nodes with 4096 Huawei Ascend 910 (194.53 Peta-OPS measured), and the results show near-linear weak scalability. With a flexible workload and single metric, AIPerf can easily scale on and rank AI-HPC, providing a powerful benchmark suite for the coming supercomputing era."
  },
  {
    "title": "Deep Sequential Model for Anchor Recommendation on Live Streaming Platforms",
    "keywords": [
      "live streaming,",
      "sequential recommendation,",
      "attention mechanism,",
      "deep learning"
    ],
    "abstract": "Live streaming has grown rapidly in recent years, attracting increasingly more participation. As the number of online anchors is large, it is difficult for viewers to find the anchors they are interested in. Therefore, a personalized recommendation system is important for live streaming platforms. On live streaming platforms, the viewer’s and anchor’s preferences are dynamically changing over time. How to capture the user’s preference change is extensively studied in the literature, but how to model the viewer’s and anchor’s preference changes and how to learn their representations based on their preference matching are less studied. Taking these issues into consideration, in this paper, we propose a deep sequential model for live streaming recommendation. We develop a component named the multi-head related-unit in the model to capture the preference matching between anchor and viewer and extract related features for their representations. To evaluate the performance of our proposed model, we conduct experiments on real datasets, and the results show that our proposed model outperforms state-of-the-art recommendation models."
  },
  {
    "title": "A Survey on Algorithms for Intelligent Computing and Smart City Applications",
    "keywords": [
      "cyber physical systems,",
      "internet of things (iot),",
      "intelligent computing algorithm,",
      "quality of service (qos),",
      "smart city"
    ],
    "abstract": "With the rapid development of human society, the urbanization of the world’s population is also progressing rapidly. Urbanization has brought many challenges and problems to the development of cities. For example, the urban population is under excessive pressure, various natural resources and energy are increasingly scarce, and environmental pollution is increasing, etc. However, the original urban model has to be changed to enable people to live in greener and more sustainable cities, thus providing them with a more convenient and comfortable living environment. The new urban framework, the smart city, provides excellent opportunities to meet these challenges, while solving urban problems at the same time. At this stage, many countries are actively responding to calls for smart city development plans. This paper investigates the current stage of the smart city. First, it introduces the background of smart city development and gives a brief definition of the concept of the smart city. Second, it describes the framework of a smart city in accordance with the given definition. Finally, various intelligent algorithms to make cities smarter, along with specific examples, are discussed and analyzed."
  },
  {
    "title": "A Multitask Multiview Neural Network for End-to-End Aspect-Based Sentiment Analysis",
    "keywords": [
      "deep learning,",
      "multitask learning,",
      "multiview learning,",
      "natural language processing,",
      "aspect-based sentiment analysis"
    ],
    "abstract": "The aspect-based sentiment analysis (ABSA) consists of two subtasks'aspect term extraction and aspect sentiment prediction. Existing methods deal with both subtasks one by one in a pipeline manner, in which there lies some problems in performance and real application. This study investigates the end-to-end ABSA and proposes a novel multitask multiview network (MTMVN) architecture. Specifically, the architecture takes the unified ABSA as the main task with the two subtasks as auxiliary tasks. Meanwhile, the representation obtained from the branch network of the main task is regarded as the global view, whereas the representations of the two subtasks are considered two local views with different emphases. Through multitask learning, the main task can be facilitated by additional accurate aspect boundary information and sentiment polarity information. By enhancing the correlations between the views under the idea of multiview learning, the representation of the global view can be optimized to improve the overall performance of the model. The experimental results on three benchmark datasets show that the proposed method exceeds the existing pipeline methods and end-to-end methods, proving the superiority of our MTMVN architecture."
  },
  {
    "title": "Improvising Personalized Travel Recommendation System with Recency Effects",
    "keywords": [
      "travel recommendation,",
      "time sensitivity,",
      "recency effect,",
      "personalization,",
      "social media"
    ],
    "abstract": "A travel recommendation system based on social media activity provides a customized place of interest to accommodate user-specific needs and preferences. In general, the user’s inclination towards travel destinations is subject to change over time. In this project, we have analyzed users’ twitter data, as well as their friends and followers in a timely fashion to understand recent travel interest. A machine learning classifier identifies tweets relevant to travel. The travel tweets are then used to obtain personalized travel recommendations. Unlike most of the personalized recommendation systems, our proposed model takes into account a user’s most recent interest by incorporating time-sensitive recency weight into the model. Our proposed model has outperformed the existing personalized place of interest recommendation model, and the overall accuracy is 75.23%."
  },
  {
    "title": "Effective Density-Based Clustering Algorithms for Incomplete Data",
    "keywords": [
      "density-based clustering,",
      "incomplete data,",
      "clustering algorihtm"
    ],
    "abstract": "Density-based clustering is an important category among clustering algorithms. In real applications, many datasets suffer from incompleteness. Traditional imputation technologies or other techniques for handling missing values are not suitable for density-based clustering and decrease clustering result quality. To avoid these problems, we develop a novel density-based clustering approach for incomplete data based on Bayesian theory, which conducts imputation and clustering concurrently and makes use of intermediate clustering results. To avoid the impact of low-density areas inside non-convex clusters, we introduce a local imputation clustering algorithm, which aims to impute points to high-density local areas. The performances of the proposed algorithms are evaluated using ten synthetic datasets and five real-world datasets with induced missing values. The experimental results show the effectiveness of the proposed algorithms."
  },
  {
    "title": "Sensitive Integration of Multilevel Optimization Model in Human Activity Recognition for Smartphone and Smartwatch Applications",
    "keywords": [
      "optimization,",
      "ant lion optimization (alo),",
      "gspan,",
      "forward-backward rules (fbr),",
      "internet of things (iot),",
      "smartwatch,",
      "smartphone"
    ],
    "abstract": "This study proposes an intelligent data analysis model for finding optimal patterns in human activities on the basis of biometric features obtained from four sensors installed on smartphone and smartwatch devices. The proposed model, referred to as Scheduling Activities of smartphone and smartwatch based on Optimal Pattern Model (SA-OPM), consists of four main stages. The first stage relates to the collection of data from four sensors in real time (i.e., two smartphone sensors called accelerometer and gyroscope and two smartwatch sensors of the same name). The second stage involves the preprocessing of the data by converting them into graphs. As graphs are difficult to deal with directly, a deterministic selection algorithm is proposed as a new method to find the optimal root to split the graphs into multiple subgraphs. The third stage entails determining the number of samples related to each subgraph by using the optimization technique called the lion optimization algorithm. The final stage involves the generation of patterns from the optimal subgraph by using the association pattern algorithm called gSpan. The pattern finder based on Forward-Backward Rules (FBR) generates the optimal patterns and thus aids humans in organizing their activities. Results indicate that the proposed SA-OPM model generates robust and authentic patterns of human activities."
  },
  {
    "title": "Analysis and Predictions of Spread, Recovery, and Death Caused by COVID-19 in India",
    "keywords": [
      "covid-19,",
      "regression,",
      "correlation,",
      "machine learning,",
      "prediction"
    ],
    "abstract": "The novel coronavirus outbreak was first reported in late December 2019 and more than 7 million people were infected with this disease and over 0.40 million worldwide lost their lives. The first case was diagnosed on 30 January 2020 in India and the figure crossed 0.24 million as of 6 June 2020. This paper presents a detailed study of recently developed forecasting models and predicts the number of confirmed, recovered, and death cases in India caused by COVID-19. The correlation coefficients and multiple linear regression applied for prediction and autocorrelation and autoregression have been used to improve the accuracy. The predicted number of cases shows a good agreement with 0.9992 R-squared score to the actual values. The finding suggests that lockdown and social distancing are two important factors that can help to suppress the increasing spread rate of COVID-19."
  },
  {
    "title": "Diagnosis of COVID-19 from Chest X-Ray Images Using Wavelets-Based Depthwise Convolution Network",
    "keywords": [
      "coronavirus,",
      "covid-19,",
      "deep learning,",
      "convolution neural network,",
      "x-ray images"
    ],
    "abstract": "Coronavirus disease 2019 also known as COVID-19 has become a pandemic. The disease is caused by a beta coronavirus called Severe Acute Respiratory Syndrome Coronavirus 2 (SARS-CoV-2). The severity of the disease can be understood by the massive number of deaths and affected patients globally. If the diagnosis is fast-paced, the disease can be controlled in a better manner. Laboratory tests are available for diagnosis, but they are bounded by available testing kits and time. The use of radiological examinations that comprise Computed Tomography (CT) can be used for the diagnosis of the disease. Specifically, chest X-Ray images can be analysed to identify the presence of COVID-19 in a patient. In this paper, an automated method for the diagnosis of COVID-19 from the chest X-Ray images is proposed. The method presents an improved depthwise convolution neural network for analysing the chest X-Ray images. Wavelet decomposition is applied to integrate multiresolution analysis in the network. The frequency sub-bands obtained from the input images are fed in the network for identifying the disease. The network is designed to predict the class of the input image as normal, viral pneumonia, and COVID-19. The predicted output from the model is combined with Grad-CAM visualization for diagnosis. A comparative study with the existing methods is also performed. The metrics like accuracy, sensitivity, and F1-measure are calculated for performance evaluation. The performance of the proposed method is better than the existing methodologies and thus can be used for the effective diagnosis of the disease."
  },
  {
    "title": "An Advanced Uncertainty Measure Using Fuzzy Soft Sets: Application to Decision-Making Problems",
    "keywords": [
      "fuzzy soft sets,",
      "dempster-shafer theory,",
      "grey relational analysis,",
      "entropy,",
      "belief measures and medical diagnosis"
    ],
    "abstract": "In this paper, uncertainty has been measured in the form of fuzziness which arises due to imprecise boundaries of fuzzy sets. Uncertainty caused due to human’s cognition can be decreased by the use of fuzzy soft sets. There are different approaches to deal with the measurement of uncertainty. The method we proposed uses fuzzified evidence theory to calculate total degree of fuzziness of the parameters. It consists of mainly four parts. The first part is to measure uncertainties of parameters using fuzzy soft sets and then to modulate the uncertainties calculated. Afterward, the appropriate basic probability assignments with respect to each parameter are produced. In the last, we use Dempster’s rule of combination to fuse independent parameters into integrated one. To validate the proposed method, we perform an experiment and compare our outputs with grey relational analysis method. Also, a medical diagnosis application in reference to COVID-19 has been given to show the effectiveness of advanced method by comparing with other method."
  },
  {
    "title": "Prediction of COVID-19 Confirmed, Death, and Cured Cases in India Using Random Forest Model",
    "keywords": [
      "coronavirus,",
      "covid-19,",
      "respiratory tract,",
      "multi-class classification,",
      "random forest"
    ],
    "abstract": "A novel coronavirus (SARS-CoV-2) is an unusual viral pneumonia in patients, first found in late December 2019, latter it declared a pandemic by World Health Organizations because of its fatal effects on public health. In this present, cases of COVID-19 pandemic are exponentially increasing day by day in the whole world. Here, we are detecting the COVID-19 cases, i.e., confirmed, death, and cured cases in India only. We are performing this analysis based on the cases occurring in different states of India in chronological dates. Our dataset contains multiple classes so we are performing multi-class classification. On this dataset, first, we performed data cleansing and feature selection, then performed forecasting of all classes using random forest, linear model, support vector machine, decision tree, and neural network, where random forest model outperformed the others, therefore, the random forest is used for prediction and analysis of all the results. The K-fold cross-validation is performed to measure the consistency of the model."
  },
  {
    "title": "Effect of E-Learning on Public Health and Environment During COVID-19 Lockdown",
    "keywords": [
      "e-learning,",
      "environment,",
      "health,",
      "covid-19"
    ],
    "abstract": "E-learning is the most promising venture in the entire world. During the COVID-19 lockdown, e-learning is successfully providing potential information to the students and researchers. In developing nations like India, with limited resources, e-learning tools and platforms provide a chance to make education available to middle and low income households. This paper gives insights about three different online services, namely Google Classroom, Zoom, and Microsoft Teams being used by three different educational institutions. We aim to analyze the efficiency and acceptability of e-learning tools among Indian students during the COVID-19 lockdown. The paper also aims to evaluate the impact of e-learning on the environment and public health during COVID-19 lockdown. It is found that e-learning has potential to reduce carbon emissions, which has beneficial impact on the environment. However, the mental health is impacted as e-learning may lead to self-isolation and reduction in academic achievements that may lead to anxiety and mental depression. Due to usage of electronic devices for learning, the eyes and neck muscles may be put in strain, having deleterious effects on physical health."
  },
  {
    "title": "Analysis of Protein-Ligand Interactions of SARS-CoV-2 Against Selective Drug Using Deep Neural Networks",
    "keywords": [
      "deep neural network (dnn),",
      "coronavirus,",
      "protein-ligand interactions,",
      "deep learning,",
      "clinical healthcare system"
    ],
    "abstract": "In recent time, data analysis using machine learning accelerates optimized solutions on clinical healthcare systems. The machine learning methods greatly offer an efficient prediction ability in diagnosis system alternative with the clinicians. Most of the systems operate on the extracted features from the patients and most of the predicted cases are accurate. However, in recent time, the prevalence of COVID-19 has emerged the global healthcare industry to find a new drug that suppresses the pandemic outbreak. In this paper, we design a Deep Neural Network (DNN) model that accurately finds the protein-ligand interactions with the drug used. The DNN senses the response of protein-ligand interactions for a specific drug and identifies which drug makes the interaction that combats effectively the virus. With limited genome sequence of Indian patients submitted to the GISAID database, we find that the DNN system is effective in identifying the protein-ligand interactions for a specific drug."
  },
  {
    "title": "Multivariate Deep Learning Approach for Electric Vehicle Speed Forecasting",
    "keywords": [
      "electric vehicle (ev),",
      "multivariate long short-term memory (lstm),",
      "speed forecasting,",
      "deep learning"
    ],
    "abstract": "Speed forecasting has numerous applications in intelligent transport systems’ design and control, especially for safety and road efficiency applications. In the field of electromobility, it represents the most dynamic parameter for efficient online in-vehicle energy management. However, vehicles’ speed forecasting is a challenging task, because its estimation is closely related to various features, which can be classified into two categories, endogenous and exogenous features. Endogenous features represent electric vehicles’ characteristics, whereas exogenous ones represent its surrounding context, such as traffic, weather, and road conditions. In this paper, a speed forecasting method based on the Long Short-Term Memory (LSTM) is introduced. The LSTM model training is performed upon a dataset collected from a traffic simulator based on real-world data representing urban itineraries. The proposed models are generated for univariate and multivariate scenarios and are assessed in terms of accuracy for speed forecasting. Simulation results show that the multivariate model outperforms the univariate model for short- and long-term forecasting."
  },
  {
    "title": "Intelligent Monitoring System for Biogas Detection Based on the Internet of Things: Mohammedia, Morocco City Landfill Case",
    "keywords": [
      "internet of things (iots),",
      "biogas,",
      "monitoring,",
      "composition,",
      "detection,",
      "landfill"
    ],
    "abstract": "Mechanization is a depollution activity, because it provides an energetic and ecological response to the problem of organic waste treatment. Through burning, biogas from mechanization reduces gas pollution from fermentation by a factor of 20. This study aims to better understand the influence of the seasons on the emitted biogas in the landfill of the city Mohammedia. The composition of the biogas that naturally emanates from the landfill has been continuously analyzed by our intelligent system, from different wells drilled in recent and old waste repositories. During the rainy season, the average production of methane, carbon dioxide, and oxygen and nitrogen are currently 56%, 32%, and 1%, respectively, compared to 51%, 31%, and 0.8%, respectively, for old waste. Hazards levels, potential fire, and explosion risks associated with biogas are lower than those of natural gases in most cases. For this reason a system is proposed to measure and monitor the biogas production of the landfill site remotely. Measurement results carried out at various sites of the landfill in the city of Mohammedia by the system show that the biogas contents present dangers and sanitary risks which are of another order."
  },
  {
    "title": "Hybrid Recommender System for Tourism Based on Big Data and AI: A Conceptual Framework",
    "keywords": [
      "recommender systems,",
      "user profiling,",
      "content-based filtering,",
      "collaborative filtering,",
      "hybrid recommender system,",
      "e-tourism,",
      "trip planning"
    ],
    "abstract": "With the development of the Internet, technology, and means of communication, the production of tourist data has multiplied at all levels (hotels, restaurants, transport, heritage, tourist events, activities, etc.), especially with the development of Online Travel Agency (OTA). However, the list of possibilities offered to tourists by these Web search engines (or even specialized tourist sites) can be overwhelming and relevant results are usually drowned in informational \"noise\", which prevents, or at least slows down the selection process. To assist tourists in trip planning and help them to find the information they are looking for, many recommender systems have been developed. In this article, we present an overview of the various recommendation approaches used in the field of tourism. From this study, an architecture and a conceptual framework for tourism recommender system are proposed, based on a hybrid recommendation approach. The proposed system goes beyond the recommendation of a list of tourist attractions, tailored to tourist preferences. It can be seen as a trip planner that designs a detailed program, including heterogeneous tourism resources, for a specific visit duration. The ultimate goal is to develop a recommender system based on big data technologies, artificial intelligence, and operational research to promote tourism in Morocco, specifically in the Daraâ-Tafilalet region."
  },
  {
    "title": "IoT-Based Data Logger for Weather Monitoring Using Arduino-Based Wireless Sensor Networks with Remote Graphical Application and Alerts",
    "keywords": [
      "arduino,",
      "weather station,",
      "internet of things,",
      "wireless,",
      "sensors,",
      "smart environment"
    ],
    "abstract": "In recent years, the monitoring systems play significant roles in our life. So, in this paper, we propose an automatic weather monitoring system that allows having dynamic and real-time climate data of a given area. The proposed system is based on the internet of things technology and embedded system. The system also includes electronic devices, sensors, and wireless technology. The main objective of this system is sensing the climate parameters, such as temperature, humidity, and existence of some gases, based on the sensors. The captured values can then be sent to remote applications or databases. Afterwards, the stored data can be visualized in graphics and tables form."
  },
  {
    "title": "New Enhanced Authentication Protocol for Internet of Things",
    "keywords": [
      "authetication,",
      "internet of things (iot),",
      "sensor,",
      "security,",
      "authorization"
    ],
    "abstract": "Internet of Things (IoT) refers to a new extended network that enables to any object to be linked to the Internet in order to exchange data and to be controlled remotely. Nowadays, due to its multiple advantages, the IoT is useful in many areas like environment, water monitoring, industry, public security, medicine, and so on. For covering all spaces and operating correctly, the IoT benefits from advantages of other recent technologies, like radio frequency identification, wireless sensor networks, big data, and mobile network. However, despite of the integration of various things in one network and the exchange of data among heterogeneous sources, the security of user’s data is a central question. For this reason, the authentication of interconnected objects is received as an interested importance. In 2012, Ye et al. suggested a new authentication and key exchanging protocol for Internet of things devices. However, we have proved that their protocol cannot resist to various attacks. In this paper, we propose an enhanced authentication protocol for IoT. Furthermore, we present the comparative results between our proposed scheme and other related ones."
  },
  {
    "title": "Improvement in Automated Diagnosis of Soft Tissues Tumors Using Machine Learning",
    "keywords": [
      "classification,",
      "soft tissues tumours,",
      "preprocessing techniques,",
      "support vector machine (svm),",
      "decision tree (dt),",
      "machine learning,",
      "predictive diagnosis"
    ],
    "abstract": "Soft Tissue Tumors (STT) are a form of sarcoma found in tissues that connect, support, and surround body structures. Because of their shallow frequency in the body and their great diversity, they appear to be heterogeneous when observed through Magnetic Resonance Imaging (MRI). They are easily confused with other diseases such as fibroadenoma mammae, lymphadenopathy, and struma nodosa, and these diagnostic errors have a considerable detrimental effect on the medical treatment process of patients. Researchers have proposed several machine learning models to classify tumors, but none have adequately addressed this misdiagnosis problem. Also, similar studies that have proposed models for evaluation of such tumors mostly do not consider the heterogeneity and the size of the data. Therefore, we propose a machine learning-based approach which combines a new technique of preprocessing the data for features transformation, resampling techniques to eliminate the bias and the deviation of instability and performing classifier tests based on the Support Vector Machine (SVM) and Decision Tree (DT) algorithms. The tests carried out on dataset collected in Nur Hidayah Hospital of Yogyakarta in Indonesia show a great improvement compared to previous studies. These results confirm that machine learning methods could provide efficient and effective tools to reinforce the automatic decision-making processes of STT diagnostics."
  },
  {
    "title": "Mathematical Validation of Proposed Machine Learning Classifier for Heterogeneous Traffic and Anomaly Detection",
    "keywords": [
      "anomaly detection,",
      "heterogeneous traffic,",
      "preprocessing,",
      "machine learning,",
      "training,",
      "classification"
    ],
    "abstract": "The modeling of an efficient classifier is a fundamental issue in automatic training involving a large volume of representative data. Hence, automatic classification is a major task that entails the use of training methods capable of assigning classes to data objects by using the input activities presented to learn classes. The recognition of new elements is possible based on predefined classes. Intrusion detection systems suffer from numerous vulnerabilities during analysis and classification of data activities. To overcome this problem, new analysis methods should be derived so as to implement a relevant system to monitor circulated traffic. The main objective of this study is to model and validate a heterogeneous traffic classifier capable of categorizing collected events within networks. The new model is based on a proposed machine learning algorithm that comprises an input layer, a hidden layer, and an output layer. A reliable training algorithm is proposed to optimize the weights, and a recognition algorithm is used to validate the model. Preprocessing is applied to the collected traffic prior to the analysis step. This work aims to describe the mathematical validation of a new machine learning classifier for heterogeneous traffic and anomaly detection."
  },
  {
    "title": "Machine Knowledge and Human Cognition",
    "keywords": [
      "intelligent machine,",
      "machine knowledge,",
      "human cognition,",
      "knowledge interpretation,",
      "principle of functional similarity,",
      "probable approximative correction (pac) model"
    ],
    "abstract": "Intelligent machines are knowledge systems with unique knowledge structure and function. In this paper, we discuss issues including the characteristics and forms of machine knowledge, the relationship between knowledge and human cognition, and the approach to acquire machine knowledge. These issues are of great significance to the development of artificial intelligence."
  },
  {
    "title": "DFF-ResNet: An Insect Pest Recognition Model Based on Residual Networks",
    "keywords": [
      "insect pest recognition,",
      "deep feature fusion,",
      "residual network,",
      "image classification"
    ],
    "abstract": "Insect pest control is considered as a significant factor in the yield of commercial crops. Thus, to avoid economic losses, we need a valid method for insect pest recognition. In this paper, we proposed a feature fusion residual block to perform the insect pest recognition task. Based on the original residual block, we fused the feature from a previous layer between two 1×1 convolution layers in a residual signal branch to improve the capacity of the block. Furthermore, we explored the contribution of each residual group to the model performance. We found that adding the residual blocks of earlier residual groups promotes the model performance significantly, which improves the capacity of generalization of the model. By stacking the feature fusion residual block, we constructed the Deep Feature Fusion Residual Network (DFF-ResNet). To prove the validity and adaptivity of our approach, we constructed it with two common residual networks (Pre-ResNet and Wide Residual Network (WRN)) and validated these models on the Canadian Institute For Advanced Research (CIFAR) and Street View House Number (SVHN) benchmark datasets. The experimental results indicate that our models have a lower test error than those of baseline models. Then, we applied our models to recognize insect pests and obtained validity on the IP102 benchmark dataset. The experimental results show that our models outperform the original ResNet and other state-of-the-art methods."
  },
  {
    "title": "Survey on Data Analysis in Social Media: A Practical Application Aspect",
    "keywords": [
      "social media,",
      "topic analysis,",
      "time series analysis,",
      "sentiment analysis,",
      "network analysis,",
      "disaster management,",
      "bio-surveillance,",
      "business intelligence"
    ],
    "abstract": "Social media has more than three billion users sharing events, comments, and feelings throughout the world. It serves as a critical information source with large volumes, high velocity, and a wide variety of data. The previous studies on information spreading, relationship analyzing, and individual modeling, etc., have been heavily conducted to explore the tremendous social and commercial values of social media data. This survey studies the previous literature and the existing applications from a practical perspective. We outline a commonly used pipeline in building social media-based applications and focus on discussing available analysis techniques, such as topic analysis, time series analysis, sentiment analysis, and network analysis. After that, we present the impacts of such applications in three different areas, including disaster management, healthcare, and business. Finally, we list existing challenges and suggest promising future research directions in terms of data privacy, 5G wireless network, and multilingual support."
  },
  {
    "title": "CircRNA-Disease Associations Prediction Based on Metapath2vec++ and Matrix Factorization",
    "keywords": [
      "circular rnas (circrnas),",
      "circrna-disease associations,",
      "matepath2vec++,",
      "matrix factorization"
    ],
    "abstract": "Circular RNA (circRNA) is a novel non-coding endogenous RNAs. Evidence has shown that circRNAs are related to many biological processes and play essential roles in different biological functions. Although increasing numbers of circRNAs are discovered using high-throughput sequencing technologies, these techniques are still time-consuming and costly. In this study, we propose a computational method to predict circRNA-disesae associations which is based on metapath2vec++ and matrix factorization with integrated multiple data (called PCD_MVMF). To construct more reliable networks, various aspects are considered. Firstly, circRNA annotation, sequence, and functional similarity networks are established, and disease-related genes and semantics are adopted to construct disease functional and semantic similarity networks. Secondly, metapath2vec++ is applied on an integrated heterogeneous network to learn the embedded features and initial prediction score. Finally, we use matrix factorization, take similarity as a constraint, and optimize it to obtain the final prediction results. Leave-one-out cross-validation, five-fold cross-validation, and f-measure are adopted to evaluate the performance of PCD_MVMF. These evaluation metrics verify that PCD_MVMF has better prediction performance than other methods. To further illustrate the performance of PCD_MVMF, case studies of common diseases are conducted. Therefore, PCD_MVMF can be regarded as a reliable and useful circRNA-disease association prediction tool."
  },
  {
    "title": "Multi-Attention Fusion Modeling for Sentiment Analysis of Educational Big Data",
    "keywords": [
      "educational big data,",
      "sentiment analysis,",
      "aspect-level,",
      "attention"
    ],
    "abstract": "As an important branch of natural language processing, sentiment analysis has received increasing attention. In teaching evaluation, sentiment analysis can help educators discover the true feelings of students about the course in a timely manner and adjust the teaching plan accurately and timely to improve the quality of education and teaching. Aiming at the inefficiency and heavy workload of college curriculum evaluation methods, a Multi-Attention Fusion Modeling (Multi-AFM) is proposed, which integrates global attention and local attention through gating unit control to generate a reasonable contextual representation and achieve improved classification results. Experimental results show that the Multi-AFM model performs better than the existing methods in the application of education and other fields."
  },
  {
    "title": "Survey on Lie Group Machine Learning",
    "keywords": [
      "lie group machine learning,",
      "lie group subspace orbit generation learning,",
      "quantum group learning,",
      "symplectic group learning,",
      "lie group fiber bundle learning"
    ],
    "abstract": "Lie group machine learning is recognized as the theoretical basis of brain intelligence, brain learning, higher machine learning, and higher artificial intelligence. Sample sets of Lie group matrices are widely available in practical applications. Lie group learning is a vibrant field of increasing importance and extraordinary potential and thus needs to be developed further. This study aims to provide a comprehensive survey on recent advances in Lie group machine learning. We introduce Lie group machine learning techniques in three major categories: supervised Lie group machine learning, semisupervised Lie group machine learning, and unsupervised Lie group machine learning. In addition, we introduce the special application of Lie group machine learning in image processing. This work covers the following techniques: Lie group machine learning model, Lie group subspace orbit generation learning, symplectic group learning, quantum group learning, Lie group fiber bundle learning, Lie group cover learning, Lie group deep structure learning, Lie group semisupervised learning, Lie group kernel learning, tensor learning, frame bundle connection learning, spectral estimation learning, Finsler geometric learning, homology boundary learning, category representation learning, and neuromorphic synergy learning. Overall, this survey aims to provide an insightful overview of state-of-the-art development in the field of Lie group machine learning. It will enable researchers to comprehensively understand the state of the field, identify the most appropriate tools for particular applications, and identify directions for future research."
  },
  {
    "title": "Inference Attacks on Genomic Data Based on Probabilistic Graphical Models",
    "keywords": [
      "single nucleotide polymorphism (snp)-trait association,",
      "belief propagation,",
      "factor graph,",
      "data sanitization"
    ],
    "abstract": "The rapid progress and plummeting costs of human-genome sequencing enable the availability of large amount of personal biomedical information, leading to one of the most important concerns — genomic data privacy. Since personal biomedical data are highly correlated with relatives, with the increasing availability of genomes and personal traits online (i.e., leakage unwittingly, or after their releasing intentionally to genetic service platforms), kin-genomic data privacy is threatened. We propose new inference attacks to predict unknown Single Nucleotide Polymorphisms (SNPs) and human traits of individuals in a familial genomic dataset based on probabilistic graphical models and belief propagation. With this method, the adversary can predict the unobserved genomes or traits of targeted individuals in a family genomic dataset where some individuals’ genomes and traits are observed, relying on SNP-trait association from Genome-Wide Association Study (GWAS), Mendel’s Laws, and statistical relations between SNPs. Existing genome inferences have relatively high computational complexity with the input of tens of millions of SNPs and human traits. Then, we propose an approach to publish genomic data with differential privacy guarantee. After finding an approximate distribution of the input genomic dataset relying on Bayesian networks, a noisy distribution is obtained after injecting noise into the approximate distribution. Finally, synthetic genomic dataset is sampled and it is proved that any query on synthetic dataset satisfies differential privacy guarantee."
  },
  {
    "title": "Error Data Analytics on RSS Range-Based Localization",
    "keywords": [
      "cramér-rao lower bound (crlb),",
      "error data analytics,",
      "generalized least squares,",
      "received signal strength (rss)"
    ],
    "abstract": "The quality of measurement data is critical to the accuracy of both outdoor and indoor localization methods. Due to the inevitable measurement error, the analytics on the error data is critical to evaluate localization methods and to find the effective ones. For indoor localization, Received Signal Strength (RSS) is a convenient and low-cost measurement that has been adopted in many localization approaches. However, using RSS data for localization needs to solve a fundamental problem, that is, how accurate are these methods? The reason of the low accuracy of the current RSS-based localization methods is the oversimplified analysis on RSS measurement data. In this proposed work, we adopt a generalized measurement model to find optimal estimators whose estimated error is equal to the Cramér-Rao Lower Bound (CRLB). Through mathematical techniques, the key factors that affect the accuracy of RSS-based localization methods are revealed, and the analytics expression that discloses the proportional relationship between the localization accuracy and these factors is derived. The significance of our discovery has two folds: First, we present a general expression for localization error data analytics, which can explain and predict the accuracy of range-based localization algorithms; second, the further study on the general analytics expression and its minimum can be used to optimize current localization algorithms."
  },
  {
    "title": "Gradient Amplification: An Efficient Way to Train Deep Neural Networks",
    "keywords": [
      "deep learning,",
      "gradient amplification,",
      "learning rate,",
      "backpropagation,",
      "vanishing gradients"
    ],
    "abstract": "Improving performance of deep learning models and reducing their training times are ongoing challenges in deep neural networks. There are several approaches proposed to address these challenges, one of which is to increase the depth of the neural networks. Such deeper networks not only increase training times, but also suffer from vanishing gradients problem while training. In this work, we propose gradient amplification approach for training deep learning models to prevent vanishing gradients and also develop a training strategy to enable or disable gradient amplification method across several epochs with different learning rates. We perform experiments on VGG-19 and Resnet models (Resnet-18 and Resnet-34) , and study the impact of amplification parameters on these models in detail. Our proposed approach improves performance of these deep learning models even at higher learning rates, thereby allowing these models to achieve higher performance with reduced training time."
  },
  {
    "title": "Fast Skyline Community Search in Multi-Valued Networks",
    "keywords": [
      "multi-valued graph,",
      "community search,",
      "skyline community"
    ],
    "abstract": "Community search has been extensively studied in large networks, such as Protein-Protein Interaction (PPI) networks, citation graphs, and collaboration networks. However, in terms of widely existing multi-valued networks, where each node has d (d⩾1) numerical attributes, almost all existing algorithms either completely ignore the attributes of node at all or only consider one attribute. To solve this problem, the concept of skyline community was presented, based on the concepts of k-core and skyline recently. The skyline community is defined as a maximal k-core that satisfies some influence constraints, which is very useful in depicting the communities that are not dominated by other communities in multi-valued networks. However, the algorithms proposed on skyline community search can only work in the special case that the nodes have different values on each attribute, and the computation complexity degrades exponentially as the number of attributes increases. In this work, we turn our attention to the general scenario where multiple nodes may have the same attribute value. Specifically, we first present an algorithm, called MICS, which can find all skyline communities in a multi-valued network. To improve computation efficiency, we then propose a dimension reduction based algorithm, called P-MICS, using the maximum entropy method. Our algorithm can significantly reduce the skyline community searching time, while is still able to find almost all cohesive skyline communities. Extensive experiments on real-world datasets demonstrate the efficiency and effectiveness of our algorithms."
  },
  {
    "title": "Applying Big Data Based Deep Learning System to Intrusion Detection",
    "keywords": [
      "intrusion detection,",
      "deep learning,",
      "convolution neural network,",
      "fully connected feedforward neural network,",
      "multi-level clustering algorithm"
    ],
    "abstract": "With vast amounts of data being generated daily and the ever increasing interconnectivity of the world’s internet infrastructures, a machine learning based Intrusion Detection Systems (IDS) has become a vital component to protect our economic and national security. Previous shallow learning and deep learning strategies adopt the single learning model approach for intrusion detection. The single learning model approach may experience problems to understand increasingly complicated data distribution of intrusion patterns. Particularly, the single deep learning model may not be effective to capture unique patterns from intrusive attacks having a small number of samples. In order to further enhance the performance of machine learning based IDS, we propose the Big Data based Hierarchical Deep Learning System (BDHDLS). BDHDLS utilizes behavioral features and content features to understand both network traffic characteristics and information stored in the payload. Each deep learning model in the BDHDLS concentrates its efforts to learn the unique data distribution in one cluster. This strategy can increase the detection rate of intrusive attacks as compared to the previous single learning model approaches. Based on parallel training strategy and big data techniques, the model construction time of BDHDLS is reduced substantially when multiple machines are deployed."
  },
  {
    "title": "Novel and Efficient Randomized Algorithms for Feature Selection",
    "keywords": [
      "feature selection,",
      "randomized algorithms,",
      "efficient selection"
    ],
    "abstract": "Feature selection is a crucial problem in efficient machine learning, and it also greatly contributes to the explainability of machine-driven decisions. Methods, like decision trees and Least Absolute Shrinkage and Selection Operator (LASSO), can select features during training. However, these embedded approaches can only be applied to a small subset of machine learning models. Wrapper based methods can select features independently from machine learning models but they often suffer from a high computational cost. To enhance their efficiency, many randomized algorithms have been designed. In this paper, we propose automatic breadth searching and attention searching adjustment approaches to further speedup randomized wrapper based feature selection. We conduct theoretical computational complexity analysis and further explain our algorithms’ generic parallelizability. We conduct experiments on both synthetic and real datasets with different machine learning base models. Results show that, compared with existing approaches, our proposed techniques can locate a more meaningful set of features with a high efficiency."
  },
  {
    "title": "Text-Based Price Recommendation System for Online Rental Houses",
    "keywords": [
      "price recommendation,",
      "natural language processing,",
      "sentence embedding,",
      "long short-term memory (lstm),",
      "mean shift"
    ],
    "abstract": "Online short-term rental platforms, such as Airbnb, have been becoming popular, and a better pricing strategy is imperative for hosts of new listings. In this paper, we analyzed the relationship between the description of each listing and its price, and proposed a text-based price recommendation system called TAPE to recommend a reasonable price for newly added listings. We used deep learning techniques (e.g., feedforward network, long short-term memory, and mean shift) to design and implement TAPE. Using two chronologically extracted datasets of the same four cities, we revealed important factors (e.g., indoor equipment and high-density area) that positively or negatively affect each property’s price, and evaluated our preliminary and enhanced models. Our models achieved a Root-Mean-Square Error (RMSE) of 33.73 in Boston, 20.50 in London, 34.68 in Los Angeles, and 26.31 in New York City, which are comparable to an existing model that uses more features."
  },
  {
    "title": "A Survey of Data Partitioning and Sampling Methods to Support Big Data Analysis",
    "keywords": [
      "big data analysis,",
      "data partitioning,",
      "data sampling,",
      "distributed and parallel computing,",
      "approximate computing"
    ],
    "abstract": "Computer clusters with the shared-nothing architecture are the major computing platforms for big data processing and analysis. In cluster computing, data partitioning and sampling are two fundamental strategies to speed up the computation of big data and increase scalability. In this paper, we present a comprehensive survey of the methods and techniques of data partitioning and sampling with respect to big data processing and analysis. We start with an overview of the mainstream big data frameworks on Hadoop clusters. The basic methods of data partitioning are then discussed including three classical horizontal partitioning schemes: range, hash, and random partitioning. Data partitioning on Hadoop clusters is also discussed with a summary of new strategies for big data partitioning, including the new Random Sample Partition (RSP) distributed model. The classical methods of data sampling are then investigated, including simple random sampling, stratified sampling, and reservoir sampling. Two common methods of big data sampling on computing clusters are also discussed: record-level sampling and block-level sampling. Record-level sampling is not as efficient as block-level sampling on big distributed data. On the other hand, block-level sampling on data blocks generated with the classical data partitioning methods does not necessarily produce good representative samples for approximate computing of big data. In this survey, we also summarize the prevailing strategies and related work on sampling-based approximation on Hadoop clusters. We believe that data partitioning and sampling should be considered together to build approximate cluster computing frameworks that are reliable in both the computational and statistical respects."
  },
  {
    "title": "Feature Representations Using the Reflected Rectified Linear Unit (RReLU) Activation",
    "keywords": [
      "deep learning,",
      "feature space,",
      "approximations,",
      "multi-output activations,",
      "rectified linear unit (relu)"
    ],
    "abstract": "Deep Neural Networks (DNNs) have become the tool of choice for machine learning practitioners today. One important aspect of designing a neural network is the choice of the activation function to be used at the neurons of the different layers. In this work, we introduce a four-output activation function called the Reflected Rectified Linear Unit (RReLU) activation which considers both a feature and its negation during computation. Our activation function is \"sparse\", in that only two of the four possible outputs are active at a given time. We test our activation function on the standard MNIST and CIFAR-10 datasets, which are classification problems, as well as on a novel Computational Fluid Dynamics (CFD) dataset which is posed as a regression problem. On the baseline network for the MNIST dataset, having two hidden layers, our activation function improves the validation accuracy from 0.09 to 0.97 compared to the well-known ReLU activation. For the CIFAR-10 dataset, we use a deep baseline network that achieves 0.78 validation accuracy with 20 epochs but overfits the data. Using the RReLU activation, we can achieve the same accuracy without overfitting the data. For the CFD dataset, we show that the RReLU activation can reduce the number of epochs from 100 (using ReLU) to 10 while obtaining the same levels of performance."
  },
  {
    "title": "Online Real-Time Trajectory Analysis Based on Adaptive Time Interval Clustering Algorithm",
    "keywords": [
      "storm,",
      "trajectory clustering,",
      "adaptive,",
      "data mining,",
      "density grid"
    ],
    "abstract": "With the development of Chinese international trade, real-time processing systems based on ship trajectory have been used to cluster trajectory in real-time, so that the hot zone information of a sea ship can be discovered in real-time. This technology has great research value for the future planning of maritime traffic. However, ship navigation characteristics cannot be found in real-time with a ship Automatic Identification System (AIS) positioning system, and the clustering effect based on the density grid fixed-time-interval algorithm cannot resolve the shortcomings of real-time clustering. This study proposes an adaptive time interval clustering algorithm based on density grid (called DAC-Stream). This algorithm can perform adaptive time-interval clustering according to the size of the real-time ship trajectory data stream, so that a ship’s hot zone information can be found efficiently and in real-time. Experimental results show that the DAC-Stream algorithm improves the clustering effect and accelerates data processing compared with the fixed-time-interval clustering algorithm based on density grid (called DC-Stream)."
  },
  {
    "title": "Comparative Study of Statistical Features to Detect the Target Event During Disaster",
    "keywords": [
      "disaster,",
      "twitter,",
      "support vector machine (svm),",
      "statical features"
    ],
    "abstract": "Microblogs, such as facebook and twitter, have much attention among the users and organizations. Nowadays, twitter is more popular because of its real-time nature. People often interacted with real-time events such as earthquakes and floods through twitter. During a disaster, the number of posts or tweets is drastically increased in twitter. At the time of the disaster, detecting a target event is a challenging task. In this paper, a framework is proposed for observing the tweets and to detect the target event. For detecting the target event, a classifier is devised based on different combinations of statistical features such as the position of the keyword in a tweet, length of a tweet, the frequency of hashtag, and frequency of user mentions and the URL. From the result, it is evident that the combination of frequency of hashtag and position of keyword features provides good classification results than the other combinations of features. Hence, usage of two features, namely, frequency of hashtag and position of the earthquake keyword reduces the event’s detection time. And also these two features are further helpful for detecting the sub-events which are used for filtering the tweets related to the disaster. Additionally, different classifiers such as Artificial Neural Networks (ANN), decision tree, and K-Nearest Neighbor (KNN) are compared by using these two features. However, Support Vector Machine (SVM) with linear kernel by using the combination of position of earthquake keyword and frequency of hashtag outperforms state-of-the-art methods. Therefore, SVM (linear kernel) with proposed features is applied for detecting the earthquake during disaster. The proposed algorithm is tested on Nepal earthquake and landslide datasets, 2015."
  },
  {
    "title": "Mining Conditional Functional Dependency Rules on Big Data",
    "keywords": [
      "data mining,",
      "conditional functional dependency,",
      "big data,",
      "data quality"
    ],
    "abstract": "Current Conditional Functional Dependency (CFD) discovery algorithms always need a well-prepared training dataset. This condition makes them difficult to apply on large and low-quality datasets. To handle the volume issue of big data, we develop the sampling algorithms to obtain a small representative training set. We design the fault-tolerant rule discovery and conflict-resolution algorithms to address the low-quality issue of big data. We also propose parameter selection strategy to ensure the effectiveness of CFD discovery algorithms. Experimental results demonstrate that our method can discover effective CFD rules on billion-tuple data within a reasonable period."
  },
  {
    "title": "On Quantum Methods for Machine Learning Problems Part I: Quantum Tools",
    "keywords": [
      "quantum algorithm,",
      "quantum programming,",
      "machine learning"
    ],
    "abstract": "This is a review of quantum methods for machine learning problems that consists of two parts. The first part, \"quantum tools\", presents the fundamentals of qubits, quantum registers, and quantum states, introduces important quantum tools based on known quantum search algorithms and SWAP-test, and discusses the basic quantum procedures used for quantum search methods. The second part, \"quantum classification algorithms\", introduces several classification problems that can be accelerated by using quantum subroutines and discusses the quantum methods used for classification."
  },
  {
    "title": "Sparse Deep Nonnegative Matrix Factorization",
    "keywords": [
      "sparse nonnegative matrix factorization (nmf),",
      "deep learning,",
      "nesterov’s accelerated gradient algorithm"
    ],
    "abstract": "Nonnegative Matrix Factorization (NMF) is a powerful technique to perform dimension reduction and pattern recognition through single-layer data representation learning. However, deep learning networks, with their carefully designed hierarchical structure, can combine hidden features to form more representative features for pattern recognition. In this paper, we proposed sparse deep NMF models to analyze complex data for more accurate classification and better feature interpretation. Such models are designed to learn localized features or generate more discriminative representations for samples in distinct classes by imposing L1-norm penalty on the columns of certain factors. By extending a one-layer model into a multilayer model with sparsity, we provided a hierarchical way to analyze big data and intuitively extract hidden features due to nonnegativity. We adopted the Nesterov's accelerated gradient algorithm to accelerate the computing process. We also analyzed the computing complexity of our frameworks to demonstrate their efficiency. To improve the performance of dealing with linearly inseparable data, we also considered to incorporate popular nonlinear functions into these frameworks and explored their performance. We applied our models using two benchmarking image datasets, and the results showed that our models can achieve competitive or better classification performance and produce intuitive interpretations compared with the typical NMF and competing multilayer models."
  },
  {
    "title": "A Semi-Supervised Attention Model for Identifying Authentic Sneakers",
    "keywords": [
      "sneaker identification,",
      "fine-grained classification,",
      "multi-instance learning,",
      "attention mechanism"
    ],
    "abstract": "To protect consumers and those who manufacture and sell the products they enjoy, it is important to develop convenient tools to help consumers distinguish an authentic product from a counterfeit one. The advancement of deep learning techniques for fine-grained object recognition creates new possibilities for genuine product identification. In this paper, we develop a Semi-Supervised Attention (SSA) model to work in conjunction with a large-scale multiple-source dataset named YSneaker, which consists of sneakers from various brands and their authentication results, to identify authentic sneakers. Specifically, the SSA model has a self-attention structure for different images of a labeled sneaker and a novel prototypical loss is designed to exploit unlabeled data within the data structure. The model draws on the weighted average of the output feature representations, where the weights are determined by an additional shallow neural network. This allows the SSA model to focus on the most important images of a sneaker for use in identification. A unique feature of the SSA model is its ability to take advantage of unlabeled data, which can help to further minimize the intra-class variation for more discriminative feature embedding. To validate the model, we collect a large number of labeled and unlabeled sneaker images and perform extensive experimental studies. The results show that YSneaker together with the proposed SSA architecture can identify authentic sneakers with a high accuracy rate."
  },
  {
    "title": "On Quantum Methods for Machine Learning Problems Part II: Quantum Classification Algorithms",
    "keywords": [
      "quantum classification,",
      "binary classification,",
      "nearest neighbor algorithm"
    ],
    "abstract": "This is a review of quantum methods for machine learning problems that consists of two parts. The first part, \"quantum tools\", presented some of the fundamentals and introduced several quantum tools based on known quantum search algorithms. This second part of the review presents several classification problems in machine learning that can be accelerated with quantum subroutines. We have chosen supervised learning tasks as typical classification problems to illustrate the use of quantum methods for classification."
  },
  {
    "title": "Classification on Grade, Price, and Region with Multi-Label and Multi-Target Methods in Wineinformatics",
    "keywords": [
      "classification,",
      "informatics,",
      "machine learning,",
      "multi-label,",
      "multi-target,",
      "support vector machines,",
      "wine,",
      "wineinformatics"
    ],
    "abstract": "Classifying wine according to their grade, price, and region of origin is a multi-label and multi-target problem in wineinformatics. Using wine reviews as the attributes, we compare several different multi-label/multi-target methods to the single-label method where each label is treated independently. We explore both single-label and multi-label approaches for a two-class problem for each of the labels and we explore both single-label and multi-target approaches for a four-class problem on two of the three labels, with the third label remaining a two-class problem. In terms of per-label accuracy, the single-label method has the best performance, although some multi-label methods approach the performance of single-label. However, multi-label/multi-target metrics approaches do exceed the performance of the single-label method."
  },
  {
    "title": "Clinical Big Data and Deep Learning: Applications, Challenges, and Future Outlooks",
    "keywords": [
      "deep learning,",
      "clinical data,",
      "electronic health record (ehr),",
      "medical image,",
      "clinical note"
    ],
    "abstract": "The explosion of digital healthcare data has led to a surge of data-driven medical research based on machine learning. In recent years, as a powerful technique for big data, deep learning has gained a central position in machine learning circles for its great advantages in feature representation and pattern recognition. This article presents a comprehensive overview of studies that employ deep learning methods to deal with clinical data. Firstly, based on the analysis of the characteristics of clinical data, various types of clinical data (e.g., medical images, clinical notes, lab results, vital signs, and demographic informatics) are discussed and details provided of some public clinical datasets. Secondly, a brief review of common deep learning models and their characteristics is conducted. Then, considering the wide range of clinical research and the diversity of data types, several deep learning applications for clinical data are illustrated: auxiliary diagnosis, prognosis, early warning, and other tasks. Although there are challenges involved in applying deep learning techniques to clinical data, it is still worthwhile to look forward to a promising future for deep learning applications in clinical big data in the direction of precision medicine."
  },
  {
    "title": "Selective Ensemble Learning Method for Belief-Rule-Base Classification System Based on PAES",
    "keywords": [
      "belief-rule-base,",
      "pareto-archived evolutionary strategy,",
      "selective ensemble,",
      "classification"
    ],
    "abstract": "Traditional Belief-Rule-Based (BRB) ensemble learning methods integrate all of the trained sub-BRB systems to obtain better results than a single belief-rule-based system. However, as the number of BRB systems participating in ensemble learning increases, a large amount of redundant sub-BRB systems are generated because of the diminishing difference between subsystems. This drastically decreases the prediction speed and increases the storage requirements for BRB systems. In order to solve these problems, this paper proposes BRBCS-PAES: a selective ensemble learning approach for BRB Classification Systems (BRBCS) based on Pareto-Archived Evolutionary Strategy (PAES) multi-objective optimization. This system employs the improved Bagging algorithm to train the base classifier. For the purpose of increasing the degree of difference in the integration of the base classifier, the training set is constructed by the repeated sampling of data. In the base classifier selection stage, the trained base classifier is binary coded, and the number of base classifiers participating in integration and generalization error of the base classifier is used as the objective function for multi-objective optimization. Finally, the elite retention strategy and the adaptive mesh algorithm are adopted to produce the PAES optimal solution set. Three experimental studies on classification problems are performed to verify the effectiveness of the proposed method. The comparison results demonstrate that the proposed method can effectively reduce the number of base classifiers participating in the integration and improve the accuracy of BRBCS."
  },
  {
    "title": "LoSI: Large Scale Location Inference Through FM Signal Integration and Estimation",
    "keywords": [
      "global positioning system (gps)-free positioning,",
      "frequency modulation (fm) radio,",
      "signals of opportunity"
    ],
    "abstract": "In this paper we present a large scale, passive positioning system that can be used for approximate localization in Global Positioning System (GPS) denied/spoofed environments. This system can be used for detecting GPS spoofing as well as for initial position estimation for input to other GPS free positioning and navigation systems like Terrain Contour Matching (TERCOM). Our Location inference through Frequency Modulation (FM) Signal Integration and estimation (LoSI) system is based on broadcast FM radio signals and uses Received Signal Strength Indicator (RSSI) obtained using a Software Defined Radio (SDR). The RSSI thus obtained is used for indexing into an estimated model of expected FM spectrum for the entire United States. We show that with the hardware for data acquisition, a single point resolution of around 3 miles and associated algorithms, we are capable of positioning with errors as low as a single pixel (more precisely around 0.12 mile). The algorithm uses a large-scale model estimation phase that computes the expected FM spectrum in small rectangular cells (realized using geohashes) across the Contiguous United States (CONUS). We define and use Dominant Channel Descriptor (DCD) features, which can be used for positioning using time varying models. Finally we use an algorithm based on Euclidean nearest neighbors in the DCD feature space for position estimation. The system first runs a DCD feature detector on the observed spectrum and then solves a subset query formulation to find Inference Candidates (IC). Finally, it uses a simple Euclidean nearest neighbor search on the ICs to localize the observation. We report results on 1500 points across Florida using data and model estimates from 2015 and 2017. We also provide a Bayesian decision theoretic justification for the nearest neighbor search."
  },
  {
    "title": "Prediction of miRNA-circRNA Associations Based on k-NN Multi-Label with Random Walk Restart on a Heterogeneous Network",
    "keywords": [
      "mirna-circrna associations,",
      "heterogeneous network,",
      "multi-label,",
      "random walk restart"
    ],
    "abstract": "Circular RNAs (circRNAs) play important roles in various biological processes, as essential non-coding RNAs that have effects on transcriptional and posttranscriptional gene expression regulation. Recently, many studies have shown that circRNAs can be regarded as micro RNA (miRNA) sponges, which are known to be associated with certain diseases. Therefore efficient computation methods are needed to explore miRNA-circRNA interactions, but only very few computational methods for predicting the associations between miRNAs and circRNAs exist. In this study, we adopt an improved random walk computational method, named KRWRMC, to express complicated associations between miRNAs and circRNAs. Our major contributions can be summed up in two points. First, in the conventional Random Walk Restart Heterogeneous (RWRH) algorithm, the computational method simply converts the circRNA/miRNA similarity network into the transition probability matrix; in contrast, we take the influence of the neighbor of the node in the network into account, which can suggest or stress some potential associations. Second, our proposed KRWRMC is the first computational model to calculate large numbers of miRNA-circRNA associations, which can be regarded as biomarkers to diagnose certain diseases and can thus help us to better understand complicated diseases. The reliability of KRWRMC has been verified by Leave One Out Cross Validation (LOOCV) and 10-fold cross validation, the results of which indicate that this method achieves excellent performance in predicting potential miRNA-circRNA associations."
  },
  {
    "title": "Tweetluenza: Predicting Flu Trends from Twitter Data",
    "keywords": [
      "twitter data analysis,",
      "influenza forecasting,",
      "prediction using social media,",
      "social media mining"
    ],
    "abstract": "Health authorities worldwide strive to detect Influenza prevalence as early as possible in order to prepare for it and minimize its impacts. To this end, we address the Influenza prevalence surveillance and prediction problem. In this paper, we develop a new Influenza prevalence prediction model, called Tweetluenza, to predict the spread of the Influenza in real time using cross-lingual data harvested from Twitter data streams with emphases on the United Arab Emirates (UAE). Based on the features of tweets, Tweetluenza filters the Influenza tweets and classifies them into two classes, reporting and non-reporting. To monitor the growth of Influenza, the reporting tweets were employed. Furthermore, a linear regression model leverages the reporting tweets to predict the Influenza-related hospital visits in the future. We evaluated Tweetluenza empirically to study its feasibility and compared the results with the actual hospital visits recorded by the UAE Ministry of Health. The results of our experiments demonstrate the practicality of Tweetluenza, which was verified by the high correlation between the Influenza-related Twitter data and hospital visits due to Influenza. Furthermore, the evaluation of the analysis and prediction of Influenza shows that combining English and Arabic tweets improves the correlation results."
  },
  {
    "title": "Statistical Learning for Semantic Parsing: A Survey",
    "keywords": [
      "deep learning,",
      "semantic parsing,",
      "knowledge base question answering (kbqa)"
    ],
    "abstract": "A long-term goal of Artificial Intelligence (AI) is to provide machines with the capability of understanding natural language. Understanding natural language may be referred as the system must produce a correct response to the received input order. This response can be a robot move, an answer to a question, etc. One way to achieve this goal is semantic parsing. It parses utterances into semantic representations called logical form, a representation of many important linguistic phenomena that can be understood by machines. Semantic parsing is a fundamental problem in natural language understanding area. In recent years, researchers have made tremendous progress in this field. In this paper, we review recent algorithms for semantic parsing including both conventional machine learning approaches and deep learning approaches. We first give an overview of a semantic parsing system, then we summary a general way to do semantic parsing in statistical learning. With the rise of deep learning, we will pay more attention on the deep learning based semantic parsing, especially for the application of Knowledge Base Question Answering (KBQA). At last, we survey several benchmarks for KBQA."
  },
  {
    "title": "A Novel Clustering Technique for Efficient Clustering of Big Data in Hadoop Ecosystem",
    "keywords": [
      "clustering,",
      "hadoop,",
      "big data,",
      "k-means,",
      "hierarchical"
    ],
    "abstract": "Big data analytics and data mining are techniques used to analyze data and to extract hidden information. Traditional approaches to analysis and extraction do not work well for big data because this data is complex and of very high volume. A major data mining technique known as data clustering groups the data into clusters and makes it easy to extract information from these clusters. However, existing clustering algorithms, such as k-means and hierarchical, are not efficient as the quality of the clusters they produce is compromised. Therefore, there is a need to design an efficient and highly scalable clustering algorithm. In this paper, we put forward a new clustering algorithm called hybrid clustering in order to overcome the disadvantages of existing clustering algorithms. We compare the new hybrid algorithm with existing algorithms on the bases of precision, recall, F-measure, execution time, and accuracy of results. From the experimental results, it is clear that the proposed hybrid clustering algorithm is more accurate, and has better precision, recall, and F-measure values."
  },
  {
    "title": "Network Representation Based on the Joint Learning of Three Feature Views",
    "keywords": [
      "network representation learning,",
      "network feature mining,",
      "embedding learning,",
      "link prediction,",
      "matrix factorization"
    ],
    "abstract": "Network representation learning plays an important role in the field of network data mining. By embedding network structures and other features into the representation vector space of low dimensions, network representation learning algorithms can provide high-quality feature input for subsequent tasks, such as network link prediction, network vertex classification, and network visualization. The existing network representation learning algorithms can be trained based on the structural features, vertex texts, vertex tags, community information, etc. However, there exists a lack of algorithm of using the future evolution results of the networks to guide the network representation learning. Therefore, this paper aims at modeling the future network evolution results of the networks based on the link prediction algorithm, introducing the future link probabilities between vertices without edges into the network representation learning tasks. In order to make the network representation vectors contain more feature factors, the text features of the vertices are also embedded into the network representation vectors. Based on the above two optimization approaches, we propose a novel network representation learning algorithm, Network Representation learning algorithm based on the joint optimization of Three Features (TFNR). Based on Inductive Matrix Completion (IMC), TFNR algorithm introduces the future probabilities between vertices without edges and text features into the procedure of modeling network structures, which can avoid the problem of the network structure sparse. Experimental results show that the proposed TFNR algorithm performs well in network vertex classification and visualization tasks on three real citation network datasets."
  },
  {
    "title": "A Semi-Supervised Deep Network Embedding Approach Based on the Neighborhood Structure",
    "keywords": [
      "network embedding,",
      "deep learning,",
      "network analysis"
    ],
    "abstract": "Network embedding is a very important task to represent the high-dimensional network in a low-dimensional vector space, which aims to capture and preserve the network structure. Most existing network embedding methods are based on shallow models. However, actual network structures are complicated which means shallow models cannot obtain the high-dimensional nonlinear features of the network well. The recently proposed unsupervised deep learning models ignore the labels information. To address these challenges, in this paper, we propose an effective network embedding method of Structural Labeled Locally Deep Nonlinear Embedding (SLLDNE). SLLDNE is designed to obtain highly nonlinear features through utilizing deep neural network while preserving the label information of the nodes by using a semi-supervised classifier component to improve the ability of discriminations. Moreover, we exploit linear reconstruction of neighborhood nodes to enable the model to get more structural information. The experimental results of vertex classification on two real-world network datasets demonstrate that SLLDNE outperforms the other state-of-the-art methods."
  },
  {
    "title": "Bayesian Analysis of Complex Mutations in HBV, HCV, and HIV Studies",
    "keywords": [
      "bayesian analysis,",
      "hepatitis b virus (hbv),",
      "hepatitis c virus (hcv),",
      "human immunodeficiency virus (hiv),",
      "complex mutations,",
      "markov chain monte carlo"
    ],
    "abstract": "In this article, we aim to provide a thorough review of the Bayesian-inference-based methods applied to Hepatitis B Virus (HBV), Hepatitis C Virus (HCV), and Human Immunodeficiency Virus (HIV) studies with a focus on the detection of the viral mutations and various problems which are correlated to these mutations. It is particularly difficult to detect and interpret these interacting mutation patterns, but by using Bayesian statistical modeling, it provides a groundbreaking opportunity to solve these problems. Here we summarize Bayesian-based statistical approaches, including the Bayesian Variable Partition (BVP) model, Bayesian Network (BN), and the Recursive Model Selection (RMS) procedure, which are designed to detect the mutations and to make further inferences to the comprehensive dependence structure among the interactions. BVP, BN, and RMS in which Markov Chain Monte Carlo (MCMC) methods are used have been widely applied in HBV, HCV, and HIV studies in the recent years. We also provide a summary of the Bayesian methods’ applications toward these viruses’ studies, where several important and useful results have been discovered. We envisage the applications of more modified Bayesian methods to other infectious diseases and cancer cells that will be following with critical medical results before long."
  },
  {
    "title": "High Performance Frequent Subgraph Mining on Transaction Datasets: A Survey and Performance Comparison",
    "keywords": [
      "frequent subgraphs,",
      "isomorphism,",
      "spark"
    ],
    "abstract": "Graph data mining has been a crucial as well as inevitable area of research. Large amounts of graph data are produced in many areas, such as Bioinformatics, Cheminformatics, Social Networks, etc. Scalable graph data mining methods are getting increasingly popular and necessary due to increased graph complexities. Frequent subgraph mining is one such area where the task is to find overly recurring patterns/subgraphs. To tackle this problem, many main memory-based methods were proposed, which proved to be inefficient as the data size grew exponentially over time. In the past few years, several research groups have attempted to handle the Frequent Subgraph Mining (FSM) problem in multiple ways. Many authors have tried to achieve better performance using Graphic Processing Units (GPUs) which has multi-fold improvement over in-memory while dealing with large datasets. Later, Google’s MapReduce model with the Hadoop framework proved to be a major breakthrough in high performance large batch processing. Although MapReduce came with many benefits, its disk I/O and non-iterative style model could not help much for FSM domain since subgraph mining process is an iterative approach. In recent years, Spark has emerged to be the De Facto industry standard with its distributed in-memory computing capability. This is a right fit solution for iterative style of programming as well. In this survey, we cover how high-performance computing has helped in improving the performance tremendously in the transactional directed and undirected aspect of graphs and performance comparisons of various FSM techniques are done based on experimental results."
  },
  {
    "title": "Multi-Class Sentiment Analysis on Twitter: Classification Performance and Challenges",
    "keywords": [
      "twitter,",
      "sentiment analysis,",
      "machine learning"
    ],
    "abstract": "Sentiment analysis refers to the automatic collection, aggregation, and classification of data collected online into different emotion classes. While most of the work related to sentiment analysis of texts focuses on the binary and ternary classification of these data, the task of multi-class classification has received less attention. Multi-class classification has always been a challenging task given the complexity of natural languages and the difficulty of understanding and mathematically \"quantifying\" how humans express their feelings. In this paper, we study the task of multi-class classification of online posts of Twitter users, and show how far it is possible to go with the classification, and the limitations and difficulties of this task. The proposed approach of multi-class classification achieves an accuracy of 60.2% for 7 different sentiment classes which, compared to an accuracy of 81.3% for binary classification, emphasizes the effect of having multiple classes on the classification performance. Nonetheless, we propose a novel model to represent the different sentiments and show how this model helps to understand how sentiments are related. The model is then used to analyze the challenges that multi-class classification presents and to highlight possible future enhancements to multi-class classification accuracy."
  },
  {
    "title": "Efficient Preference Clustering via Random Fourier Features",
    "keywords": [
      "random fourier features,",
      "matrix decomposition,",
      "similarity matrix"
    ],
    "abstract": "Approximations based on random Fourier features have recently emerged as an efficient and elegant method for designing large-scale machine learning tasks. Unlike approaches using the Nyström method, which randomly samples the training examples, we make use of random Fourier features, whose basis functions (i.e., cosine and sine ) are sampled from a distribution independent from the training sample set, to cluster preference data which appears extensively in recommender systems. Firstly, we propose a two-stage preference clustering framework. In this framework, we make use of random Fourier features to map the preference matrix into the feature matrix, soon afterwards, utilize the traditional k-means approach to cluster preference data in the transformed feature space. Compared with traditional preference clustering, our method solves the problem of insufficient memory and greatly improves the efficiency of the operation. Experiments on movie data sets containing 100 000 ratings, show that the proposed method is more effective in clustering accuracy than the Nyström and k-means, while also achieving better performance than these clustering approaches."
  },
  {
    "title": "Towards Understanding the Security of Modern Image Captchas and Underground Captcha-Solving Services",
    "keywords": [
      "image captchas,",
      "captcha security,",
      "captcha-solving service,",
      "underground market"
    ],
    "abstract": "Image captchas have recently become very popular and are widely deployed across the Internet to defend against abusive programs. However, the ever-advancing capabilities of computer vision have gradually diminished the security of image captchas and made them vulnerable to attack. In this paper, we first classify the currently popular image captchas into three categories: selection-based captchas, slide-based captchas, and click-based captchas. Second, we propose simple yet powerful attack frameworks against each of these categories of image captchas. Third, we systematically evaluate our attack frameworks against 10 popular real-world image captchas, including captchas from tencent.com, google.com, and 12306.cn. Fourth, we compare our attacks against nine online image recognition services and against human labors from eight underground captcha-solving services. Our evaluation results show that (1) each of the popular image captchas that we study is vulnerable to our attacks; (2) our attacks yield the highest captcha-breaking success rate compared with state-of-the-art methods in almost all scenarios; and (3) our attacks achieve almost as high a success rate as human labor while being much faster. Based on our evaluation, we identify some design flaws in these popular schemes, along with some best practices and design principles for more secure captchas. We also examine the underground market for captcha-solving services, identifying 152 such services. We then seek to measure this underground market with data from these services. Our findings shed light on understanding the scale, impact, and commercial landscape of the underground market for captcha solving."
  },
  {
    "title": "Spreading Social Influence with both Positive and Negative Opinions in Online Networks",
    "keywords": [
      "influence spread,",
      "social networks,",
      "positive influential node set,",
      "greedy algorithm,",
      "positive and negative influences"
    ],
    "abstract": "Social networks are important media for spreading information, ideas, and influence among individuals. Most existing research focuses on understanding the characteristics of social networks, investigating how information is spread through the \"word-of-mouth\" effect of social networks, or exploring social influences among individuals and groups. However, most studies ignore negative influences among individuals and groups. Motivated by the goal of alleviating social problems, such as drinking, smoking, and gambling, and influence-spreading problems, such as promoting new products, we consider positive and negative influences, and propose a new optimization problem called the Minimum-sized Positive Influential Node Set (MPINS) selection problem to identify the minimum set of influential nodes such that every node in the network can be positively influenced by these selected nodes with no less than a threshold of θ. Our contributions are threefold. First, we prove that, under the independent cascade model considering positive and negative influences, MPINS is APX-hard. Subsequently, we present a greedy approximation algorithm to address the MPINS selection problem. Finally, to validate the proposed greedy algorithm, we conduct extensive simulations and experiments on random graphs and seven different real-world data sets that represent small-, medium-, and large-scale networks."
  },
  {
    "title": "A Non-Redundant Benchmark for Symmetric Protein Docking",
    "keywords": [
      "benchmark,",
      "symmetric protein"
    ],
    "abstract": "Symmetric proteins play important roles in many biological processes, such as signal transduction and molecular transportation. Therefore, determining the symmetric oligomeric structure of subunits is crucial to investigate the molecular mechanism of the related processes. Due to the high cost and technical difficulties associated with many experimental methods, computational approaches, such as molecular docking, have played an important complementary role in the determination of symmetric complex structures, in which a benchmark data set is pressingly needed. In the present work, we develop a comprehensive and non-redundant benchmark for symmetric protein docking based on the structures in the Protein Data Bank (PDB). The diverse dataset consists of 251 targets, including 212 cases with cyclic groups symmetry, 35 cases with dihedral groups symmetry, 3 cases with cubic groups symmetry, and 1 case with helical symmetry. According to the conformational changes in the interface between bound and unbound structures, the 251 targets were classified into three groups: 176 \"easy\", 37 \"medium\", and 38 \"difficult\" cases. A preliminary docking test on the targets of cyclic groups symmetry with M-ZDOCK indicated that symmetric multimer docking remains challenging. The benchmark will be beneficial for the development of symmetric protein docking algorithms. The proposed benchmark data set is available for download at http://huanglab.phys.hust.edu.cn/SDBenchmark/."
  },
  {
    "title": "Model Error Correction in Data Assimilation by Integrating Neural Networks",
    "keywords": [
      "data assimilation,",
      "deep learning,",
      "neural networks,",
      "kalman filter,",
      "variational approach"
    ],
    "abstract": "In this paper, we suggest a new methodology which combines Neural Networks (NN) into Data Assimilation (DA). Focusing on the structural model uncertainty, we propose a framework for integration NN with the physical models by DA algorithms, to improve both the assimilation process and the forecasting results. The NNs are iteratively trained as observational data is updated. The main DA models used here are the Kalman filter and the variational approaches. The effectiveness of the proposed algorithm is validated by examples and by a sensitivity study."
  },
  {
    "title": "Feature Selection with Graph Mining Technology",
    "keywords": [
      "graph mining,",
      "network embedding,",
      "big data analysis,",
      "feature selection,",
      "high-dimensional data"
    ],
    "abstract": "Many real world applications have problems with high dimensionality, which existing algorithms cannot overcome. A critical data preprocessing problem is feature selection, whereby its non-scalability negatively influences both the efficiency and performance of big data applications. In this research, we developed a new algorithm to reduce the dimensionality of a problem using graph-based analysis, which retains the physical meaning of the original high-dimensional feature space. Most existing feature-selection methods are based on a strong assumption that features are independent of each other. However, if the feature-selection algorithm does not take into consideration the interdependencies of the feature space, the selected data fail to correctly represent the original data. We developed a new feature-selection method to address this challenge. Our aim in this research was to examine the dependencies between features and select the optimal feature set with respect to the original data structure. Another important factor in our proposed method is that it can perform even in the absence of class labels. This is a more difficult problem that many feature-selection algorithms fail to address. In this case, they only use wrapper techniques that require a learning algorithm to select features. It is important to note that our experimental results indicates, this proposed simple ranking method performs better than other methods, independent of any particular learning algorithm used."
  },
  {
    "title": "Auxo: A Temporal Graph Management System",
    "keywords": [
      "graphs and networks,",
      "temporal databases,",
      "composite structures"
    ],
    "abstract": "As real-world graphs are often evolving over time, interest in analyzing the temporal behavior of graphs has grown. Herein, we propose Auxo, a novel temporal graph management system to support temporal graph analysis. It supports both efficient global and local queries with low space overhead. Auxo organizes temporal graph data in spatio-temporal chunks. A chunk spans a particular time interval and covers a set of vertices in a graph. We propose chunk layout and chunk splitting designs to achieve the desired efficiency and the abovementioned goals. First, by carefully choosing the time split policy, Auxo achieves linear complexity in both space usage and query time. Second, graph splitting further improves the worst-case query time, and reduces the performance variance introduced by splitting operations. Third, Auxo optimizes the data layout inside chunks, thereby significantly improving the performance of traverse-based graph queries. Experimental evaluation showed that Auxo achieved 2.9× to 12.1× improvement for global queries, and 1.7× to 2.7× improvement for local queries, as compared with state-of-the-art open-source solutions."
  }
]